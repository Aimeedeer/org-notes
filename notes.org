#+Hugo_base_dir: .
#+options: author:Aimee

* Posts
:PROPERTIES:
:EXPORT_HUGO_SECTION: post
:EXPORT_HUGO_MENU: :menu main
:END:
** Advent of Code                                             :rust:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: advent-of-code
:EXPORT_DATE: 2020-12-14
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Rust programming practice
:EXPORT_OPTIONS: toc:2
:END:

*GitHub repo*: https://github.com/Aimeedeer/adventofcode-2020

*** Read and Learned

- [[https://doc.rust-lang.org/book/ch19-06-macros.html][Rust Macro]] 
  - [[https://doc.rust-lang.org/reference/macros-by-example.html][Macros By Example]] 
  - [[https://doc.rust-lang.org/reference/procedural-macros.html][Procedural Macros]]
  - [[https://danielkeep.github.io/tlborm/book/README.html][The Little Book of Rust Macros]]
- [[https://doc.rust-lang.org/stable/book/ch06-03-if-let.html][Concise Control Flow with ~if let~]]
- Differences between runtime and compile time. Answers from
  Stackoverflow: https://stackoverflow.com/questions/846103/runtime-vs-compile-time
- [[https://en.wikipedia.org/wiki/Abstract_syntax_tree][Abstract Syntax Tree (AST)]]


*** Day9

A Vector of integer as input.

*** Day8 

Assembly-like program. Learned a bit CS.

I am not happy with my code, though.

*** Day7

Started using ~lazy_static~:

#+begin_src rust
extern crate lazy_static;
use lazy_static::lazy_static;

lazy_static! {
    static ref RE: Regex = Regex::new(r"^(\w+ \w+) bags contain (.*)$").unwrap();
}
#+end_src

Recursive functions in Rust:

#+begin_src rust
fn is_my_bag_in_map(candidate_bag: &str, map: &HashMap<String, HashMap<String, u32>>) -> bool {
    ...
}

fn bags_contained(candidate_bag: &str, map: &HashMap<String, HashMap<String, u32>>) -> u32 {
    ...
}
#+end_src

*** Day6

An easy puzzle, counting chars.
*** Day5

[[https://adventofcode.com/2020/day/5][Day 5: Binary Boarding]]
- Source code: https://github.com/Aimeedeer/adventofcode-2020/tree/master/day5

Use const for ~8~. The magical number is defined in the problem description.

#+begin_src rust
	const NUM_COLUMNS: u32 = 8; 
	let seat_id = row_id * NUM_COLUMNS + column_id;
#+end_src

Abstract functions ~get_row_id~ and ~get_column_id~ as ~search_id~.

#+begin_src rust
fn get_row_id(input: &str) -> Result<u32> {
    search_id(input, 128, 'F', 'B', "row id")
}

fn get_column_id(input: &str) -> Result<u32> {
    search_id(input, 8, 'L', 'R', "column id")
}

fn search_id(
    input: &str,
    len: u32,
    match_char_one: char,
    match_char_two: char,
    msg: &str	     
) -> Result<u32> {
    let range = (0..len).into_iter().collect::<Vec<_>>();
    let mut range = range.as_slice();

    for c in input.chars() {
	let temp_len = range.len();
	let (one, two) = range.split_at(temp_len/2);

	if c == match_char_one {
	    range = one;
	} else if c == match_char_two {
	    range = two;
	} else {
	    bail!("get {} failed", msg); 
	}
    }
    
    let id = range[0];    
    Ok(id)
}
#+end_src

Learned ~(0..10).into_iter()~, 
and ~bail~ instead of ~anyhow~ for returning a result with an error message.

*** Day4

[[https://adventofcode.com/2020/day/4][Day 4: Passport Processing]]
- Source code: https://github.com/Aimeedeer/adventofcode-2020/tree/master/day4

Learned to organize a mod:
- ~fn main~ first
- Data types and their impls second
- Functions that are used in ~fn main~ follow
- Detailed functions(sub functions) that are used in previous functions

Write a generic ~fn~ inside another function:

#+begin_src rust
	fn validate<T>(dest: &mut Option<T>,
		       reference: &str,
		       v: impl FnOnce(&str) -> Result<T>) {
	    *dest = v(reference).ok();	    	    
	}
	
	for raw_item in raw_passport {
	    let item = raw_item.split(':').collect::<Vec<_>>();
	    match item[0] {	
		"pid" => validate(&mut new_passport.pid, item[1], validate_pid),
		"cid" => validate(&mut new_passport.cid, item[1], validate_cid),
		"eyr" => validate(&mut new_passport.eyr, item[1], validate_eyr),
		"byr" => validate(&mut new_passport.byr, item[1], validate_byr),
		"iyr" => validate(&mut new_passport.iyr, item[1], validate_iyr),
		"ecl" => validate(&mut new_passport.ecl, item[1], validate_ecl),
		"hcl" => validate(&mut new_passport.hcl, item[1], validate_hcl),
		"hgt" => validate(&mut new_passport.hgt, item[1], validate_hgt),
		_ => {},
	    };
	}
#+end_src

Put parsing function in another method and make rules as a reference:

#+begin_src rust
fn parse_and_capture<T: FromStr>(rule: &str, input: &str, msg: &str) -> Result<T> {
    let re = Regex::new(rule).unwrap();
    let caps = re.captures(input).ok_or(anyhow!("invalid {}: {}", msg, input))?;

    let output = caps[1].parse::<T>().map_err(|_| anyhow!("error parsing {}: {}", msg, input))?;
    Ok(output)
}
#+end_src

We can also set Regex to a global varial so that it doesn't need to be
created each time in the loop.
[[https://github.com/BurntSushi/advent-of-code/blob/master/aoc04/src/main.rs][Burntsushi's code]] (in 2018) is a good example:

#+begin_src rust
        lazy_static! {
            static ref RE: Regex = Regex::new(r"(?x)
                \[
                    (?P<year>[0-9]{4})-(?P<month>[0-9]{2})-(?P<day>[0-9]{2})
                    \s+
                    (?P<hour>[0-9]{2}):(?P<minute>[0-9]{2})
                \]
                \s+
                (?:Guard\ \#(?P<id>[0-9]+)\ begins\ shift|(?P<sleep>.+))
            ").unwrap();
        }
#+end_src
*** Day3 

[[https://adventofcode.com/2020/day/3][Day 3: Toboggan Trajectory]]
- Source code: https://github.com/Aimeedeer/adventofcode-2020/tree/master/day3

Iterator: 

#+begin_src rust
// skip lines
for line in reader.lines().step_by(move_down) { ... }

// get interator's index while looping
for (line_index, line_value) in reader.lines().enumerate() { ... }
#+end_src

Put mutable variables in the same block of code while changing their values.
For example, the ~index~ below.

#+begin_src rust
    for line in reader.lines().step_by(move_down) {
	let rules = line?;
	let rules = rules.chars().collect::<Vec<char>>();
	let char_num = rules.len();

	if rules[index] == '#' {
	    tree_num += 1;
	} 

	index += move_right;
	index %= char_num;
    }
#+end_src
*** Day2

[[https://adventofcode.com/2020/day/2][Day 2: Password Philosophy]]
- Source code: https://github.com/Aimeedeer/adventofcode-2020/tree/master/day2

Use ~regex~ for parsing ~String~.
#+begin_src rust
let re = Regex::new(r"(\d+)-(\d+) ([[:alpha:]]): ([[:alpha:]]+)")?;
#+end_src

[[https://docs.rs/regex/1.4.2/regex/index.html#syntax][Regex Syntax]]

Use ~xx.get(index)~ instead of ~xx[index]~, in case that index number is out of range.
#+begin_src rust
let password = password.chars().collect::<Vec<char>>();
	
if password.get(index_1) == password.get(index_2) {
    continue;
}
#+end_src

~anyhow~ error handling.

#+begin_src rust
let caps = re.captures(&line).ok_or(anyhow!("parse line"))?;
#+end_src

~char~ counting.

#+begin_src rust
let num_valid_char = password.chars().filter(|c| *c == valid_char).count();
#+end_src

*** Day1

[[https://adventofcode.com/2020/day/1][Day 1: Report Repair]]

- Source code: https://github.com/Aimeedeer/adventofcode-2020/tree/master/day1
- Question: a better performance solution than 3 loops?
- [[https://fasterthanli.me/series/advent-of-code-2020/part-1][Other one's practice]]. Good to learn another totally different approach.
His code:
#+begin_src rust
use itertools::Itertools;

fn main() -> anyhow::Result<()> {
    let (a, b, c) = include_str!("input.txt")
        .split('\n')
        .map(str::parse::<i64>)
        .collect::<Result<Vec<_>, _>>()?
        .into_iter()
        .tuple_combinations()
        .find(|(a, b, c)| a + b + c == 2020)
        .expect("no tuple of length 3 had a sum of 2020");

    dbg!(a + b + c);
    dbg!(a * b * c);

    Ok(())
}
#+end_src

From Rust std: [[https://doc.rust-lang.org/std/iter/trait.Iterator.html#method.map][std/iter/trait.Iterator]]
> ~map()~ is conceptually similar to a ~for~ loop. 
However, as ~map()~ is lazy, it is best used when you're already working 
with other iterators. If you're doing some sort of looping 
for a side effect, it's considered more idiomatic to use ~for~ than ~map()~.

[[https://docs.rs/itertools/0.9.0/itertools/trait.Itertools.html#method.tuple_combinations][tuple_combinations]]


** Captain Game                                 :rust:smartcontract:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: captain-game
:EXPORT_DATE: 2020-12-27
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: A captain game smart contract
:EXPORT_OPTIONS: toc:2
:END:

Captain game with Parity ink.

*** My hacklog

**** 2021-02-13

Test with submit_level and run_level + level_up after run_level succeed:

#+begin_src shell
2021-02-13 12:26:36.009  DEBUG tokio-runtime-worker runtime:game account: PlayerAccount { level: 1, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230]), 1: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-13 12:26:36.010  DEBUG tokio-runtime-worker runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-13 12:26:36.011  DEBUG tokio-runtime-worker runtime:dispatch level: 1, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-13 12:26:36.012  DEBUG tokio-runtime-worker runtime:run_level_1_flipper, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-13 12:26:36.012  DEBUG tokio-runtime-worker runtime:get method call success    
2021-02-13 12:26:36.012  DEBUG tokio-runtime-worker runtime:get return value true    
2021-02-13 12:26:36.012  DEBUG tokio-runtime-worker runtime:verified flipper current state    
2021-02-13 12:26:36.013  DEBUG tokio-runtime-worker runtime:get method call success    
2021-02-13 12:26:36.013  DEBUG tokio-runtime-worker runtime:get return value false    
2021-02-13 12:26:36.013  DEBUG tokio-runtime-worker runtime:verify flipper new state    
2021-02-13 12:26:36.014  DEBUG tokio-runtime-worker runtime:run_level_1_flipper call success    
2021-02-13 12:26:36.015  DEBUG tokio-runtime-worker runtime:player_account: PlayerAccount { level: 2, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230]), 1: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
#+end_src


**** 2021-02-06

First log:

#+begin_src shell
$ canvas --dev --tmp -lerror,runtime=debug


# Bob creates a player account

2021-02-06 13:21:47.719  DEBUG event.loop0 runtime:new player account PlayerAccount { level: 0, level_contracts: {} }    
2021-02-06 13:21:54.009  DEBUG tokio-runtime-worker runtime:new player account PlayerAccount { level: 0, level_contracts: {} }    


# Bob submits a level_program

2021-02-06 13:22:12.498  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-06 13:22:12.521  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-06 13:22:12.529  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-06 13:22:12.539  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([142, 175, 4, 21, 22, 135, 115, 99, 38, 201, 254, 161, 126, 37, 252, 82, 135, 97, 54, 147, 201, 18, 144, 156, 178, 38, 170, 71, 148, 242, 106, 72])    
2021-02-06 13:22:17.161  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:22:24.007  DEBUG tokio-runtime-worker runtime:insert level 0, and contract AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    


# choose "run_level" method from the dropdown list

2021-02-06 13:22:42.891  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-06 13:22:42.892  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:22:42.893  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:22:42.893  DEBUG          event.loop0 runtime:contract selector: [222, 173, 190, 239]    
2021-02-06 13:22:42.895  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    
2021-02-06 13:22:42.902  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-06 13:22:42.903  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:22:42.905  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:22:42.905  DEBUG          event.loop0 runtime:contract selector: [222, 173, 190, 239]    
2021-02-06 13:22:42.906  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    


# click "Call" button

2021-02-06 13:23:06.012  DEBUG tokio-runtime-worker runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-06 13:23:06.013  DEBUG tokio-runtime-worker runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:23:06.014  DEBUG tokio-runtime-worker runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-06 13:23:06.015  DEBUG tokio-runtime-worker runtime:contract selector: [222, 173, 190, 239]    
2021-02-06 13:23:06.015  DEBUG tokio-runtime-worker runtime:get method call failed: Decode(Error)    
#+end_src

I have wasted so much time only because I didn't pay attention to
the two selectors and the different method return values.
Cross contract call works finally after I corrected the selector.

I add more prints for verification in the ~run_level~ method,
and create run_level_0, run_level_1, and more levels.
Each one uses the same flipper contract for testing.

**** 2021-02-04

Is this a network problem?

#+begin_src shell
contracts.call
1014: Priority is too low: (133148198758 vs 133148198758): The transaction has too low priority to replace another transaction already in the pool.
#+end_src

Again, this time, our demo doesn't work:

#+begin_src shell
2021-02-04 11:44:06.057  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 11:44:06.058  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:06.059  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:06.060  DEBUG          event.loop0 runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 11:44:06.061  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    
2021-02-04 11:44:06.069  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 11:44:06.070  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:06.072  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:06.072  DEBUG          event.loop0 runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 11:44:06.073  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    
2021-02-04 11:44:18.011  DEBUG tokio-runtime-worker runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 11:44:18.013  DEBUG tokio-runtime-worker runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:18.014  DEBUG tokio-runtime-worker runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 11:44:18.015  DEBUG tokio-runtime-worker runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 11:44:18.015  DEBUG tokio-runtime-worker runtime:get method call failed: Decode(Error)    
#+end_src

Why it prints three rounds of debug messages?

I go back to our previous sample test, and it doesn't work either:

#+begin_src shell
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:DispatchError    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:8    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:6    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:OutOfGas    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:PostInfo:     
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:actual_weight=    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:6113641282    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:pays_fee=    
2021-02-04 11:47:18.005  DEBUG tokio-runtime-worker runtime:Yes    
#+end_src

I change the sample code and remove
~.gas_limit(0)~ and ~.transferred_value(0)~, 
then it works! 
I don't understand.

#+begin_src shell
2021-02-04 11:59:12.124  DEBUG          event.loop0 runtime:calling get on AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-04 11:59:12.124  DEBUG          event.loop0 runtime:return value Err(NotCallable)    
2021-02-04 11:59:12.130  DEBUG          event.loop0 runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-04 11:59:12.132  DEBUG          event.loop0 runtime:return value Ok(false)    
2021-02-04 11:59:14.451  DEBUG          event.loop0 runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-04 11:59:14.451  DEBUG          event.loop0 runtime:return value Ok(false)    
2021-02-04 11:59:30.002  DEBUG tokio-runtime-worker runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-04 11:59:30.003  DEBUG tokio-runtime-worker runtime:return value Ok(false)    
2021-02-04 11:59:36.004  DEBUG tokio-runtime-worker runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-04 11:59:36.005  DEBUG tokio-runtime-worker runtime:return value Ok(false)    
#+end_src

Now I am going to test the game contract *again*.
~run_level~ call prints debug messages: 

#+begin_src shell
# call submit_level method

2021-02-04 12:03:53.456  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-04 12:03:53.483  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-04 12:03:53.490  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])    
2021-02-04 12:03:53.495  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([142, 175, 4, 21, 22, 135, 115, 99, 38, 201, 254, 161, 126, 37, 252, 82, 135, 97, 54, 147, 201, 18, 144, 156, 178, 38, 170, 71, 148, 242, 106, 72])    
2021-02-04 12:04:21.854  DEBUG          event.loop0 runtime:insert level 0, and contract AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:04:36.010  DEBUG tokio-runtime-worker runtime:insert level 0, and contract AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230]) 


# choose run_level method from Canvas UI

2021-02-04 12:06:35.054  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 12:06:35.055  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:06:35.056  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:06:35.056  DEBUG          event.loop0 runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 12:06:35.057  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    
2021-02-04 12:06:35.065  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 12:06:35.066  DEBUG          event.loop0 runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:06:35.067  DEBUG          event.loop0 runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:06:35.067  DEBUG          event.loop0 runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 12:06:35.068  DEBUG          event.loop0 runtime:get method call failed: Decode(Error)    


# click call button and sign it

2021-02-04 12:07:18.008  DEBUG tokio-runtime-worker runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])} }    
2021-02-04 12:07:18.009  DEBUG tokio-runtime-worker runtime:program id: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:07:18.011  DEBUG tokio-runtime-worker runtime:dispatch level: 0, calling contract: AccountId([154, 109, 9, 43, 214, 19, 68, 75, 177, 212, 196, 5, 184, 224, 248, 107, 32, 56, 240, 228, 240, 158, 222, 41, 53, 1, 138, 195, 219, 58, 141, 230])    
2021-02-04 12:07:18.011  DEBUG tokio-runtime-worker runtime:contract selector: Selector { bytes: [222, 173, 190, 239] }    
2021-02-04 12:07:18.012  DEBUG tokio-runtime-worker runtime:get method call failed: Decode(Error)   
#+end_src

Seems there is something wrong with my changed code.

**** 2021-02-03

Ink team seems to plan to implement trait for  cross-contract calls:
[[https://github.com/paritytech/ink/issues/631][[Feature] Dynamic trait based contract calling #631]].
We currently use hard-coded code in method attributes, called ~Selector~.

While our game contract needs to allow players upload their programs for 
each multiple level challenges, I plan to use multiple ~Selector~s for 
different programs.
I changed the code a bit:

#+begin_src rust
let selector;
match level {
    0 => selector = Selector::new([0xDE, 0xAD, 0xBE, 0xEF]),
    1 => selector = Selector::new([0xDE, 0xAD, 0xEE, 0xEE]),
    _ => unreachable!(),
}
#+end_src

Call method failed, and I don't know what's wrong from the error message.
I'll run the previous game-test example again later.


**** 2021-02-01

After about two weeks without working on it,
I need to restore my previous log in my memory to start with.

I build my Game contract and Example-levels contract respectively: ~cargo contract build~,
and run a Substrate node: ~canvas --dev --tmp -lerror,runtime=debug~,
then visit Canvas from browser: https://paritytech.github.io/canvas-ui/#/upload

Test process from Canvas:
- Alice deploys Game contract
- Bob deploys Flipper(Example-levels) contract
- Bob call Alice's Game contract
  - RPC call: have_player_account
    - return false
  - Tx call: creat_player_account
  - RPC call: have_player_account 
    - return true
  - RPC call: get_player_account (Error below)
#+begin_src shell
Uncaught error. Something went wrong with the query and rendering of this component. createType(Result):: Cannot construct unknown type Result
#+end_src
  - Tx call: submit_level
  - Tx call: run_level
#+begin_src shell
contracts.call
inblock

system.ExtrinsicSuccess
extrinsic event
#+end_src

We print a lot of activities in our code:

#+begin_src rust
ink_env::debug_println(&format!("print_some_thing {:?}", print_content));~
#+end_src

The node terminal prints below.
I don't know why it prints three times.

#+begin_src shell
2021-02-01 11:26:05.699  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])} }    
2021-02-01 11:26:05.700  DEBUG          event.loop0 runtime:program id: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.701  DEBUG          event.loop0 runtime:dispatch level: calling flip on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.703  DEBUG          event.loop0 runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.704  DEBUG          event.loop0 runtime:get method call success    
2021-02-01 11:26:05.704  DEBUG          event.loop0 runtime:get return value true    
2021-02-01 11:26:05.712  DEBUG          event.loop0 runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])} }    
2021-02-01 11:26:05.713  DEBUG          event.loop0 runtime:program id: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.714  DEBUG          event.loop0 runtime:dispatch level: calling flip on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.716  DEBUG          event.loop0 runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:05.717  DEBUG          event.loop0 runtime:get method call success    
2021-02-01 11:26:05.717  DEBUG          event.loop0 runtime:get return value true    
2021-02-01 11:26:18.012  DEBUG tokio-runtime-worker runtime:game account: PlayerAccount { level: 0, level_contracts: {0: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])} }    
2021-02-01 11:26:18.013  DEBUG tokio-runtime-worker runtime:program id: AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:18.014  DEBUG tokio-runtime-worker runtime:dispatch level: calling flip on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:18.016  DEBUG tokio-runtime-worker runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-02-01 11:26:18.016  DEBUG tokio-runtime-worker runtime:get method call success    
2021-02-01 11:26:18.016  DEBUG tokio-runtime-worker runtime:get return value true    
#+end_src


**** 2021-01-18

It works today, for no reason. 
[[https://github.com/Aimeedeer/game-test][Testing source code]].

#+begin_src shell
2021-01-18 17:21:12.010  DEBUG tokio-runtime-worker runtime:calling get on AccountId([143, 23, 140, 104, 129, 87, 181, 199, 82, 222, 77, 198, 172, 231, 178, 249, 251, 156, 129, 233, 134, 167, 114, 60, 101, 73, 245, 85, 139, 84, 27, 156])    
2021-01-18 17:21:12.010  DEBUG tokio-runtime-worker runtime:return value Ok(false)    
#+end_src

**** 2021-01-16

Create isolated environment for testing.
[[https://github.com/Aimeedeer/game-test][Source code]].

**** 2021-01-14

Debug ~contract trapped~ 

#+begin_src shell
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:DispatchError    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:8    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:17    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:ContractTrapped    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:PostInfo:     
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:actual_weight=    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:7172485790    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:pays_fee=    
2021-01-14 16:34:36.014  DEBUG tokio-runtime-worker runtime:Yes    
#+end_src

Found ~DispatchError~ from Substrate code:

#+begin_src rust
/// Turn this GasMeter into a DispatchResult that contains the actually used gas.
pub fn into_dispatch_result<R, E>(self, result: Result<R, E>) -> DispatchResultWithPostInfo
where
        E: Into<ExecError>,
{
        let post_info = PostDispatchInfo {
                actual_weight: Some(self.gas_spent()),
                pays_fee: Default::default(),
        };

        result
                .map(|_| post_info)
                .map_err(|e| DispatchErrorWithPostInfo { post_info, error: e.into().error })
}
#+end_src

**** 2021-01-07

Test code: 

#+begin_src rust
#[ink(message, payable)]
pub fn run_level_test(&mut self) -> bool {
    let program_id = "4cfac7f74c6233449b5e54ba070231dd94c71b89505482cd910000656258d3ed";

    ink_env::debug_println(&format!("hash {:?}", program_id));

    let program_id = hex::decode(program_id).unwrap();
    ink_env::debug_println(&format!("decode {:?}", program_id));

    let program_id = AccountId::try_from(&program_id[..]).unwrap();
    ink_env::debug_println(&format!("AccountId {:?}", program_id));

    true
}
#+end_src

Run Canvas and print ~debug~ in console:

#+begin_src shell
$ canvas --dev --tmp -lerror,runtime=debug

2021-01-07 20:47:37.878  DEBUG event.loop0 runtime:hash "4cfac7f74c6233449b5e54ba070231dd94c71b89505482cd910000656258d3ed"    
2021-01-07 20:47:37.880  DEBUG event.loop0 runtime:decode [76, 250, 199, 247, 76, 98, 51, 68, 155, 94, 84, 186, 7, 2, 49, 221, 148, 199, 27, 137, 80, 84, 130, 205, 145, 0, 0, 101, 98, 88, 211, 237]    
2021-01-07 20:47:37.881  DEBUG event.loop0 runtime:AccountId AccountId([76, 250, 199, 247, 76, 98, 51, 68, 155, 94, 84, 186, 7, 2, 49, 221, 148, 199, 27, 137, 80, 84, 130, 205, 145, 0, 0, 101, 98, 88, 211, 237])    
#+end_src

Test process:
- Run Canvas in Firefox
- Bob uploads Flipper contract (added ~selector~)
- Add deployed Flipper contract address to Game contract test code, and build ~cargo contract build~
- Deploy Game contract with Alice's account
- Bob calls Alice's Game contract

**** 2021-01-03

Write code for cross-contract call.

**** 2021-01-01

In ink, ~clone~ can't be derived for nested ~HashMap~ type.
We use ~BTreeMap~ instead.

#+begin_src rust
use ink_storage::collections::HashMap;

pub struct Game {
    game_accounts: HashMap<AccountId, GameAccount>,
}

pub struct GameAccount {
    level: u32,
    level_programs: BTreeMap<u32, AccountId>,
}
#+end_src

**** 2020-12-31

We can't use ~String~ directly.

#+begin_src shell
   Compiling game v0.1.0 (/private/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/cargo-contract_GdJJAl)
error[E0412]: cannot find type `String` in this scope
  --> /Users/aimeez/github/contract-game/src/game/lib.rs:49:51
   |
49 |     pub fn create_game_account(&mut self, role_name: String) -> Result<(), Error> {
   |                                                      ^^^^^^ not found in this scope

error: aborting due to previous error
#+end_src

We need ~alloc~ here.

#+begin_src rust
extern crate alloc;

#[ink::contract]
mod game {
    use ink_storage::collections::HashMap;
    use alloc::{string::String, format};
    ...
}
#+end_src


**** 2020-12-29

Added ~HashMap~, and it looks complicated.

#+begin_src rust
use ink_storage::collections::HashMap;

#[ink(storage)]
pub struct Game {
    game_accounts: HashMap<AccountId, GameAccount>,
}

#[derive(Debug, scale::Encode, scale::Decode, ink_storage_derive::PackedLayout, ink_storage_derive::SpreadLayout)]
#[cfg_attr(feature = "std", derive(scale_info::TypeInfo))] 
pub struct GameAccount {
    game_account_id: [u32; 8],
    level: u32,
}
#+end_src

**** 2020-12-27

Use ~ink!~ to create a contract template in our project (currently private).

#+begin_src shell
$ cargo contract check --manifest-path src/game/Cargo.toml
#+end_src

** Walnuts Hacklog                     :rust:blockchain:walnuts:log:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: walnuts
:EXPORT_DATE: 2020-11-02
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: My hacklog for Walnuts, a toy blockchain.
:EXPORT_OPTIONS: toc:2
:END:

[[https://github.com/Aimeedeer/walnuts][Walnuts source code]]

*** TODO
- [x] sha2 for hash function
- [x] chrono for UTC time as timestamp
- [x] serde for storage, write & read to a file on disc
- [x] cli
- [x] create a new block from commandline, 
      and save it in a json file
- [x] change read & write to serde <> io: 
      https://docs.rs/serde_json/1.0.59/serde_json/fn.from_reader.html
- [x] deal with unwrap() -> Result
- [ ] create transactions from commandline
- [ ] 256k for tx signature: https://docs.rs/k256/0.5.10/k256/
- [ ] nouce verify
- [ ] keep mining
- [ ] clean code
    
*** Hacklog

**** 2020-11-21

Error handling progress:

#+begin_src rust
    pub fn load() -> Result<Self> {
	let file = File::open("walnutsdata.json");
	match file {
	    Ok(file) => { 
		Ok(serde_json::from_reader(&file)?)
	    },
	    Err(e) => {
		if e.kind() == ErrorKind::NotFound {
		    Ok(Blockchain::new())
		} else {		 
		    Err(Error::from(e))
		}
	    }	    
	}

    }

    fn new() -> Self {
	Blockchain { blocks: Vec::new() }
    }

#+end_src

Rust doc:
[[https://doc.rust-lang.org/std/io/enum.ErrorKind.html][Enum std::io::ErrorKind]]

**** 2020-11-20

[[https://docs.rs/serde_json/1.0.59/serde_json/index.html][Crate serde_json]]

A worth reading issue:
[[https://github.com/serde-rs/json/issues/160][Parsing 20MB file using from_reader is slow #160]]

Changes in blockchain.rs: ~unwrap()~ -> ~?~
#+begin_src rust
    pub fn updateblockchain(block: Block) -> Result<()> {
	let f = File::create("walnutsdata.json")?;
	let blockdata = serde_json::ser::to_writer_pretty(f, &block)?;
	println!("write to walnutsdata.json");

	let data = std::fs::read_to_string("walnutsdata.json")?;
	let deserialized: Block = serde_json::from_str(&data)?;
	println!("deserialized data from walnutsdata.json: {:?}", deserialized);
	Ok(())
    }
#+end_src

The output:
#+begin_src shell
$ cargo run -- mine
    Finished dev [unoptimized + debuginfo] target(s) in 1.55s
     Running `target/debug/walnuts mine`
Opt {
    cmd: Mine,
}
write to walnutsdata.json
deserialized data from walnutsdata.json: Block { header: BlockHeader { prev_block_hash: [166, 5, 88, 255, 235, 6, 147, 45, 180, 203, 105, 29, 131, 4, 186, 246, 69, 115, 54, 230, 65, 190, 65, 172, 108, 106, 33, 220, 51, 45, 68, 150], time: 1605002954274, nonce: 1 }, txs: [] }
check mine funtion: Ok(())
#+end_src

I didn't finish implementing ~anyhow::Result~ error handling today.

**** 2020-11-16

- Created a new block (Mine) from commandline, 
  and saved it to walnutsdata.json
- Learned: always thinking in type system

Test the sample code from [[https://serde.rs/][serde.rs]] 
in my blockchain.rs code:

#+begin_src rust
let serialized = serde_json::to_string(&block).unwrap();
println!("serialized = {}", serialized);

let deserialized: Block = serde_json::from_str(&serialized).unwrap();
println!("deserialized = {:?}", deserialized);
#+end_src 

The output:

#+begin_src shell
$ cargo run -- mine

    Finished dev [unoptimized + debuginfo] target(s) in 3.04s
     Running `target/debug/walnuts mine`
Opt {
    cmd: Mine,
}
serialized = {"header":{"prev_block_hash":[166,5,88,255,235,6,147,45,180,203,105,29,131,4,186,246,69,115,54,230,65,190,65,172,108,106,33,220,51,45,68,150],"time":1605002954274,"nonce":1},"txs":[]}
deserialized = Block { header: BlockHeader { prev_block_hash: [166, 5, 88, 255, 235, 6, 147, 45, 180, 203, 105, 29, 131, 4, 186, 246, 69, 115, 54, 230, 65, 190, 65, 172, 108, 106, 33, 220, 51, 45, 68, 150], time: 1605002954274, nonce: 1 }, txs: [] }
Genesis block is: [166, 5, 88, 255, 235, 6, 147, 45, 180, 203, 105, 29, 131, 4, 186, 246, 69, 115, 54, 230, 65, 190, 65, 172, 108, 106, 33, 220, 51, 45, 68, 150]
write to walnutsdata.txt
check mine funtion: Ok(())
#+end_src

Read blockchain data from =walnutsdata.txt=

#+begin_src rust
let fout = File::open("walnutsdata.txt")?;
let mut buf_reader = BufReader::new(fout);
let mut reader = String::new();

buf_reader.read_to_string(&mut reader)?;
println!("read from walnutsdata.txt in string: {:?}", &reader);

let deserialized: Block = serde_json::from_str(&reader).unwrap();
println!("deserialized data from walnutsdata.txt: {:?}", deserialized);
#+end_src 

The output of reading data:

#+begin_src shell
$ cargo run -- mine


    Finished dev [unoptimized + debuginfo] target(s) in 1.09s
     Running `target/debug/walnuts mine`
Opt {
    cmd: Mine,
}
write to walnutsdata.txt
read from walnutsdata.txt in string: "{\"header\":{\"prev_block_hash\":[166,5,88,255,235,6,147,45,180,203,105,29,131,4,186,246,69,115,54,230,65,190,65,172,108,106,33,220,51,45,68,150],\"time\":1605002954274,\"nonce\":1},\"txs\":[]}"
deserialized data from walnutsdata.txt: Block { header: BlockHeader { prev_block_hash: [166, 5, 88, 255, 235, 6, 147, 45, 180, 203, 105, 29, 131, 4, 186, 246, 69, 115, 54, 230, 65, 190, 65, 172, 108, 106, 33, 220, 51, 45, 68, 150], time: 1605002954274, nonce: 1 }, txs: [] }
check mine funtion: Ok(())
#+end_src

Change to =serde_json::to_string_pretty=:

#+begin_src rust
let blockdata = serde_json::to_string_pretty(&block).unwrap();

println!("write to walnutsdata.json");

let f = File::create("walnutsdata.json")?;
{
    let mut buffer = BufWriter::new(f);

    buffer.write_all(&blockdata.as_bytes())?;
    buffer.flush()?;
}

let mut fout = File::open("walnutsdata.json")?;

// future consideration: io & os performance
// let mut buf_reader = BufReader::new(fout);

let mut data = String::new();
fout.read_to_string(&mut data)?;

println!("read from walnutsdata.json in string: {}", &data);

let deserialized: Block = serde_json::from_str(&data).unwrap();
println!("deserialized data from walnutsdata.json: {:?}", deserialized);
	
Ok(())

#+end_src

The pretty output:

#+begin_src shell
    Finished dev [unoptimized + debuginfo] target(s) in 1.08s
     Running `target/debug/walnuts mine`
Opt {
    cmd: Mine,
}
write to walnutsdata.json
read from walnutsdata.json in string: {
  "header": {
    "prev_block_hash": [
      166,
      5,
      88,
      255,
      235,
      6,
      147,
      45,
      180,
      203,
      105,
      29,
      131,
      4,
      186,
      246,
      69,
      115,
      54,
      230,
      65,
      190,
      65,
      172,
      108,
      106,
      33,
      220,
      51,
      45,
      68,
      150
    ],
    "time": 1605002954274,
    "nonce": 1
  },
  "txs": []
}
deserialized data from walnutsdata.json: Block { header: BlockHeader { prev_block_hash: [166, 5, 88, 255, 235, 6, 147, 45, 180, 203, 105, 29, 131, 4, 186, 246, 69, 115, 54, 230, 65, 190, 65, 172, 108, 106, 33, 220, 51, 45, 68, 150], time: 1605002954274, nonce: 1 }, txs: [] }
check mine funtion: Ok(())
#+end_src

**** 2020-11-13

- Learned: 
  - cargo clean: clean the target folder
  - cargo run -- mysubcommand == target/walnuts mysubcommand
  - https://rust-cli.github.io/book/tutorial/cli-args.html
- Use structopt as cli in main.rs
  - When I moved the cli related code to cli.rs, there is an error

#+begin_src shell
error[E0599]: no function or associated item named `from_args` found for struct `Opt` in the current scope
  --> src/main.rs:16:25
   |
16 |     let opt = cli::Opt::from_args();
   |                         ^^^^^^^^^ function or associated item not found in `Opt`
   | 
  ::: src/cli.rs:5:1
   |
5  | pub struct Opt {
   | -------------- function or associated item `from_args` not found for this
   |
   = help: items from traits can only be used if the trait is in scope
help: the following trait is implemented but not in scope; perhaps add a `use` for it:
   |
1  | use structopt::StructOpt;
   |

error: aborting due to previous error

For more information about this error, try `rustc --explain E0599`.
#+end_src

Then I added this piece to previous main.rs, and it built.

#+begin_src rust
use structopt::StructOpt;
#+end_src

**** 2020-11-12

- Cargo check / cargo build
- =std::io= to deal with files
- cli
  - clap
  - structopt: https://docs.rs/structopt/0.3.20/structopt/
    - https://rust-cli.github.io/book/tutorial/cli-args.html

**** 2020-11-11

- Use Tony's =secp256k1= library
- Serde

About serde derive:

#+begin_src shell
error: cannot find derive macro `Serialize` in this scope
 --> src/block.rs:6:10
  |
6 | #[derive(Serialize, Deserialize, Debug)]
  |          ^^^^^^^^^

error: cannot find derive macro `Deserialize` in this scope
#+end_src

Then add feature in Cargo.toml

#+begin_src rust
serde = { version = "1.0.117", features = ["derive"] }
#+end_src

The doc explains:
[[https://serde.rs/derive.html][Using derive]]

**** 2020-11-10

- [[https://docs.rs/chrono/0.4.19/chrono/struct.DateTime.html][Rust: chrono]] for UTC time
- Read: [[https://betweentwocommits.com/blog/how-bitcoin-timestamping-works][How Bitcoin Timestamping Works]] 
>Bitcoin timestamping does not guarantee an exact time. 
Bitcoin miners are calibrated to create blocks approximately 
every ten minutes. 
However, because of the way their protocol works, 
this is only an average. It could be two minutes, or fifteen. 
This means that the time given by a timestamp is 
only precise to within a range of a few hours. 
For most use cases, this is not an issue, 
since getting the date right is more important than 
the minute or second.

>I should mention that the act of inserting non-transactional data 
in the blockchain is a disputed practice. 
As I mentioned earlier, 
the blockchain is now approximately 300 GB, 
and it can only get bigger. Some people believe that 
adding data not directly related to Bitcoin's true purpose - 
managing transactions - needlessly bloats the size of the blockchain, 
and should not be allowed. 
I am in favour of reducing bloat (including 
a restriction now in the protocol to limit the size of the data 
you can insert), but I think that timestamping is an acceptable 
"secondary purpose" for Bitcoin, which opens the door to 
a lot of potential applications, and which promotes 
the use of Bitcoin.

>The easiest application of Bitcoin timestamps 
is a program called opentimestamps, created by Peter Todd himself. 

**** 2020-11-08

- First build
- main: Read =block.hash()=

**** 2020-11-03 

Creat mod
- block.rs
- blockchain.rs
- blockheader.rs
- transaction.rs
- lib.rs

Use hash crate: https://docs.rs/sha2/0.5.2/sha2/
for generating block's hash string.

Some other hash functions written in Rust:
https://github.com/RustCrypto/hashes

**** 2020-11-02 

- Created Walnuts: my toy blockchain in Rust
** Project: The Big Announcement  :substrate:ethereum:smartcontract:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: bigannouncement
:EXPORT_DATE: 2020-12-07
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: A tiny smart contract.
:EXPORT_OPTIONS: toc:2
:END:

*** Project intro and status

The Big Announcement project on different chains.

TODO:
- [ ] TBA on Substrate (WIP)
- [ ] TBA on Solana (WIP)
- [ ] TBA on NEAR
- [ ] TBA on Nervos
- [ ] TBA on Aleo
- [ ] TBA on Concordium

*** TBA on Ethereum

- Source code: [[https://github.com/Aimeedeer/bigannouncement][bigannouncement.eth]]
  - [[https://github.com/Aimeedeer/bigannouncement/blob/master/contracts/BigAnnouncement.sol][Solidity contract]]
- Ethereum [[https://github.com/Aimeedeer/bigannouncement/blob/master/doc/hacklog.md][Hacklog]]

*** TBA on Substrate

**** Ink code

[[https://github.com/Aimeedeer/tba-substrate][tba-substrate]]

**** Substrate Hacklog

***** Contract naming

#+begin_src shell
$ cargo contract new bigannouncement-substrate
ERROR: Contract names cannot contain hyphens
#+end_src

New name: tbaSubstrate ;)

#+begin_src shell
$ cargo contract new tbaSubstrate
	Created contract tbaSubstrate
#+end_src

But Rust seems doesn't like it:

#+begin_src shell
warning: crate `tbaSubstrate` should have a snake case name
  |
  = note: `#[warn(non_snake_case)]` on by default
  = help: convert the identifier to snake case: `tba_substrate`
#+end_src 

My mood is just like this post: [[https://fasterthanli.me/articles/frustrated-its-not-you-its-rust][Frustrated? It's not you, it's Rust]]

***** Failed of using ~ink_prelude~

I use ~cargo add ink_prelude~, and it shows in the ~Cargo.toml~ as 

#+begin_src rust
ink_prelude = "0.0.0"
#+end_src

But the [[https://github.com/paritytech/ink/commit/75d3b99c3b86398acaef74b84e441da79a88c53f][newest released version]] is different, and I change it to 

#+begin_src rust
ink_prelude = "3.0.0-rc2"
#+end_src

Then build it, and there is a new error:

#+begin_src shell
$ cargo +nightly contract build
 [1/3] Building cargo project
   Compiling ink_prelude v3.0.0-rc2
   Compiling ink_primitives v3.0.0-rc2
error[E0463]: can't find crate for `std`
  |
  = note: the `wasm32-unknown-unknown` target may not be installed

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `ink_prelude`
#+end_src

Keep trying:

#+begin_src shell
$ rustup install nightly-2020-10-06
info: syncing channel updates for 'nightly-2020-10-06-x86_64-apple-darwin'
info: latest update on 2020-10-06, rust version 1.49.0-nightly (a1dfd2490 2020-10-05)
...

$ rustup target add wasm32-unknown-unknown --toolchain nightly-2020-10-06
info: downloading component 'rust-std' for 'wasm32-unknown-unknown'
info: installing component 'rust-std' for 'wasm32-unknown-unknown'
info: using up to 500.0 MiB of RAM to unpack components
Aimees-MacBook-Pro:tbaSubstrate aimeez$ cargo +nightly-2020-10-06 build --release

...

warning: unused imports: `format`, `string`
 --> lib.rs:4:19
  |
4 | use ink_prelude::{format, string};
  |                   ^^^^^^  ^^^^^^
  |
  = note: `#[warn(unused_imports)]` on by default

warning: 1 warning emitted

    Finished release [optimized] target(s) in 1m 24s

$ cargo contract build && cargo contract generate-metadata
 [1/3] Building cargo project
   Compiling ink_prelude v3.0.0-rc2
error[E0463]: can't find crate for `std`
  |
  = note: the `wasm32-unknown-unknown` target may not be installed

error: aborting due to previous error

For more information about this error, try `rustc --explain E0463`.
error: could not compile `ink_prelude`
#+end_src

At last, I use ~alloc~ instead of ~ink_prelude~:

#+begin_src rust
use alloc::{string::String, format};
#+end_src

It built.

***** Deploy failed:

#+begin_src shell
system.ExtrinsicFailed
#+end_src

***** Run Rust test command

#+begin_src shell
$ cargo +nightly test -- new_works # test new an instance
#+end_src

#+begin_src shell
$ RUST_BACKTRACE=1 cargo +nightly test -- new_works
#+end_src

***** Debug_println

#+begin_src rust
let message = String::from("Initialize the Big Announcement contract");
ink_env::debug_println(&format!("thanks for instantiation {:?}, and price {}", &message, price));
#+end_src

#+begin_src shell
$ cargo +nightly test -- --nocapture

    Finished test [unoptimized + debuginfo] target(s) in 0.08s
     Running target/debug/deps/tba_substrate-6d0825befe66c5c8

running 2 tests
thanks for instantiation "Initialize the Big Announcement contract", and price 340282366920938463463374607431768211455
thanks for instantiation "Initialize the Big Announcement contract", and price 1
Thanks for posting the message "new message"
test tba_substrate::tests::new_works ... ok
test tba_substrate::tests::set_works ... ok

test result: ok. 2 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out
#+end_src

#+begin_src shell
$ cargo +nightly test -- --nocapture set_works
#+end_src

***** Test ink's example: contract-transfer

#+begin_src rust
#[ink::test]
fn transfer_works() {
    // given
    let contract_balance = 100;
    let accounts = default_accounts();
    let mut give_me = create_contract(contract_balance);

    println!("alice: {}", get_balance(accounts.alice));
    // when
    set_sender(accounts.eve);
    set_balance(accounts.eve, 0);
    println!("eve: {}", get_balance(accounts.eve));
    assert_eq!(give_me.give_me(80), Ok(()));

    println!("eve after: {}", get_balance(accounts.eve));
    println!("alice after: {}", get_balance(accounts.alice));

    // then
    assert_eq!(get_balance(accounts.eve), 80);
}
#+end_src

The printing shows that alice's balance didn't change 
while eve's balance changed.

#+begin_src shell
$ cargo +nightly test -- --nocapture transfer_works
running 1 test
alice after: 170141183460469231731687303715884105727
eve: 0
eve after: 80
alice after: 170141183460469231731687303715884105727
test give_me::tests::transfer_works ... ok
#+end_src 


*** TBA on Dfinity

**** Motoko code

[[https://github.com/brson/rust-contract-comparison/tree/master/code/tba-dfinty/tba-motoko][TBA Motoko]]

**** Dfinity Hacklog

Previous log is on [[https://gist.github.com/Aimeedeer/aae0d6759fb04bb30478cbf38d4d46ce][Gist]].

For building TBA, I started with its example [[https://github.com/dfinity/examples/tree/master/motoko/echo][Echo]].
The README.md seems to be out of date -- 
it starts a node ~dfx start~ before creating a project,
while the tutorials, [[https://sdk.dfinity.org/docs/quickstart/local-quickstart.html#start-the-local-network][Start the local network]], need you to start
a node inside a project.
I don't think I would use Echo now.

I'll create a tba folder, and start the node:

#+begin_src shell
$ dfx new tba
Fetching manifest https://sdk.dfinity.org/manifest.json
 Checking for latest dfx version...
You seem to be running an outdated version of dfx.

You are strongly encouraged to upgrade by running 'dfx upgrade'!
Creating new project "tba"...
CREATE       tba/src/tba_assets/assets/sample-asset.txt (24B)...
CREATE       tba/src/tba/main.mo (107B)...
CREATE       tba/dfx.json (454B)...
CREATE       tba/.gitignore (165B)...
 Checking for latest dfx version...
CREATE       tba/src/tba_assets/public/index.js (131B)...
CREATE       tba/package.json (282B)...
CREATE       tba/webpack.config.js (2.15KB)...
 Checking for latest dfx version...
 Installing node dependencies...
 Installing node dependencies...
 Checking for latest dfx version...
 Checking for latest dfx version...

> fsevents@1.2.13 install /<my_path>/tba/node_modules/watchpack-chokidar2/node_modules/fsevents
> node install.js
 Checking for latest dfx version...
 Installing node dependencies...
 Checking for latest dfx version...
 Installing node dependencies...
npm WARN tba_assets@0.1.0 No repository field.
npm WARN tba_assets@0.1.0 No license field.

 Installing node dependencies...

13 packages are looking for funding
  run `npm fund` for details

found 1 high severity vulnerability
  Done.
 Checking for latest dfx version...

===============================================================================
        Welcome to the internet computer developer community!
                        You're using dfx 0.6.20

                                   
                        
                
          
                        
                              
                                    
                                      
                                  
                           
                 
              
                      
                              
                                           
     


To learn more before you start coding, see the documentation available online:

- Quick Start: https://sdk.dfinity.org/docs/quickstart/quickstart-intro.html
- SDK Developer Tools: https://sdk.dfinity.org/docs/developers-guide/sdk-guide.html
- Motoko Language Guide: https://sdk.dfinity.org/docs/language-guide/motoko.html
- Motoko Quick Reference: https://sdk.dfinity.org/docs/language-guide/language-manual.html

If you want to work on programs right away, try the following commands to get started:

    cd tba
    dfx help
    dfx new --help

===============================================================================
#+end_src

By the way, I follow the suggestion to upgrade my ~dfx~, 
and it seems it doesn't do anything useful:

#+begin_src shell 
$ dfx upgrade
Current version: 0.6.20
Fetching manifest https://sdk.dfinity.org/manifest.json
Already up to date

$ dfx --version
dfx 0.6.20
#+end_src

I start another terminal window for the node:

#+begin_src shell
$ dfx start
Jan 27 16:01:01.798 INFO ic-starter. Configuration: ValidatedConfig { replica_path: Some("/Users/aimeez/.cache/dfinity/versions/0.6.20/replica"), replica_version: "0.1.0", log_level: Warning, subnet_id: fscpm-uiaaa-aaaaa-aaaap-yai, cargo_bin: "cargo", cargo_opts: "", state_dir: "/<my_path>/tba/.dfx/state/replicated_state", http_listen_addr: V4(127.0.0.1:0), http_port_file: Some("/<my_path>/tba/.dfx/replica-configuration/replica-1.port"), metrics_addr: None, hypervisor_create_funds_whitelist: "*", artifact_pool_dir: "/<my_path>/tba/.dfx/state/replicated_state/node-100/ic_consensus_pool", crypto_root: "/<my_path>/tba/.dfx/state/replicated_state/node-100/crypto", state_manager_root: "/<my_path>/tba/.dfx/state/replicated_state/node-100/state", registry_file: "/<my_path>/tba/.dfx/state/replicated_state/registry.proto", bootstrap_registry: None, state_dir_holder: None }, Application: starter
Jan 27 16:01:01.799 INFO Initialize replica configuration "/<my_path>/tba/.dfx/state/replicated_state/ic.json5", Application: starter
Jan 27 16:01:01.816 INFO Executing "/Users/aimeez/.cache/dfinity/versions/0.6.20/replica" "--replica-version" "0.1.0" "--config-file" "/<my_path>/tba/.dfx/state/replicated_state/ic.json5", Application: starter
Jan 27 16:01:06.664 ERRO s:fscpm-uiaaa-aaaaa-aaaap-yai/n:owpmo-ykels-vijqd-6ql2q-gklnb-6oii4-2zkce-54jdn-vt7ob-hrn7h-hae/ic_messaging/xnet_endpoint No XNet configuration for node owpmo-ykels-vijqd-6ql2q-gklnb-6oii4-2zkce-54jdn-vt7ob-hrn7h-hae. This is an error in production, but may be ignored in single-subnet test deployments.
Jan 27 16:01:07.671 WARN s:fscpm-uiaaa-aaaaa-aaaap-yai/n:owpmo-ykels-vijqd-6ql2q-gklnb-6oii4-2zkce-54jdn-vt7ob-hrn7h-hae/ic_http_handler/ic_http_handler NNS subnet not found in network topology. Skipping fetching the delegation.
Starting webserver on port 61644 for replica at "http://localhost:61644"
binding to: V4(127.0.0.1:8000)
replica(s): http://localhost:61644/
#+end_src

I go back to the first terminal window and deploy (before ~build~ that I usually do) it.
Now there comes an error:

#+begin_src shell
$ dfx deploy
Deploying all canisters.
Creating canisters...
Creating canister "tba"...
"tba" canister created with canister id: "rwlgt-iiaaa-aaaaa-aaaaa-cai"
Creating canister "tba_assets"...
"tba_assets" canister created with canister id: "rrkah-fqaaa-aaaaa-aaaaq-cai"
Building canisters...
Building frontend...
The post-build step failed for canister 'rrkah-fqaaa-aaaaa-aaaaq-cai' with an embedded error: The command '"npm" "run" "build"' failed with exit status 'exit code: 1'.
Stdout:

> tba_assets@0.1.0 build /<my_path>/tba
> webpack


Stderr:
/<my_path>/tba/node_modules/terser-webpack-plugin/dist/index.js:572
      const hooks = compiler.webpack.javascript.JavascriptModulesPlugin.getCompilationHooks(compilation);
                                     ^

TypeError: Cannot read property 'javascript' of undefined
    at compiler.hooks.compilation.tap.compilation (/<my_path>/tba/node_modules/terser-webpack-plugin/dist/index.js:572:38)
    at SyncHook.eval [as call] (eval at create (/<my_path>/tba/node_modules/tapable/lib/HookCodeFactory.js:19:10), <anonymous>:85:1)
    at SyncHook.lazyCompileHook (/<my_path>/tba/node_modules/tapable/lib/Hook.js:154:20)
    at Compiler.newCompilation (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:631:26)
    at hooks.beforeCompile.callAsync.err (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:667:29)
    at AsyncSeriesHook.eval [as callAsync] (eval at create (/<my_path>/tba/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:6:1)
    at AsyncSeriesHook.lazyCompileHook (/<my_path>/tba/node_modules/tapable/lib/Hook.js:154:20)
    at Compiler.compile (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:662:28)
    at readRecords.err (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:321:11)
    at Compiler.readRecords (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:529:11)
    at hooks.run.callAsync.err (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:318:10)
    at AsyncSeriesHook.eval [as callAsync] (eval at create (/<my_path>/tba/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:6:1)
    at AsyncSeriesHook.lazyCompileHook (/<my_path>/tba/node_modules/tapable/lib/Hook.js:154:20)
    at hooks.beforeRun.callAsync.err (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:315:19)
    at AsyncSeriesHook.eval [as callAsync] (eval at create (/<my_path>/tba/node_modules/tapable/lib/HookCodeFactory.js:33:10), <anonymous>:15:1)
    at AsyncSeriesHook.lazyCompileHook (/<my_path>/tba/node_modules/tapable/lib/Hook.js:154:20)
    at Compiler.run (/<my_path>/tba/node_modules/webpack/lib/Compiler.js:312:24)
    at runWithDependencies (/<my_path>/tba/node_modules/webpack/lib/MultiCompiler.js:265:15)
    at asyncLib.map (/<my_path>/tba/node_modules/webpack/lib/MultiCompiler.js:185:6)
    at arrayEachIndex (/<my_path>/tba/node_modules/neo-async/async.js:2548:9)
    at Object.map (/<my_path>/tba/node_modules/neo-async/async.js:2900:9)
    at runCompilers (/<my_path>/tba/node_modules/webpack/lib/MultiCompiler.js:182:13)
    at MultiCompiler.runWithDependencies (/<my_path>/tba/node_modules/webpack/lib/MultiCompiler.js:194:3)
    at MultiCompiler.run (/<my_path>/tba/node_modules/webpack/lib/MultiCompiler.js:261:9)
    at processOptions (/<my_path>/tba/node_modules/webpack-cli/bin/cli.js:353:14)
    at yargs.parse (/<my_path>/tba/node_modules/webpack-cli/bin/cli.js:364:3)
    at Object.parse (/<my_path>/tba/node_modules/yargs/yargs.js:567:18)
    at /<my_path>/tba/node_modules/webpack-cli/bin/cli.js:49:8
    at Object.<anonymous> (/<my_path>/tba/node_modules/webpack-cli/bin/cli.js:366:3)
    at Module._compile (internal/modules/cjs/loader.js:778:30)
npm ERR! code ELIFECYCLE
npm ERR! errno 1
npm ERR! tba_assets@0.1.0 build: `webpack`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the tba_assets@0.1.0 build script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.
#+end_src

I build directly, and still an error:

#+begin_src shell
$ dfx build
Cannot find canister id. Please issue 'dfx canister create tba_assets'.
#+end_src

I don't know what to do with this error while checking back with 
Dfinity's documentation. So I ~rm -rf tba~ and then
use ~dfx new tba~ to re-create tba.
Now it works:

#+begin_src shell
$ dfx deploy
Deploying all canisters.
Creating canisters...
Creating canister "tba"...
"tba" canister created with canister id: "rwlgt-iiaaa-aaaaa-aaaaa-cai"
Creating canister "tba_assets"...
"tba_assets" canister created with canister id: "rrkah-fqaaa-aaaaa-aaaaq-cai"
Building canisters...
Building frontend...
Installing canisters...
Installing code for canister tba, with canister_id rwlgt-iiaaa-aaaaa-aaaaa-cai
Installing code for canister tba_assets, with canister_id rrkah-fqaaa-aaaaa-aaaaq-cai
Deployed canisters.
#+end_src

Test it:

#+begin_src shell
$ dfx build
Building canisters...
Building frontend...

$ dfx canister call tba greet me
("Hello, me!")
#+end_src

My processes are:
- Create new project with ~dfx new <your project>~
- Go into the project folder ~cd <your project>~
- Install npm with ~npm install~
- Open another terminal window, go to the project folder, and run a local node with ~dfx start~
- Go back to previous terminal window, and deploy my project: ~dfx deploy~.
It seems that the deployment operation also builds the project before deploy it.

Now, I am going to write some code (change the default one).
The default code in ~tba/src/tba/main.mo~ is:
#+begin_src js
actor {
    public func greet(name : Text) : async Text {
        return "Hello, " # name # "!";
    };
};
#+end_src

The Motoko seems to be easy to use, its syntax looks strange, though.

My contract code is:

#+begin_src js
actor TBA {
    stable var tba_msg = "The Big Announcement";

    public func set_message(msg : Text) : async Text {
        tba_msg := msg;
        return "Hello, " # tba_msg # "!";
    };

    public func set_message_no_return(msg : Text) {
        tba_msg := msg;        
    };

    public func loading_message() : async Text {
        return tba_msg;
    };
};
#+end_src

Test with command line:

#+begin_src shell
$ dfx canister call tba set_message My_Big_Announcement_Test
("Hello, My_Big_Announcement_Test!")

$ dfx canister call tba set_message_no_return My_Big_Announcement_Test_No_Return
()

$ dfx canister call tba loading_message
("My_Big_Announcement_Test_No_Return")
#+end_src


I have to mention that error messages are not useful.
I try to change some code and build failed. 
The error messages are:

#+begin_src shell
$ dfx build
Building canisters...
Building frontend...
The build step failed for canister 'rwlgt-iiaaa-aaaaa-aaaaa-cai' with an embedded error: The command '"/Users/aimeez/.cache/dfinity/versions/0.6.20/moc" "/<my_path>/tba/src/tba/main.mo" "-o" "/<my_path>/tba/.dfx/local/canisters/tba/tba.did" "--idl" "--actor-idl" "/<my_path>/tba/.dfx/local/canisters/idl/" "--actor-alias" "tba" "rwlgt-iiaaa-aaaaa-aaaaa-cai" "--actor-alias" "tba_assets" "rrkah-fqaaa-aaaaa-aaaaq-cai" "--package" "base" "/Users/aimeez/.cache/dfinity/versions/0.6.20/base"' failed with exit status 'exit code: 1'.
Stdout:

Stderr:
/<my_path>/tba/src/tba/main.mo:4.21-4.25: type error, unbound type Test
#+end_src

I have no clue where to start debugging, or guessing.
Not fun.

**** Using Rust to write TBA

Official tutorials: [[https://sdk.dfinity.org/docs/developers-guide/work-with-languages.html][Using Rust]]

I'm glad I can use Rust command directly to create a project.
But, that's all. 

#+begin_src shell
$ cargo new tba_rust
     Created binary (application) `tba_rust` package
Aimees-MacBook-Pro:dfinity-project aimeez$ cd tba_rust/
Aimees-MacBook-Pro:tba_rust aimeez$ dfx build
Command must be run in a project directory (with a dfx.json file).
Aimees-MacBook-Pro:tba_rust aimeez$ cargo build
   Compiling tba_rust v0.1.0 (/<my_path>/tba_rust)
    Finished dev [unoptimized + debuginfo] target(s) in 3.51s
#+end_src

Then I need to copy ~Cargo.toml~ to another place according the tutorials:

> Projects that run on the Internet Computer typically use 
one project-level ~Cargo.toml~ file to set up a workspace 
for the canister members of the project and a second ~Cargo.toml~ file 
in the source code directory to configure settings for each canister.

After finishing the basic round of configuration, I use ~cargo build~
and there is an error:

#+begin_src shell
$ cargo build
error: failed to read `/<my_path>/tba_rust/src/tba_rust/Cargo.toml`

Caused by:
  No such file or directory (os error 2)
#+end_src

The path is incorrect, and I change it in the root ~Cargo.toml~ file:

#+begin_src rust
[workspace]
members = [
    "src/",
]
#+end_src

~cargo build~ works but ~dfx build~ doesn't work (I have started ~dfx start~ 
in another terminal window). The error is:

#+begin_src shell
$ cargo build
   Compiling tba_rust v0.1.0 (/<my_path>/tba_rust/src)

$ dfx build
Building canisters...
Executing 'cargo build --target wasm32-unknown-unknown --package tba_rust'
   Compiling tba_rust v0.1.0 (/<my_path>/tba_rust/src)
warning: function is never used: `main`
 --> src/main.rs:1:4
  |
1 | fn main() {
  |    ^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: 1 warning emitted

    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
The post-build step failed for canister 'rwlgt-iiaaa-aaaaa-aaaaa-cai' with an embedded error: No such file or directory (os error 2)
#+end_src

However, the config
~members = ["src/",]~
isn't right according to Rust configuration.
I create another folder ~tba_rust~ under ~/<my_path>/tba_rust/src/~,
and move all the files from ~src~ to ~src/tba_rust~.
Then I add ~cdylib~ to my ~/<my_path>/tba_rust/src/Cargo.toml~ file.

#+begin_src rust
[lib]
path = "main.rs"
crate-type = ["cdylib"]
#+end_src

Now both ~cargo build~ and ~dfx build~ work.
The terminal prints: 

#+begin_src shell
$ dfx build
Building canisters...
Executing 'cargo build --target wasm32-unknown-unknown --package tba_rust'
   Compiling tba_rust v0.1.0 (/<my_path>/tba_rust/src/tba_rust)
warning: function is never used: `main`
 --> src/tba_rust/main.rs:1:4
  |
1 | fn main() {
  |    ^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: 1 warning emitted

    Finished dev [unoptimized + debuginfo] target(s) in 1.37s
#+end_src

*The documentation has been misguiding so far.*

Deploy it:

#+begin_src shell
$ dfx canister install --all
Installing code for canister tba_rust, with canister_id rwlgt-iiaaa-aaaaa-aaaaa-cai
The Replica returned an error: code 5, message: "Canister rwlgt-iiaaa-aaaaa-aaaaa-cai cannot be installed because the canister is not empty. Try installing with mode='reinstall' instead."

$ dfx canister install --mode reinstall
error: The following required arguments were not provided:
    --all

USAGE:
    dfx canister install --mode <mode> --all

For more information try --help

$ dfx canister install --mode reinstall --all
Installing code for canister tba_rust, with canister_id rwlgt-iiaaa-aaaaa-aaaaa-cai
#+end_src

I am not going to move forward since there is no more tutorials about Rust programming on Dfinity.

**** Dfinity references

[[https://medium.com/dfinity/a-technical-overview-of-the-internet-computer-f57c62abc20f][A Technical Overview of the Internet Computer]]

[[https://medium.com/dfinity/the-internet-computers-token-economics-an-overview-29e238bd1d83][The Internet Computers Token Economics: An Overview]]

> You can do two things with ICP tokens:
>
> -  Lock them inside the NNS to create neurons, which can vote on proposals and earn voting rewards.
> -  Convert them into cycles, which are used to power computation by software canisters running on the Internet Computer.
>
> Cycles
>
> Software canisters that run on the Internet Computer must be charged with cycles, which are used to 
power computations and memory management, and are burned in the process. 
The conversion of ICP tokens to cycles occurs at a variable rate, which is 
constantly configured by the NNS in response to external markets.

[[https://sdk.dfinity.org/docs/developers-guide/sample-apps.html][Sample Apps]]

[[https://sdk.dfinity.org/docs/language-guide/motoko.html][Dfinity Motoko Programming Language]]

> Motoko lets you declare certain variables as ~stable~. 
The values of ~stable~ variables are automatically preserved across software upgrades.

It's weird to use another name ~stable~ to replace a name that is in consensus ~static~.


[[https://sdk.dfinity.org/docs/candid-spec/idl][Candid Specification]]

It brings some design thoughts, especially the section [[https://sdk.dfinity.org/docs/candid-spec/idl#_services][Services]].
An interesting read.

[[https://sdk.dfinity.org/docs/developers-guide/work-with-languages.html][Using Rust]]

[[https://docs.rs/candid/0.6.13/candid/][Crate candid]]

Forum post: [[https://forum.dfinity.org/t/developer-experience-january-2021/1749][Developer Experience, January 2021]]



*** TBA on Solana

**** Solana hacklog

Doc: https://docs.solana.com/cli/install-solana-cli-tools

Install Solana:

#+begin_src shell
$ sh -c "$(curl -sSfL https://release.solana.com/v1.5.5/install)"
downloading v1.5.5 installer
Configuration: /<my_path>/.config/solana/install/config.yml
Active release directory: /<my_path>/solana/install/active_release
 Release version: 1.5.5
 Release URL: https://github.com/solana-labs/solana/releases/download/v1.5.5/solana-release-x86_64-apple-darwin.tar.bz2
   Update successful
Adding export PATH="/<my_path>/solana/install/active_release/bin:$PATH" to /<my_other_path>/.profile
Adding export PATH="/<my_path>/solana/install/active_release/bin:$PATH" to /<my_other_path>/.bash_profile

Close and reopen your terminal to apply the PATH changes or run the following in your existing shell:
  export PATH="/<my_path>/solana/install/active_release/bin:$PATH"
#+end_src

Run ~export PATH~ as the output says:

#+begin_src shell
$ export PATH="/<my_path>/solana/install/active_release/bin:$PATH"
#+end_src

Close the current terminal and open a new one.
Check Solana:

#+begin_src shell
$ solana --version
solana-cli 1.5.5 (src:10e12d14; feat:1043916741)
#+end_src

Try ~update~ command:

#+begin_src shell
$ solana-install update
Configuration: /<my_path>/.config/solana/install/config.yml
Active release directory: /<my_path>/.local/share/solana/install/active_release
 Release version: 1.5.5
 Release URL: https://github.com/solana-labs/solana/releases/download/v1.5.5/solana-release-x86_64-apple-darwin.tar.bz2
1.5.5 is present, no download required.
   Update successful
#+end_src

I use a pre-build version, so I download it as the doc says:

#+begin_src shell
$ cd solana-release/
$ ls
bin		version.yml

$ export PATH=$PWD/bin:$PATH
#+end_src

~solana --help~ shows a huge list of commands:

#+begin_src shell
$ solana --help
solana-cli 1.4.25 (src:893cc764; feat:2339469691)
Blockchain, Rebuilt for Scale

USAGE:
    solana [FLAGS] [OPTIONS] <SUBCOMMAND>

FLAGS:
    -h, --help                           Prints help information
        --no-address-labels              Do not use address labels in the output
        --skip-seed-phrase-validation    Skip validation of seed phrases. Use this if your phrase does not use the BIP39
                                         official English word list
    -V, --version                        Prints version information
    -v, --verbose                        Show additional information

OPTIONS:
        --commitment <COMMITMENT_LEVEL>    Return information at the selected commitment level [possible values: recent,
                                           single, singleGossip, root, max]
    -C, --config <FILEPATH>                Configuration file to use [default:
                                           /<my_path>/.config/solana/cli/config.yml]
    -u, --url <URL_OR_MONIKER>             URL for Solana's JSON RPC or moniker (or their first letter): [mainnet-beta,
                                           testnet, devnet, localhost]
    -k, --keypair <KEYPAIR>                Filepath or URL to a keypair
        --output <FORMAT>                  Return information in specified output format [possible values: json, json-
                                           compact]
        --ws <URL>                         WebSocket URL for the solana cluster

SUBCOMMANDS:
    account                        Show the contents of an account
    address                        Get your public key
    airdrop                        Request lamports
    authorize-nonce-account        Assign account authority to a new entity
    balance                        Get your balance
    block                          Get a confirmed block
    block-height                   Get current block height
    block-production               Show information about block production
    block-time                     Get estimated production time of a block
    catchup                        Wait for a validator to catch up to the cluster
    cluster-date                   Get current cluster date, computed from genesis creation time and network time
    cluster-version                Get the version of the cluster entrypoint
    config                         Solana command-line tool configuration settings
    confirm                        Confirm transaction by signature
    create-address-with-seed       Generate a derived account address with a seed
    create-nonce-account           Create a nonce account
    create-stake-account           Create a stake account
    create-vote-account            Create a vote account
    deactivate-stake               Deactivate the delegated stake from the stake account
    decode-transaction             Decode a base-58 binary transaction
    delegate-stake                 Delegate stake to a vote account
    deploy                         Deploy a program
    epoch                          Get current epoch
    epoch-info                     Get information about the current epoch
    feature                        Runtime feature management
    fees                           Display current cluster fees
    first-available-block          Get the first available block in the storage
    genesis-hash                   Get the genesis hash
    gossip                         Show the current gossip network nodes
    help                           Prints this message or the help of the given subcommand(s)
    inflation                      Show inflation information
    largest-accounts               Get addresses of largest cluster accounts
    leader-schedule                Display leader schedule
    live-slots                     Show information about the current slot progression
    logs                           Stream transaction logs
    merge-stake                    Merges one stake account into another
    new-nonce                      Generate a new nonce, rendering the existing nonce useless
    nonce                          Get the current nonce value
    nonce-account                  Show the contents of a nonce account
    pay                            Deprecated alias for the transfer command
    ping                           Submit transactions sequentially
    program                        Program management
    rent                           Calculate per-epoch and rent-exempt-minimum values for a given account data
                                   length.
    resolve-signer                 Checks that a signer is valid, and returns its specific path; useful for signers
                                   that may be specified generally, eg. usb://ledger
    slot                           Get current slot
    split-stake                    Duplicate a stake account, splitting the tokens between the two
    stake-account                  Show the contents of a stake account
    stake-authorize                Authorize a new signing keypair for the given stake account
    stake-history                  Show the stake history
    stake-set-lockup               Set Lockup for the stake account
    stakes                         Show stake account information
    supply                         Get information about the cluster supply of SOL
    transaction-count              Get current transaction count
    transaction-history            Show historical transactions affecting the given address from newest to oldest
    transfer                       Transfer funds between system accounts
    validator-info                 Publish/get Validator info on Solana
    validators                     Show summary information about the current validators
    vote-account                   Show the contents of a vote account
    vote-authorize-voter           Authorize a new vote signing keypair for the given vote account
    vote-authorize-withdrawer      Authorize a new withdraw signing keypair for the given vote account
    vote-update-commission         Update the vote account's commission
    vote-update-validator          Update the vote account's validator identity
    wait-for-max-stake             Wait for the max stake of any one node to drop below a percentage of total.
    withdraw-from-nonce-account    Withdraw SOL from the nonce account
    withdraw-from-vote-account     Withdraw lamports from a vote account into a specified account
    withdraw-stake                 Withdraw the unstaked SOL from the stake account
#+end_src

And then a lot of wallet explanations:
[[https://docs.solana.com/cli/conventions][Using Solana CLI]]


*** TBA on Aleo

TODO:
- [ ] Next, change the default code: https://developer.aleo.org/developer/getting_started/syntax
- [ ] Create TBA program

**** Aleo hacklog

*Install Aleo*

#+begin_src shell
$ cargo install aleo
    Updating crates.io index
  Downloaded aleo v0.2.0
  ...
   Compiling aleo v0.2.0
    Finished release [optimized] target(s) in 3m 50s
  Installing /Users/aimeez/.cargo/bin/aleo                                       Installed package `aleo v0.2.0` (executable `aleo`)

$ aleo
aleo 0.2.0
The Aleo Team <hello@aleo.org>

USAGE:
    aleo [FLAGS] <SUBCOMMAND>

FLAGS:
    -d, --debug      Enable debug mode
    -h, --help       Prints help information
    -V, --version    Prints version information
    -v, --verbose    Enable verbose mode

SUBCOMMANDS:
    help    Prints this message or the help of the given subcommand(s)
    new     Generates a new Aleo account
#+end_src

Test some commands:

#+begin_src shell
aleo new --seed testtest
error: Invalid value for '--seed <seed>': invalid digit found in string
Aimees-MacBook-Pro:aleo aimeez$ aleo new --seed <my_test_seed>

  Private Key  APrivateKey1yg4Nkz7waZ4Smte38XSg9a4tH7vydLCQCr2GPr7QArjhmiQ # only for test purposes
     View Key  AViewKey1cXkqYJ3exGTVhrMCJrQPCwcGFnsb1d153HSGk5U5b7Q4
      Address  aleo1ztpasdk5acqz2nphfcn8mz3dyd9d5z23kjun04r7vy0gqfszrsyq2tw9qk

$ cargo run --release --example dummy_transaction
error: failed to parse lock file at: /<my_path>/aleo/Cargo.lock

Caused by:
  package `bytes` is specified twice in the lockfile
#+end_src

There are more errors because some packages are specified twice in the lockfile.
The lockfile is generated by cargo and is not supposed to be edited manually. 
So I delete ~Cargo.lock~ file, and run the example again. 
Now it built.
(Read cargo book: [[https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html][Cargo.toml vs Cargo.lock]]).

#+begin_src shell
$ rm Cargo.lock
$ cargo clean
$ cargo run --release --example dummy_transaction
    Updating crates.io index
  Downloaded httparse v1.3.5
  ...
   Compiling aleo v0.2.0 (/<my_path>/aleo)
    Finished release [optimized] target(s) in 5m 00s
     Running `target/release/examples/dummy_transaction`

WARNING - "outer_snark_pk-12b0f50.params" does not exist. snarkVM will download this file remotely and store it locally. Please ensure "outer_snark_pk-12b0f50.params" is stored in "/<my_path>/.cargo/registry/src/github.com-1ecc6299db9ec823/snarkvm-parameters-0.0.2/src/params/outer_snark_pk-12b0f50.params".

snarkvm_parameters::params - Downloading parameters...
snarkvm_parameters::params - 100.00% complete (479 MB total)
snarkvm_parameters::params - Download complete
snarkvm_parameters::params - Storing parameters ("/<my_path>/.cargo/registry/src/github.com-1ecc6299db9ec823/snarkvm-parameters-0.0.2/src/params/outer_snark_pk-12b0f50.params")
2878386d9bc55cd70edc2f8a8ed00776bd0e25dabdf47ff351e59cc75d055508dc47296a7708e2bb340e89bf4e33d7aa58ff91ebb81cdf996bc44aa91c67548912f7dd3c4950b603c8a4f75e0e431c46aa8ad4547c3858098be9f10559f80001b0bbef8f226950f0ff2228ab46d33507a1f5e88260549f1bcfc099ab15624610c894eee83712e5f2edd32a44587589564402555280599c226c7e681c30a4eeb8b058934993bcd2666d45bce96ffb2b96c33a8b7548022d401f2b8fe28366bf0c84f313ea49db0e697c0c17e590a818a35d218bf710c984008d1c1d02834b124ef839763d51350b5bc4e950baa790a30086f3d16a56b679b538ec7f376c2153f6800a15da00b97345f5e426550b9ed4530c0ff010a375b10c297dc1cfcf980870a68f197e46fee23f2165e0e7178870b7e240e38cf77190f9b033128c2b92fc8500a3da185847ee02830fba4658c23a00f30572d9e4c3ccad9dcd9827a3fa916fc4995f19cf21a564ade7a60a33212dc113fce37b131df331ddf26a9c1dc51fccbbcb7097c0dcd67bc21893a09245d093efa2cbe739bf506ec577754ef6f3f5c0b8d22c20a823a467dd916d1db1fb0001005e790fd960087fc90f157164bbc6c5fb65e27660c9e2020f5af25f2e4b0f990ecc5d7553b989681dba0a1b0981f6a186a8cb87e4a4b7de7e26cba3e5acbc59c37739832b85385abf2bcca6a6cb4711e72d395fd45dac64242447550393de040055d1fda3b04916320fc4a302fcb1be7af0ccd6c04184ae42d5c34f245dfd74f06d1a2467ce69b0d7880a1e882c10482bb3e1d583cda0b8e32c8040f9e11d22c30118661412417f5ed2794f9b737aa22efb92eb815126968ea01d4cc8580c28000079d39218d00e129b822d3647c548bb63fc24cd009064ec497fb585f1d10f3274e3c7e0bc2423532d4cbb8dad4ecb8022cfb3a1705d115c2de10c0212c87c061499d5acd1ad63208d9a2d56f2c580ca214172b8d8a938be132126a0c02621630075e97d8c17a3d577c0f3d891978bf55f6f5202a632cbc46a6a21f7bf33f340ea29002a84e526bf1e9af07a0db3acd5b1580b61372042df326c582be684f6a60e06944a5dec5e48c10225ff31eeaa9be2dc81f4522d045218ff14326be3a0c20000cbb3c9cddbb049a71941b237665f9f36adafd0d0e9853670a50e1ab0f0821c606df9632af66df58abccbdf35c8a13ac1eb4b250e26780e1c73d0f67249c8950f000000000000000001097bfc730a603426e535d187d67a198869a355208a73b5230214f464a2c4be0048c0d41d1e0d4744ac74511cd316acb84572900fe57d5fed6d926ed8b08b4c01521ca5ed84865e274f05ade37e14ac388350149bd5a5a162038f29883adf940362810ea9753049d55c5f7cb4086ad65e44db5fd23048f10dd6d826504619920008af4b3f4a14aaebc83449780a3c06368479d54518e4c9394b107196a6d4799d052d2d44d4ec904094b57fb0e071226e0e08e5f5342f37b65cd75b9ba45912ab0551c7ddfac4313ea26fd63be3acb08dc3a5e37a0c61037d1b397e4039cbab81044890c6bfaa7e4ddba39a929cfcaa7a86e1f045502f96d85131be5254f530eb0182af40f3cb0ae138cb8592169fcbe15d769f6fb805a288f689262865bc42b20a7ce3121a346aaa0c8827c5513d92150fd87a60aca46ecf6eaee5970cda8ce8053ffe83f915f1fcd2fdc5f1071b3099176002112dbeb6aa9b37e45cd25618c40bdb8808b3be13a53bf80a374d5961efa487f7764c782f41154e387e5def32dd0f8200085621e0b9c3bb8d56afd297e8bf3377f4498e5727d2f723173154df1e600a040b530b063f511bcd856fa013090fbacf4e4dfdbe10017cfbfff9bdee91221fea02ef840cea3eac78a9ced0f633235ac80c772de318667f28738c908b998422ce035ebfc13d70403b719525c5b6b1dc23db4b463e4c6a03eb39c9d4fcda48c8b8078114f6395636232416f48c449ed8efe270ddbef30e95880b19c0d37a336b3a0de942246d92fe10f51140b1139d9ee073631a2673e856389acb8f8da443f819058eda09a75fb40ba50e94e14e7846176cdf7be03bc104f47d194f23958899910c12afdaa934939f3f6b3c8f4cb3a4453ab89b62326c163f9cf4d06ce572493f11f300
#+end_src

I don't know what to expect from this example, though.

*Install Leo*

#+begin_src shell
$ cargo install leo-lang
    Updating crates.io index
  Downloaded leo-lang v1.0.8
  ...
   Compiling leo-lang v1.0.8
    Finished release [optimized] target(s) in 9m 14s
  Installing /<my_path>/.cargo/bin/leo                                        Installed package `leo-lang v1.0.8` (executable `leo`)

$ leo
leo v1.0.8
The Aleo Team <hello@aleo.org>
Leo compiler and package manager

USAGE:
    leo [FLAGS] [SUBCOMMAND]

FLAGS:
    -d, --debug    Enables debugging mode
    -h, --help     Prints help information

SUBCOMMANDS:
    new        Create a new Leo package in a new directory
    init       Create a new Leo package in an existing directory
    build      Compile the current package as a program
    watch      Watch the changes of the leo's source files
    test       Compile and run all tests in the current package
    setup      Run a program setup
    prove      Run the program and produce a proof
    run        Run a program with input variables
    login      Login to the Aleo Package Manager
    add        Install a package from the Aleo Package Manager
    remove     Uninstall a package from the current package
    publish    Publish the current package to the Aleo Package Manager
    deploy     Deploy the current package as a program to the network (*)
    clean      Clean the output directory
    lint       Lints the Leo files in the package (*)
    update     Update Leo to the latest version
#+end_src

Let create a project ~firsttest~:

#+begin_src shell
$ leo new firsttest
Initializing Successfully initialized package "firsttest"

$ cd firsttest/
$ ls
Leo.toml	README.md	inputs		src
$ ls src/
main.leo
$ ls inputs/
firsttest.in	firsttest.state
#+end_src

The file tree looks like this:

#+begin_src shell
firsttest/
 Leo.toml
 README.md 
 inputs/ 
  firsttest.in
  firsttest.state
 src/    
   main.leo
#+end_src

Run firsttest:

#+begin_src shell
$ leo run
 Compiling Starting...
 Compiling Compiling main program... ("/<my_path>/firsttest/src/main.leo")
 Compiling Complete
      Done Finished in 6 milliseconds

     Setup Starting...
     Setup Saving proving key ("/<my_path>/firsttest/outputs/firsttest.lpk")
     Setup Complete
     Setup Saving verification key ("/<my_path>/firsttest/outputs/firsttest.lvk")
     Setup Complete
      Done Finished in 40 milliseconds

   Proving Starting...
   Proving Saving proof... ("/<my_path>/firsttest/outputs/firsttest.proof")
      Done Finished in 10 milliseconds

 Verifying Starting...
 Verifying Proof is valid
      Done Finished in 2 milliseconds
#+end_src


**** Aleo references

- Doc: https://developer.aleo.org/aleo/getting_started/overview/
- SDK: https://github.com/AleoHQ/aleo
- Package manager: https://aleo.pm/
- Node: https://github.com/AleoHQ/snarkOS
- VM: https://github.com/AleoHQ/snarkVM


** Play with Substrate                   :rust:substrate:blockchain:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: play-with-substrate
:EXPORT_DATE: 2020-11-15
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Substrate is interesting and it seems powerful.
:EXPORT_OPTIONS: toc:2
:END:

References:
- Doc: [[https://substrate.dev/docs/en/knowledgebase/runtime/frame][FRAME]]  Framework for Runtime Aggregation of Modularized Entities (FRAME)
- Doc: [[https://substrate.dev/docs/en/tutorials/add-a-pallet/import-a-pallet][Add a Pallet to Your Runtime]]
- Repo: [[https://github.com/substrate-developer-hub/substrate-node-template#local-development][Substrate Node Template]]
- Doc: [[https://paritytech.github.io/ink/ink_lang/attr.contract.html][Attribute Macro ink_lang::contract]]
- Doc: [[https://substrate.dev/docs/en/knowledgebase/advanced/cryptography#public-key-cryptography][Cryptography]]
- Doc: [[https://paritytech.github.io/wasmi/wasmi/index.html][wasmi]]
- Doc: [[https://substrate.dev/docs/en/knowledgebase/advanced/consensus][Consensus]]
> In order to agree on the resulting state after a transition, 
all operations within a blockchain's state transition function must be deterministic.

> Substrate provides several block construction 
algorithms and also allows you to create your own:
> - Aura (round robin)
> - BABE (slot-based)
> - Proof of Work

*** 2020-12-08 A super simple smart contract

The source code is on GitHub: [[https://github.com/Aimeedeer/mytest-with-ink][mytest-with-ink]].


I am following [[https://github.com/paritytech/ink#play-with-it][ink]] tutorials:

Creating a default smart contract with ~cargo contract new mytest~,
and it generates ~lib.rs~ and ~Cargo.toml~ files.

I changed code in ~lib.rs~, turn ~bool~ to ~String~ type.

#+begin_src shell
$ cargo contract new mytest

Created contract mytest

$ cd mytest
$ cargo contract build && cargo contract generate-metadata
 [1/3] Building cargo project
ERROR: cargo-contract cannot build using the "stable" channel. Switch to nightly. See https://github.com/paritytech/cargo-contract#build-requires-the-nightly-toolchain
ERROR: cargo-contract cannot build using the "stable" channel. Switch to nightly. See https://github.com/paritytech/cargo-contract#build-requires-the-nightly-toolchain
#+end_src

Switch from stable to nightly:

#+begin_src shell
$ rustup default nightly

info: using existing install for 'nightly-x86_64-apple-darwin'
info: default toolchain set to 'nightly-x86_64-apple-darwin'

  nightly-x86_64-apple-darwin unchanged - rustc 1.50.0-nightly (98d66340d 2020-11-14)

$ cargo contract build && cargo contract generate-metadata
#+end_src

The result:

#+begin_src shell
Your contract is ready. You can find it here:
/<mypath>/mytest/target/mytest.wasm
  Generating metadata
 [1/3] Building cargo project
    Finished release [optimized] target(s) in 0.07s
 [2/3] Post processing wasm file
 [3/3] Optimizing wasm file
  Compiling ... #packages
    Finished release [optimized] target(s) in 1m 20s
     Running `target/release/metadata-gen`
	Your metadata file is ready.
You can find it here:
/<mypath>/mytest/target//metadata.json
#+end_src

Change the ~bool~ type to ~String~ in the code:

#+begin_src rust
    #[ink(storage)]
    pub struct Mytest {
        value: String,
    }
#+end_src

And run the contract:

#+begin_src shell
$ cargo contract build && cargo contract generate-metadata
 [1/3] Building cargo project
   Compiling mytest v0.1.0 (/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/cargo-contract_p9Kcuf)
error[E0433]: failed to resolve: use of undeclared type `String`
  --> /<mypath>/mytest/lib.rs:28:23
   |
28 |             Self::new(String::from("init!"))
   |                       ^^^^^^ use of undeclared type `String`
#+end_src

Now add crate ~alloc~:

#+begin_src rust
extern crate alloc;
use alloc::string::String;
#+end_src

and build it:

#+begin_src shell
$ cargo contract build && cargo contract generate-metadata 
 [1/3] Building cargo project
   Compiling mytest v0.1.0 (/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/cargo-contract_p7eKiU)
error[E0412]: cannot find type `String` in this scope
  --> /Users/aimeez/github/mytest/lib.rs:11:16
   |
11 |         value: String,
   |                ^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
7  | use alloc::string::String;
   |
7  | use crate::String;
   |
#+end_src

What's wrong?
There is a warning here that says unused import `alloc::string::String`.

#+begin_src shell
$ cargo +nightly test
warning: unused import: `alloc::string::String`
 --> lib.rs:4:5
  |
4 | use alloc::string::String;
  |     ^^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(unused_imports)]` on by default

warning: 1 warning emitted

    Finished test [unoptimized + debuginfo] target(s) in 0.08s
     Running target/debug/deps/mytest-c60315897dda6247

running 2 tests
test mytest::tests::default_works ... ok
test mytest::tests::it_works ... ok
#+end_src

Because `String` inside the `mod` used type from `std` when I ran
`cargo test` while `build` uses `no_std` so it couldn't build.
Let's move `alloc::string::String` inside the `mod` to import 
the `String` type we need in this contract code.

#+begin_src rust
#![cfg_attr(not(feature = "std"), no_std)]

extern crate alloc;
use ink_lang as ink;

#[ink::contract]
mod mytest {
    use alloc::string::String;

    #[ink(storage)]
    pub struct Mytest {
        value: String,
    }

    impl Mytest {
#+end_src

Now it built:

#+begin_src shell
$ cargo contract build && cargo contract generate-metadata 
 [1/3] Building cargo project
    Finished release [optimized] target(s) in 0.11s
 [2/3] Post processing wasm file
 [3/3] Optimizing wasm file
wasm-opt is not installed. Install this tool on your system in order to 
reduce the size of your contract's Wasm binary. 
See https://github.com/WebAssembly/binaryen#tools
	
Your contract is ready. You can find it here:
/Users/aimeez/github/mytest/target/mytest.wasm
  Generating metadata
 [1/3] Building cargo project
    Finished release [optimized] target(s) in 0.06s
 [2/3] Post processing wasm file
 [3/3] Optimizing wasm file
wasm-opt is not installed. Install this tool on your system in order to 
reduce the size of your contract's Wasm binary. 
See https://github.com/WebAssembly/binaryen#tools
    Updating crates.io index
   Compiling metadata-gen v0.1.0 (/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/cargo-contract_fNuJ5a/.ink/metadata_gen)
    Finished release [optimized] target(s) in 2.09s
     Running `target/release/metadata-gen`
	Your metadata file is ready.
You can find it here:
/Users/aimeez/github/mytest/target/metadata.json
#+end_src

I want to deploy this contract that we need to run a Canvas node.
I start the node with `canvas --dev --tmp` and it runs.

#+begin_src shell
$ canvas --dev --tmp
2020-12-07 11:33:44  Running in --dev mode, RPC CORS has been disabled.    
2020-12-07 11:33:44  Canvas Node    
2020-12-07 11:33:44    version 0.1.0-258b0fa-x86_64-macos    
2020-12-07 11:33:44    by Canvas, 2020-2020    
2020-12-07 11:33:44   Chain specification: Development    
2020-12-07 11:33:44   Node name: ashamed-expansion-2693    
2020-12-07 11:33:44   Role: AUTHORITY    
2020-12-07 11:33:44   Database: RocksDb at /var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/substratemw8oWO/chains/dev/db    
2020-12-07 11:33:44    Native runtime: canvas-8 (canvas-0.tx1.au1)    
2020-12-07 11:33:44   Initializing Genesis block/state (state: 0xa59bf816, header-hash: 0xb343d7c7)    
2020-12-07 11:33:44   Loading GRANDPA authority set from genesis on what appears to be first startup.    
2020-12-07 11:33:44    Loaded block-time = 6000 milliseconds from genesis on first-launch    
2020-12-07 11:33:44  Using default protocol ID "sup" because none is configured in the chain specs    
2020-12-07 11:33:44   Local node identity is: 12D3KooWPVg8eFAUQwkxNRneEnf9aTtnW4N5mfcnYuM2uzntSLxY    
2020-12-07 11:33:45   Highest known block at #0    
2020-12-07 11:33:45   Prometheus server started at 127.0.0.1:9615    
2020-12-07 11:33:45  Listening for new connections on 127.0.0.1:9944.    
2020-12-07 11:33:48   Starting consensus session on top of parent 0xb3438d10dfad2cb1016336ce4cb6bbad06d15bb33889a320c5872576f8ded7c7    
2020-12-07 11:33:48   Prepared block for proposing at 1 [hash: 0xa5aebe057cf481c8e86f0871de9f85a122c44dfaf18ec7e6c86bbe7b5d8baf66; parent_hash: 0xb343d7c7; extrinsics (1): [0x7ddc7b9c]]    
2020-12-07 11:33:48   Pre-sealed block for proposal at 1. Hash now 0xdfbe71815a49bb34e6d1d656b7967fa5769d50b4bae1fac9ef5523731a6329f7, previously 0xa5aebe057cf481c8e86f0871de9f85a122c44dfaf18ec7e6c86bbe7b5d8baf66.    
2020-12-07 11:33:48   Imported #1 (0xdfbe29f7)    
2020-12-07 11:33:50   Idle (0 peers), best: #1 (0xdfbe29f7), finalized #0 (0xb343d7c7),  0  0  
#+end_src

Then I open the page https://paritytech.github.io/canvas-ui,
but it shows:

> You are not connected to a node.
> Ensure that your node is running and that your Websocket endpoint is reachable.

I use Brave browser, and its inspect shows:

> polkadotjs.6a4157a5.js:1 WebSocket connection to 'ws://127.0.0.1:9944/' failed: Unknown reason

I tried many times but couldn't work out the problem.
Anyway, I switched to Firefox, and it works.
I can send a message to ~mytest~ contract and get the result from the RPC call.
Try out the [[https://github.com/Aimeedeer/mytest-with-ink][source code]].

*** 2020-11-20 The example: flipper

[[https://substrate.dev/substrate-contracts-workshop/#/0/creating-an-ink-project][Creating an ink! Project]]

Run ~cargo contract new flipper~ again
(I already ran it last time):
#+begin_src shell
$ cargo +nightly contract build
 [1/3] Building cargo project
   Compiling termcolor v1.1.2
   Compiling trybuild v1.0.35
   Compiling ink_lang_macro v3.0.0-rc2
   Compiling ink_lang v3.0.0-rc2
   Compiling flipper v0.1.0 (/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/cargo-contract_4mvqYY)
    Finished release [optimized] target(s) in 5.55s
 [2/3] Post processing wasm file
 [3/3] Optimizing wasm file
wasm-opt is not installed. Install this tool on your system in order to 
reduce the size of your contract's Wasm binary. 
See https://github.com/WebAssembly/binaryen#tools
#+end_src	

**** New tool learned

[[https://github.com/dtolnay/cargo-expand][cargo-expand]] by [[https://github.com/dtolnay][dtolnay]].

#+begin_src shell
$ cargo expand --no-default-features
# Compiling...
error: ink! only support compilation as `std` or `no_std` + `wasm32-unknown`
  --> /Users/aimeez/.cargo/registry/src/github.com-1ecc6299db9ec823/ink_env-3.0.0-rc2/src/engine/mod.rs:39:9
   |
39 | /         compile_error! {
40 | |             "ink! only support compilation as `std` or `no_std` + `wasm32-unknown`"
41 | |         }
   | |_________^
error[E0432]: unresolved import `crate::engine::EnvInstance`
  --> /Users/aimeez/.cargo/registry/src/github.com-1ecc6299db9ec823/ink_env-3.0.0-rc2/src/api.rs:29:9
   |
29 |         EnvInstance,
   |         ^^^^^^^^^^^
   |         |
   |         no `EnvInstance` in `engine`
   |         help: a similar name exists in the module: `OnInstance`
error: aborting due to 2 previous errors
For more information about this error, try `rustc --explain E0432`.
error: could not compile `ink_env`
To learn more, run the command again with --verbose.
warning: build failed, waiting for other jobs to finish...
error: build failed
#+end_src

Update the command and it works:

#+begin_src shell
$ cargo expand --no-default-features --target=wasm32-unknown-unknown

#![feature(prelude_import)]
#![no_std]
#[prelude_import]
use core::prelude::v1::*;
#[macro_use]
extern crate core;
#[macro_use]
extern crate compiler_builtins;
use ink_lang as ink;
mod flipper {
    impl ::ink_lang::ContractEnv for Flipper {
        type Env = ::ink_env::DefaultEnvironment;
    }
    type Environment = <Flipper as ::ink_lang::ContractEnv>::Env;
    type AccountId =
        <<Flipper as ::ink_lang::ContractEnv>::Env as ::ink_env::Environment>::AccountId;
    type Balance = <<Flipper as ::ink_lang::ContractEnv>::Env as ::ink_env::Environment>::Balance;
    type Hash = <<Flipper as ::ink_lang::ContractEnv>::Env as ::ink_env::Environment>::Hash;
    type Timestamp =
        <<Flipper as ::ink_lang::ContractEnv>::Env as ::ink_env::Environment>::Timestamp;
    type BlockNumber =
        <<Flipper as ::ink_lang::ContractEnv>::Env as ::ink_env::Environment>::BlockNumber;
    #[cfg(not(feature = "ink-as-dependency"))]
    const _: () = {
        impl<'a> ::ink_lang::Env for &'a Flipper {
            type EnvAccess = ::ink_lang::EnvAccess<'a, <Flipper as ::ink_lang::ContractEnv>::Env>;
            fn env(self) -> Self::EnvAccess {
                Default::default()
            }
        }
        impl<'a> ::ink_lang::StaticEnv for Flipper {
            type EnvAccess =
                ::ink_lang::EnvAccess<'static, <Flipper as ::ink_lang::ContractEnv>::Env>;
            fn env() -> Self::EnvAccess {
                Default::default()
            }
        }
    };
    #[cfg(not(feature = "ink-as-dependency"))]
    /// Defines the storage of your contract.
    /// Add new fields to the below struct in order
    /// to add new static storage fields to your contract.
    pub struct Flipper {
        /// Stores a single `bool` value on the storage.
        value: bool,
    }
    const _: () = {
        impl ::ink_storage::traits::SpreadLayout for Flipper {
            #[allow(unused_comparisons)]
            const FOOTPRINT: u64 = [
                (0u64 + <bool as ::ink_storage::traits::SpreadLayout>::FOOTPRINT),
                0u64,
            ][((0u64 + <bool as ::ink_storage::traits::SpreadLayout>::FOOTPRINT) < 0u64) as usize];
            const REQUIRES_DEEP_CLEAN_UP: bool = (false
                || (false
                    || <bool as ::ink_storage::traits::SpreadLayout>::REQUIRES_DEEP_CLEAN_UP));
            fn pull_spread(__key_ptr: &mut ::ink_storage::traits::KeyPtr) -> Self {
                Flipper {
                    value: <bool as ::ink_storage::traits::SpreadLayout>::pull_spread(__key_ptr),
                }
            }
            fn push_spread(&self, __key_ptr: &mut ::ink_storage::traits::KeyPtr) {
                match self {
                    Flipper { value: __binding_0 } => {
                        ::ink_storage::traits::SpreadLayout::push_spread(__binding_0, __key_ptr);
                    }
                }
            }
            fn clear_spread(&self, __key_ptr: &mut ::ink_storage::traits::KeyPtr) {
                match self {
                    Flipper { value: __binding_0 } => {
                        ::ink_storage::traits::SpreadLayout::clear_spread(__binding_0, __key_ptr);
                    }
                }
            }
        }
    };
    #[cfg(not(feature = "ink-as-dependency"))]
    const _: () = {
        #[allow(unused_imports)]
        use ::ink_lang::{Env as _, StaticEnv as _};
    };
    #[cfg(not(test))]
    #[cfg(not(feature = "ink-as-dependency"))]

    #... 
    #more
#+end_src

*** 2020-11-17 ink!

**** Follow the docs

Start with
[[https://substrate.dev/substrate-contracts-workshop/#/0/introduction][substrate.dev/substrate-contracts-workshop]]

Install from the webpage's command, but build failed.

The existing issue in Cargo's repo:
https://github.com/rust-lang/cargo/issues/7169

Need to read Cargo book:
https://doc.rust-lang.org/nightly/cargo/commands/cargo-install.html

Keep following the doc: [[https://substrate.dev/substrate-contracts-workshop/#/0/running-a-substrate-node][Running a Canvas Node]].
Btw, I like the tutorials explain each file.
It's helpful to me.

#+begin_src shell
$ canvas --dev --tmp
2020-11-17 17:20:43  Running in --dev mode, RPC CORS has been disabled.    
2020-11-17 17:20:43  Canvas Node    
2020-11-17 17:20:43    version 0.1.0-e189090-x86_64-macos    
2020-11-17 17:20:43    by Canvas, 2020-2020    
2020-11-17 17:20:43   Chain specification: Development    
2020-11-17 17:20:43   Node name: cute-example-7440    
2020-11-17 17:20:43   Role: AUTHORITY    
2020-11-17 17:20:43   Database: RocksDb at /var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/substratePetkPI/chains/dev/db    
2020-11-17 17:20:43    Native runtime: canvas-8 (canvas-0.tx1.au1)    
2020-11-17 17:20:43   Initializing Genesis block/state (state: 0x1611971f, header-hash: 0x575c6d5f)    
2020-11-17 17:20:43   Loading GRANDPA authority set from genesis on what appears to be first startup.    
2020-11-17 17:20:43    Loaded block-time = 6000 milliseconds from genesis on first-launch    
2020-11-17 17:20:43  Using default protocol ID "sup" because none is configured in the chain specs    
2020-11-17 17:20:43   Local node identity is: 12D3KooWSLjj5cAsQ8EeBvSRrxbg8b9mTzvoZVf7SA5NzkDzSCFx    
2020-11-17 17:20:43   Highest known block at #0    
2020-11-17 17:20:43   Prometheus server started at 127.0.0.1:9615    
2020-11-17 17:20:43  Listening for new connections on 127.0.0.1:9944.    
2020-11-17 17:20:48   Starting consensus session on top of parent 0x575c06528df3f98a10aa6ac8d6d7c8f1d0ca9738206c05dc96516b1bcb836d5f    
2020-11-17 17:20:48   Prepared block for proposing at 1 [hash: 0x8d82ffaef8eea6679896f4b8335a68771ab7add86a51959368030e6aad395e8a; parent_hash: 0x575c6d5f; extrinsics (1): [0xdc0e86a9]]    
2020-11-17 17:20:48   Pre-sealed block for proposal at 1. Hash now 0x4b4fa8e91ef020d0544796b1dc9c26c046662b6bae182be5fa5548f9818863b4, previously 0x8d82ffaef8eea6679896f4b8335a68771ab7add86a51959368030e6aad395e8a.    
2020-11-17 17:20:48   Imported #1 (0x4b4f63b4)    
2020-11-17 17:20:48   Idle (0 peers), best: #1 (0x4b4f63b4), finalized #0 (0x575c6d5f),  0  0    
2020-11-17 17:20:53   Idle (0 peers), best: #1 (0x4b4f63b4), finalized #0 (0x575c6d5f),  0  0    
2020-11-17 17:20:54   Starting consensus session on top of parent 0x4b4fa8e91ef020d0544796b1dc9c26c046662b6bae182be5fa5548f9818863b4    
2020-11-17 17:20:54   Prepared block for proposing at 2 [hash: 0x42d318b1165e2217212499aad57c1d6c89637668fb5d02d482415ef8eaa9f4da; parent_hash: 0x4b4f63b4; extrinsics (1): [0x029c6c04]]    

#+end_src

**** Thoughts

My experience with Polkadot, Substrate, and ink so far is pleasant.
The documentation is up to date enough with detailed step by step
descriptions. I can follow along smoothly.

There are some things I couldn't figure out at the first moment.
I realized that mostly because I am not familiar with Rust language and 
its ecosystem. For example, if I know Cargo better, I would learn
to use ~cargo install~ and ~cargo build~ correctly with necessary arguments.

*** 2020-11-15 Start

**** Follow the GitHub repo

#+begin_src shell
$ WASM_BUILD_TOOLCHAIN=nightly-2020-10-05 cargo build --release
error: failed to run custom build command for `node-template-runtime v2.0.0 (/Users/aimeez/github/substrate-node-template/runtime)`

Caused by:
  process didn't exit successfully: `/Users/aimeez/github/substrate-node-template/target/release/build/node-template-runtime-329be64dd2778179/build-script-build` (exit code: 1)
  --- stderr
     Compiling wasm-build-runner-impl v1.0.0 (/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701)
      Finished release [optimized] target(s) in 0.54s
       Running `/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701/target/x86_64-apple-darwin/release/wasm-build-runner-impl`
  Rust nightly not installed, please install it!
warning: build failed, waiting for other jobs to finish...
error: build failed
#+end_src

**** Install =nightly-2020-10-05= and build again

#+begin_src shell
$ rustup toolchain install nightly-2020-10-05

$ WASM_BUILD_TOOLCHAIN=nightly-2020-10-05 cargo build --release

error: failed to run custom build command for `node-template-runtime v2.0.0 (/Users/aimeez/github/substrate-node-template/runtime)`

Caused by:
  process didn't exit successfully: `/Users/aimeez/github/substrate-node-template/target/release/build/node-template-runtime-329be64dd2778179/build-script-build` (exit code: 1)
  --- stderr
     Compiling wasm-build-runner-impl v1.0.0 (/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701)
      Finished release [optimized] target(s) in 0.39s
       Running `/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701/target/x86_64-apple-darwin/release/wasm-build-runner-impl`
  Rust WASM toolchain not installed, please install it!

  Further error information:
  ------------------------------------------------------------
     Compiling wasm-test v1.0.0 (/var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/.tmpWk51lL)
  error[E0463]: can't find crate for `std`
    |
    = note: the `wasm32-unknown-unknown` target may not be installed

  error: aborting due to previous error

  For more information about this error, try `rustc --explain E0463`.
  error: could not compile `wasm-test`

  To learn more, run the command again with --verbose.
  ------------------------------------------------------------

warning: build failed, waiting for other jobs to finish...
error: build failed
#+end_src

**** Set target: 

#+begin_src shell
$ rustup target add wasm32-unknown-unknown --toolchain nightly-2020-10-05

error: failed to run custom build command for `node-template-runtime v2.0.0 (/Users/aimeez/github/substrate-node-template/runtime)`

Caused by:
  process didn't exit successfully: `/Users/aimeez/github/substrate-node-template/target/release/build/node-template-runtime-329be64dd2778179/build-script-build` (exit code: 1)
  --- stdout
  Executing build command: "/Users/aimeez/.rustup/toolchains/nightly-x86_64-apple-darwin/bin/cargo" "rustc" "--target=wasm32-unknown-unknown" "--manifest-path=/Users/aimeez/github/substrate-node-template/target/release/wbuild/node-template-runtime/Cargo.toml" "--color=always" "--release"

  --- stderr
     Compiling wasm-build-runner-impl v1.0.0 (/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701)
      Finished release [optimized] target(s) in 0.45s
       Running `/Users/aimeez/github/substrate-node-template/target/release/wbuild-runner/node-template-runtime3117747485089870701/target/x86_64-apple-darwin/release/wasm-build-runner-impl`
     Compiling sp-arithmetic v2.0.0
     Compiling sp-runtime-interface v2.0.0
     Compiling parity-util-mem v0.7.0
  error[E0282]: type annotations needed
#+end_src

**** Built failed because my default setting is nightly but not stable.

#+begin_src shell
$ rustc -V
rustc 1.50.0-nightly (98d66340d 2020-11-14)

$ rustup default stable

info: using existing install for 'stable-x86_64-apple-darwin'
info: default toolchain set to 'stable-x86_64-apple-darwin'

  stable-x86_64-apple-darwin unchanged - rustc 1.47.0 (18bf6b4f0 2020-10-07)
#+end_src

**** It took 13 minutes to build: my laptop is slow...

#+begin_src shell
$ WASM_BUILD_TOOLCHAIN=nightly-2020-10-05 cargo build --release

Finished release [optimized] target(s) in 13m 17s
#+end_src

**** Cute run!

#+begin_src shell
$ ./target/release/node-template --dev --tmp
Nov 15 18:04:40.702  WARN Running in --dev mode, RPC CORS has been disabled.    
Nov 15 18:04:40.703  INFO Substrate Node    
Nov 15 18:04:40.703  INFO   version 2.0.0-24da767-x86_64-macos    
Nov 15 18:04:40.703  INFO   by Substrate DevHub <https://github.com/substrate-developer-hub>, 2017-2020    
Nov 15 18:04:40.703  INFO  Chain specification: Development    
Nov 15 18:04:40.703  INFO   Node name: super-top-6271    
Nov 15 18:04:40.703  INFO  Role: AUTHORITY    
Nov 15 18:04:40.703  INFO  Database: RocksDb at /var/folders/g5/hf7q78jn0vngnqtqj_3qfm6r0000gn/T/substrate2jvpo0/chains/dev/db    
Nov 15 18:04:40.703  INFO   Native runtime: node-template-1 (node-template-1.tx1.au1)    
Nov 15 18:04:40.755  INFO  Initializing Genesis block/state (state: 0xc29a9e07, header-hash: 0x40cafc14)    
Nov 15 18:04:40.756  INFO  Loading GRANDPA authority set from genesis on what appears to be first startup.    
Nov 15 18:04:40.774  INFO   Loaded block-time = 6000 milliseconds from genesis on first-launch    
Nov 15 18:04:40.774  WARN Using default protocol ID "sup" because none is configured in the chain specs    
Nov 15 18:04:40.774  INFO   Local node identity is: 12D3KooWSMTDCBT4GHADWJxdRJTBnSKgEAXrekDVcwG6SuQy1az9 (legacy representation: 12D3KooWSMTDCBT4GHADWJxdRJTBnSKgEAXrekDVcwG6SuQy1az9)    
Nov 15 18:04:41.071  INFO  Highest known block at #0    
Nov 15 18:04:41.072  INFO  Prometheus server started at 127.0.0.1:9615    
Nov 15 18:04:41.073  INFO Listening for new connections on 127.0.0.1:9944.    
Nov 15 18:04:42.012  INFO  Starting consensus session on top of parent 0x40ca582052a890e826eb0c3d3e5d9a1383f7cb95dd87d5b542b574040ea6fc14    
Nov 15 18:04:42.017  INFO  Prepared block for proposing at 1 [hash: 0x384b4a0ce970b7b28dbc0764ef74ee3b3a55517c31476496db175845d03fe61e; parent_hash: 0x40cafc14; extrinsics (1): [0xab8edeca]]    
Nov 15 18:04:42.021  INFO  Pre-sealed block for proposal at 1. Hash now 0x753af28ba42e197ddf1df41477d452ac35cd3138afe70083f81e64637f51c1fd, previously 0x384b4a0ce970b7b28dbc0764ef74ee3b3a55517c31476496db175845d03fe61e.    
Nov 15 18:04:42.021  INFO  Imported #1 (0x753ac1fd)    
Nov 15 18:04:46.074  INFO  Idle (0 peers), best: #1 (0x753ac1fd), finalized #0 (0x40cafc14),  0  0    
Nov 15 18:04:48.010  INFO  Starting consensus session on top of parent 0x753af28ba42e197ddf1df41477d452ac35cd3138afe70083f81e64637f51c1fd    
Nov 15 18:04:48.010  INFO  Prepared block for proposing at 2 [hash: 0x625c206bc45416b3745d544d93626a4cacaf74bf73c33cd11077edbeaaa95750; parent_hash: 0x753ac1fd; extrinsics (1): [0xb6e92b6d]]    
Nov 15 18:04:48.014  INFO  Pre-sealed block for proposal at 2. Hash now 0xe680ef911bd8a4c24ea2d7485255ca2cbe275cd51d0fa71dcc29846f84524d38, previously 0x625c206bc45416b3745d544d93626a4cacaf74bf73c33cd11077edbeaaa95750.    
Nov 15 18:04:48.014  INFO  Imported #2 (0xe6804d38)    
#+end_src

**** Doc

https://substrate.dev/docs/en/tutorials/create-your-first-substrate-chain/interact

** State Machines                                         :cs:state:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: state-machines
:EXPORT_DATE: 2020-11-28
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Theories about state machines
:EXPORT_OPTIONS: toc:2
:END:

*** State machines

[[https://en.wikipedia.org/wiki/Finite-state_machine][Finite-state machine]]
> The finite-state machine has less computational power 
than some other models of computation such as the 
Turing machine.[3] The computational power distinction 
means there are computational tasks that a Turing machine 
can do but an FSM cannot. This is because an FSM's 
memory is limited by the number of states it has. 
>
> Finite-state machines are a class of automata studied 
in automata theory and the theory of computation. 
In computer science, finite-state machines are widely used in 
modeling of application behavior, design of 
hardware digital systems, software engineering, 
compilers, network protocols, and the study of computation and languages.

[[https://en.wikipedia.org/wiki/State_machine_replication][State machine replication]]

> For the subsequent discussion a State Machine will be defined as the following tuple of values
> - A set of States
> - A set of Inputs
> - A set of Outputs
> - A transition function (Input  State  State)
> - An output function (Input  State  Output)
> - A distinguished State called Start.

> A State Machine begins at the State labeled Start. 
Each Input received is passed through the transition 
and output function to produce a new State and an Output. 
The State is held stable until a new Input is received, 
while the Output is communicated to the appropriate receiver.

*** Consensus

[[https://en.wikipedia.org/wiki/Consensus_(computer_science)][Consensus (computer science)]]

*** Turing completeness

[[https://en.wikipedia.org/wiki/Turing_completeness][Turing completeness]]

*** Oracle

[[https://en.wikipedia.org/wiki/Oracle_machine][Oracle machine]]
> An oracle machine can be conceived as a Turing machine 
connected to an oracle. The oracle, in this context, 
is an entity capable of solving some problem, which 
for example may be a decision problem or a function problem. 
The problem does not have to be computable; the oracle is not 
assumed to be a Turing machine or computer program. 
The oracle is simply a "black box" that is able to 
produce a solution for any instance of a given computational problem.

> In cryptography, oracles are used to make arguments for 
the security of cryptographic protocols where a hash function 
is used. A security reduction for the protocol is 
given in the case where, instead of a hash function, 
a random oracle answers each query randomly but 
consistently; the oracle is assumed to be available to 
all parties including the attacker, as the hash function is. 
Such a proof shows that unless the attacker solves 
the hard problem at the heart of the security reduction, 
they must make use of some interesting property of 
the hash function to break the protocol; they cannot 
treat the hash function as a black box (i.e., as a random oracle).

** Cheatsheet                                    :git:emacs:orgmode:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: cheatsheet
:EXPORT_DATE: 2020-10-29
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: My cheatsheet about Git and Emacs.
:EXPORT_OPTIONS: toc:2
:END:

*** Emacs & org-mode
**** References

- https://stackoverflow.com/questions/16186843/inline-code-in-org-mode
- https://orgmode.org/org.html#Emphasis-and-monospace

**** Examples

Indent code:
Ctrl + X, Tab, left/right

src_sh[:exports code]{echo -e "test"}

#+begin_src 
src_sh[:exports code]{echo -e "test"}
#+end_Src

~fn main()~ 

#+begin_src
~fn main()~ 
#+end_src

=verbatim text=

#+begin_src
=verbatim text=
#+end_src

*** Git commands


**** Git tutorial

https://github.com/git/git/blob/master/Documentation/gittutorial.txt

#+begin_src shell
$ git show HEAD^  # to see the parent of HEAD
$ git show HEAD^^ # to see the grandparent of HEAD
$ git show HEAD~4 # to see the great-great grandparent of HEAD
#+end_src

**** Git commit log

It outputs a list of the email domains who have committed to the repository in the last 100,000 commits.

#+begin_src shell
$ git log -n100000 --format="%ae" | cut -d@ -f2 | sort | uniq -c | sort -nr | less
#+end_src

**** Remote .git

#+begin_src shell
$ ls .git
$ rm .git
rm: .git: is a directory
$ rm -rf .git
#+end_src

**** Download a file from command line

#+begin_src shell
$ curl -LO https://upload.wikimedia.org/wikipedia/commons/c/c4/Creative-Tail-Halloween-ghost.svg
$ curl -L https://upload.wikimedia.org/wikipedia/commons/7/74/Twemoji2_1f47b.svg > ghost.svg
#+end_src

**** Cherry pick

#+begin_src shell
$ git remote add some_github_id https://github.com/some_github_id/rust-in-blockchain.git
$ git fetch some_github_id
$ git log some_github_id/master
$ git cherry-pick some_commit_hash
$ git diff HEAD^..HEAD
$ git push origin master
#+end_src

**** Reset a commit

#+begin_src shell
$ git reset HEAD^
$ git rm */~
$ git rm */*~
$ git commit --amend
$ git log
commit ad8b178eb99e414f7eb298798acbe1317099cc1b (HEAD -> master)
#+end_src

More: [[https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History][Git Tools - Rewriting History]]

**** Hide changes and do not commit

#+begin_src shell
$ git stash
#+end_src

**** Cancel hiding

#+begin_src shell
$ git stash pop 
#+end_src

**** Merge a PR and edit it

#+begin_src shell
$ git remote add <someones_github_id> https://github.com/<someones_github_id>/rust-in-blockchain.git
$ git fetch <someones_github_id>
remote: Enumerating objects: 11, done.
remote: Counting objects: 100% (11/11), done.
remote: Compressing objects: 100% (4/4), done.
remote: Total 8 (delta 4), reused 6 (delta 2), pack-reused 0
Unpacking objects: 100% (8/8), done.
From https://github.com/<someones_github_id>/rust-in-blockchain
 * [new branch]      master     -> <someones_github_id>/master # this one is on master branch

$ git merge <someones_github_id>/master
#+end_src

**** Add submodule to rib

#+begin_src shell
$ ln -> means link
#+end_src

**** Creat an aliase for syncing file 

#+begin_src shell
$ ln -s ../awesome-blockchain-rust/README.md awesome-blockchain-rust.md 
#+end_src

**** Recover to previous clean code

#+begin_src shell
$ git checkout -f
#+end_src

**** About PATH

#+begin_src shell
$ pwd
$ echo $PWD
$ export PATH=$PATH:$PWD
#+end_src

**** SSH

#+begin_src shell
$ eval `ssh-agent`
$ ssh-add
$ ssh -T git@github.com 
#+end_src

**** Generated a new key

#+begin_src shell
$ ssh-keygen -C your@email.com 
#+end_src

**** Move a file to current

#+begin_src shell
$ git mv www/contracts .
#+end_src
** Rust Cargo and More                       :rust:cargo:rustup:log:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: rust-cargo-etc
:EXPORT_DATE: 2020-11-14
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Understand Rust programming language.
:EXPORT_OPTIONS: toc:2
:END:

*** Cargo bin

#+begin_src shell
$ ~/.cargo/bin
-bash: /Users/aimeez/.cargo/bin: is a directory

$ cd ~/.cargo/bin
$ ls
basic-http-server	cargo-generate		diesel			rust-trending		ssmanager
cargo			cargo-make		lighthouse		rustc			ssserver
cargo-add		cargo-miri		makers			rustdoc			ssurl
cargo-casperlabs	cargo-rm		mdbook			rustfmt			wasm-pack
cargo-clippy		cargo-upgrade		mdbook-linkcheck	rustlings		wasm-pack.stamp
cargo-contract		cargo-watch		rls			rustup
cargo-fmt		cargo-web		rust-gdb		simple-http-server
cargo-fuzz		clippy-driver		rust-lldb		sslocal

$ which cargo
/Users/aimeez/.cargo/bin/cargo

$ ls -lh
total 496760
-rwxr-xr-x   1 aimeez  staff   5.1M Apr 26  2020 basic-http-server
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 cargo
-rwxr-xr-x   1 aimeez  staff   7.1M Sep 14 10:48 cargo-add
-rwxr-xr-x   1 aimeez  staff   1.0M Aug 25 13:56 cargo-casperlabs
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 cargo-clippy
-rwxr-xr-x   1 aimeez  staff   4.6M Nov  6 20:59 cargo-contract
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 cargo-fmt
-rwxr-xr-x   1 aimeez  staff   1.3M May 18 18:52 cargo-fuzz
-rwxr-xr-x   1 aimeez  staff   6.5M Oct 14 14:37 cargo-generate
-rwxr-xr-x   1 aimeez  staff   7.9M Oct 29 13:17 cargo-make
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 cargo-miri
-rwxr-xr-x   1 aimeez  staff   2.0M Sep 14 10:48 cargo-rm
-rwxr-xr-x   1 aimeez  staff   3.5M Sep 14 10:48 cargo-upgrade
-rwxr-xr-x   1 aimeez  staff   2.1M Aug 11 15:20 cargo-watch
-rwxr-xr-x   1 aimeez  staff   9.5M Oct 29 14:52 cargo-web
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 clippy-driver
-rwxr-xr-x   1 aimeez  staff   3.1M Jun 17 12:56 diesel
-rwxr-xr-x   1 aimeez  staff    42M Aug 11 12:46 lighthouse
-rwxr-xr-x   1 aimeez  staff   7.9M Oct 29 13:17 makers
-rwxr-xr-x   1 aimeez  staff    10M Sep 20 11:06 mdbook
-rwxr-xr-x   1 aimeez  staff   9.3M Sep 20 11:09 mdbook-linkcheck
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rls
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rust-gdb
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rust-lldb
-rwxr-xr-x   1 aimeez  staff   6.5M Jun 13 15:51 rust-trending
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rustc
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rustdoc
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rustfmt
-rwxr-xr-x   1 aimeez  staff   2.7M Jul 27 16:43 rustlings
-rwxr-xr-x  12 aimeez  staff   7.1M Jul 27 16:47 rustup
-rwxr-xr-x   1 aimeez  staff   2.6M Aug 11 15:12 simple-http-server
-rwxr-xr-x   1 aimeez  staff   6.1M Jun  8 11:05 sslocal
-rwxr-xr-x   1 aimeez  staff   4.1M Jun  8 11:04 ssmanager
-rwxr-xr-x   1 aimeez  staff   3.9M Jun  8 11:04 ssserver
-rwxr-xr-x   1 aimeez  staff   1.3M Jun  8 11:03 ssurl
-rwxr-xr-x   1 aimeez  staff   7.2M May 23 01:28 wasm-pack
-rw-r--r--   1 aimeez  staff    54B Oct 29 14:21 wasm-pack.stamp
#+end_src

*** Rustup toolchains

[[https://rust-lang.github.io/rustup/installation/index.html][The rustup book]]
>rustup installs rustc, cargo, rustup and other standard tools 
to Cargo's bin directory. On Unix it is located at $HOME/.cargo/bin 
and on Windows at %USERPROFILE%\.cargo\bin. 
This is the same directory that cargo install will 
install Rust programs and Cargo plugins.


Toolchains on my mac:

#+begin_src shell
$ ls ~/.rustup/
downloads	settings.toml	toolchains	update-hashes

$ ls ~/.rustup/toolchains/
1.34.2-x86_64-apple-darwin		nightly-2019-10-14-x86_64-apple-darwin	nightly-x86_64-apple-darwin
1.41.0-x86_64-apple-darwin		nightly-2020-03-19-x86_64-apple-darwin	stable-x86_64-apple-darwin
1.43.1-x86_64-apple-darwin		nightly-2020-05-15-x86_64-apple-darwin
1.45.2-x86_64-apple-darwin		nightly-2020-08-23-x86_64-apple-darwin

$ ls ~/.rustup/toolchains/stable-x86_64-apple-darwin/
bin	etc	lib	share

$ ls ~/.rustup/toolchains/stable-x86_64-apple-darwin/bin/
cargo		cargo-fmt	rls		rust-gdbgui	rustc		rustfmt
cargo-clippy	clippy-driver	rust-gdb	rust-lldb	rustdoc
#+end_src
*** Rust lang entry

[[https://github.com/rust-lang/rust/blob/efbaa413061c2a6e52f06f00a60ee7830fcf3ea5/compiler/rustc_passes/src/entry.rs#L50-L76][EntryPointType]]

[[https://github.com/rust-lang/rust/blob/56293097f7f877f1350a6cd00f79d03132f16515/compiler/rustc_codegen_cranelift/src/main_shim.rs][rust/compiler/rustc_codegen_cranelift/src/main_shim.rs]]

Rustc: #[lang = "start"]

[[https://github.com/rust-lang/rust/blob/master/library/std/src/rt.rs#L60][fn lang_start<T: crate::process::Termination + 'static>(main: fn() -> T, argc: isize, argv: *const *const u8,)]]

Rustc uses std to create the main() function,
with mymain() as one argument,
as lang-start for the operating system 
to start executing.

From [[https://play.rust-lang.org/][Rust playground]], we can generate LLVM code from 
our empty main function:

#+begin_src rust
fn main() {
}
#+end_src

The LLVM code:

#+begin_src llvm
; std::rt::lang_start
; Function Attrs: nonlazybind uwtable
define hidden i64 @_ZN3std2rt10lang_start17hd0d6144126b78ac1E(void ()* nonnull %main, i64 %argc, i8** %argv) unnamed_addr #1 !dbg !42 {
start:
#+end_src

** Rust Smart Contract               :blockchain:rust:smartcontract:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: rust-smart-contract
:EXPORT_DATE: 2020-11-21
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Learning resources and references.
:EXPORT_OPTIONS: toc:2
:END:

[[https://github.com/brson/rust-contract-comparison][rust-contract-comparison]]

[[http://troubles.md/why-write-smart-contracts-in-rust/][Why Write Smart Contracts in Rust?]]
> The future of smart contracts, in my eyes 
and the eyes of many others, lies with WebAssembly. 
This is a virtual machine specification 
which essentially acts as a portable and simple RISC ISA - since 
it matches the runtime model of 
a CPU many existing languages can be compiled to it unchanged. 
Apart from special-case DSLs like Solidity most languages 
expose the runtime model of the CPU somehow. 
Not only that, but its similarity to the CPU allows 
it to be compiled to incredibly efficient machine code 
without complex optimisations that can affect correctness 
and increase code complexity.

[[https://github.com/paritytech/fleetwood][Fleetwood]]
> *Future Work*
> 
> It would be nice to be able to write smart contracts 
that are easily compiled for different chains 
with no runtime overhead while allowing to use 
specific details of the underlying chain. 
While developing the Fleetwood technology stack 
we are trying to uphold this future goal 
by considering interoperability of new features in accordance to it.

** Rust and Computer Science                               :rust:cs:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: rust-cs
:EXPORT_DATE: 2020-11-21
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Rust and CS resources.
:EXPORT_OPTIONS: toc:2
:END:

*** CS lectures

[[https://cs140e.sergio.bz/syllabus/#schedule][CS140e]]: Stanfords CS140e Winter 2018 course
- [[https://cs140e.sergio.bz/syllabus/#schedule][Schedule, reads and code]]

[[https://reberhardt.com/cs110l/spring-2020/][CS 110L: Safety in Systems Programming]]
- [[https://reberhardt.com/cs110l/spring-2020/slides/lecture-18.pdf][Comparison between C and Rust]]

[[https://github.com/cis198-2016s][CIS 198 - Rust - Spring 2016]]
- [[https://cis198-2016s.github.io/projects/][Project page]]

[[https://people.eecs.berkeley.edu/~alexch/classes/CS294-F2020.html][CS294: Foundations of Probabilistic Proofs (F2020)]]

[[https://github.com/SmallPond/MIT6.828_OS][MIT6.828 Operating System Engineering]]


*** Reads and videos

Type system: [[https://v5.chriskrycho.com/journal/things-i-was-wrong-about/1-types/][Things I Was Wrong About: Types]]

[[https://arxiv.org/pdf/2010.07763.pdf][Refinement Types]]

[[https://www.cs.utexas.edu/~EWD/transcriptions/EWD03xx/EWD340.html][The Humble Programmer by Edsger W. Dijkstra]]

Book: [[https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-4.html#%_toc_start][Structure and Interpretation of Computer Programs]]

[[https://www.youtube.com/watch?v=j-BVv0XW1H8][How to learn programming | Charles Isbell and Michael Littman and Lex Fridman]]

[[https://www.youtube.com/watch?v=yzMVEbs8Zz0][Charles Isbell and Michael Littman: Machine Learning and Education | Lex Fridman Podcast #148]]

> joy

*** Rust language

[[https://lborb.github.io/book/][The Little Book of Rust Books]]

[[https://rust-unofficial.github.io/too-many-lists/index.html][Learn Rust With Entirely Too Many Linked Lists]]

[[https://people.mpi-sws.org/~jung/phd/thesis-screen.pdf][Understanding and Evolving the Rust Programming Language]] August 2020

[[https://wiki.alopex.li/RustStarterKit2020][Rust Starter Kit 2020]]

Video: [[https://www.youtube.com/watch?v=0zOg8_B71gE][Pascal Hertleif - Writing Idiomatic Libraries in Rust]]

Collections:
- Rust book: [[https://doc.rust-lang.org/stable/book/ch08-00-common-collections.html][Common Collections]]
- [[https://doc.rust-lang.org/stable/std/collections/index.html][Module std::collections]]
> To get this out of the way: you should probably just use ~Vec~ or ~HashMap~. 
These two collections cover most use cases for generic data storage and processing. 
They are exceptionally good at doing what they do. 
All the other collections in the standard library have 
specific use cases where they are the optimal choice, 
but these cases are borderline niche in comparison. 
Even when Vec and HashMap are technically suboptimal, 
they're probably a good enough choice to get started.
>
> Rust's collections can be grouped into four major categories:
>
> - Sequences: Vec, VecDeque, LinkedList
> - Maps: HashMap, BTreeMap
> - Sets: HashSet, BTreeSet
> - Misc: BinaryHeap

*** Copy and Clone in Rust

[[https://doc.rust-lang.org/stable/book/ch04-01-what-is-ownership.html][What Is Ownership?]]

This chapter is really good. The stack and heap are well explained.

[[https://doc.rust-lang.org/stable/book/appendix-03-derivable-traits.html?highlight=clone#clone-and-copy-for-duplicating-values][Clone and Copy for Duplicating Values]]

[[https://doc.rust-lang.org/core/clone/index.html][Module core::clone]]

> Differs from ~Copy~ in that ~Copy~ is implicit and extremely inexpensive, 
while ~Clone~ is always explicit and may or may not be expensive. 
In order to enforce these characteristics, Rust does not allow you to reimplement ~Copy~, 
but you may reimplement ~Clone~ and run arbitrary code.

Blog post:
[[https://hashrust.com/blog/moves-copies-and-clones-in-rust/][Moves, copies and clones in Rust]]

Not much new in this post if you've already read Rust book.


*** Rust discussion

[[https://readrust.net/computer-science][ReadRust: Computer Science]]

[[https://www.reddit.com/r/rust/comments/6nw22d/opinions_about_using_rust_instead_of_c_in/][Reddit discussion: Opinions about using Rust instead of C in Computer Science courses]]

Rust weaknesses:
[[https://www.reddit.com/r/rust/comments/jia2xn/what_are_some_of_rusts_weaknesses_as_a_language/][This question got a bunch of discussions]]

** Learn Programming                      :rust:lisp:programming:cs:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: learn-programming
:EXPORT_DATE: 2021-01-17
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Learning notes from books and lectures.
:EXPORT_OPTIONS: toc:2
:END:

*** Book: Code Complete

*Abstract Data Types (ADTs)*

An abstract data type is a collection of data and operations that work on that data. 
The operations both describe the data to the rest of the program and allow the rest of the program 
to change the data. The word data in abstract data type is used loosely. 
An ADT might be a graphics window with all the operations that affect it, 
a file and file operations, an insurance-rates table and the operations on it, or something else.

Understanding ADTs is essential to understanding object-oriented programming.
Without understanding ADTs, programmers create classes that are classes in name onlyin reality, 
they are little more than convenient carrying cases for loosely related collections of data and routines. 
With an understanding of ADTs, programmers can create classes that are easier to 
implement initially and easier to modify over time.

Thinking about ADTs first and classes second is an example of programming into a language vs. programming in one.

Abstract data types are exciting because you can use them to manipulate real-world entities 
rather than low-level, implementation entities. Instead of inserting a node into 
a linked list, you can add a cell to a spreadsheet, a new type of window to a list of 
window types, or another passenger car to a train simulation. Tap into the power of 
being able to work in the problem domain rather than at the low-level implementation domain!

*Reasons to Create a Class*

- Model real-world objects
- Model abstract objects
- Reduce complexity
- Isolate complexity
- Hide implementation details
- Limit effects of changes
- Hide global data
- Streamline parameter passing
- Make central points of control
- Facilitate reusable code
> NASAs Software Engineering Laboratory studied ten projects that pursued reuse aggressively (McGarry, Waligora, and McDermott 1989). In both the object-oriented and the functionally oriented approaches, the initial projects werent able to take much of their code from previous projects because previous projects hadnt estab- lished a sufficient code base. Subsequently, the projects that used functional design were able to take about 35 percent of their code from previous projects. Projects that used an object-oriented approach were able to take more than 70 percent of their code from previous projects. If you can avoid writing 70 percent of your code by planning ahead, do it!
>
>Notably, the core of NASAs approach to creating reusable classes does not involve designing for reuse. NASA identifies reuse candidates at the ends of their projects. They then perform the work needed to make the classes reusable as a special project at the end of the main project or as the first step in a new project. This approach helps prevent gold-platingcreation of functionality that isnt required and that unneces- sarily adds complexity.
- Plan for a family of programs
- Package related operations
- Accomplish a specific refactoring

*Classes to Avoid*

- *Avoid creating god classes*. Avoid creating omniscient classes that are all-knowing and all-powerful. If a class spends its time retrieving data from other classes using Get() and Set() routines (that is, digging into their business and telling them what to do), ask whether that functionality might better be organized into those other classes rather than into the god class (Riel 1996).
- *Eliminate irrelevant classes*. If a class consists only of data but no behavior, ask your- self whether its really a class and consider demoting it so that its member data just becomes attributes of one or more other classes.
- *Avoid classes named after verbs*. A class that has only behavior but no data is gener- ally not really a class. Consider turning a class like DatabaseInitialization() or String- Builder() into a routine on some other class.


*** Book: [[https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-4.html#%_toc_start][Structure and Interpretation of Computer Programs]]

*[[https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-10.html][1.1  The Elements of Programming]]*

- *Primitive expressions*, which represent the simplest entities the language is concerned with,
- *Means of combination*, by which compound elements are built from simpler ones, and
- *means of abstraction*, by which compound elements can be named and manipulated as units

*1.1.8  Procedures as Black-Box Abstractions*
- So a procedure definition should be able to suppress detail. The users of the procedure may not have written the procedure themselves, but may have obtained it from another programmer as a black box. A user should not need to know how the procedure is implemented in order to use it.

*1.2  Procedures and the Processes They Generate*
- A procedure is a pattern for the local evolution of a computational process. It specifies how each stage of the process is built upon the previous stage. We would like to be able to make statements about the overall, or global, behavior of a process whose local evolution has been specified by a procedure. This is very difficult to do in general, but we can at least try to describe some typical patterns of process evolution.


*** Videos: MIT 6.001 Structure and Interpretation, 1986

Coupled with the book: Structure and Interpretation of Computer Programs

I like this lecture a lot:
[[https://www.youtube.com/watch?v=PEwZL3H2oKg&list=PLE18841CABEA24090&index=5][Lecture 3A: Henderson Escher Example]]

Blur the line between what's data and what's a procedure.


** Smart Contracts                        :blockchain:smartcontract:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: smart-contracts
:EXPORT_DATE: 2021-01-06
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Smart contract engineering and papers
:EXPORT_OPTIONS: toc:2
:END:

*[[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-220.html][A Languge-Based Approach to Smart Contract Engineering]]*

> Writing Contracts as Finite State Machines 
>
> A Quartz contract definition adheres to a widely used structure for describing and analyzing
computer programs known as a finite state machine. Under this organization, a contract is 
in one of a fixed number of explicitly listed possible states, including a designated starting state. 
>
> Insights on Language Design
> 
> - Contract Lifecycles Nearly
> - Finite Virtual Resources
> - Cryptographic Hashing
> - Time-Based Logic
> - Authorization

[[https://www2.eecs.berkeley.edu/Pubs/TechRpts/2020/EECS-2020-178.html][Quartz: A Framework for Engineering Secure Smart Contracts]]
- TODO: read references

> The Quartz language contains several contract-specific features.
Many distributed ledgers, most notably Ethereum, have first-class
support for virtual currency that may be bound to contracts and
exchanged among them. State machines in Quartz use keywords to
check their balance or disburse tokens to an external contract. If
we wish to produce contracts for a ledger without first-class tokens,
we can emulate this functionality by adding an extra field and the
necessary operations to the generated implementations. Transition
authorization is treated as a first-class primitive in Quartz, unlike
in Solidity and other contract languages. Quartz allows contract
authors to express rich authorization constraints such as restricting
an operation to any member of a particular group or requiring
approval from all members of a group before it is executed. Finally,
Quartz restricts communication between state machines. A state
machine may send tokens to another state machine, but it cannot
invoke another machines transitions directly. This simplifies the expression and verification of contract logic. Note that Quartz makes
no assumptions about the behavior of the recipient, which may or
may not be another Quartz state machine, for model checking.
>
> Here, we formally define a subset of the operational semantics of the
Quartz DSL. Evaluation rules for expressions, which are generally
routine, are omitted for brevity. A Quartz state machine is formally
defined as a 4-tuple , 0,  ,   where  is a set of states, 0 is
the initial state,  is a set of transitions, and  is a set of fields, each
with a specific name and type.
>
> Why Model Checking and TLA+?
>
> We chose bounded model checking as Quartzs core verification
technique because it does not require significant intervention from
the end user, i.e., the contract author. Although a contract author
must write the invariants she would like to have verified, Quartz
fully automates the more difficult task of writing a formal specification of the contracts behavior and its execution environment
that is suitable as input to a model checker. Model checking also
offers immediately useful feedback to the user as output  an execution trace that produces a violation of one or more of the desired
properties. This feedback helps guide a contract author in making
refinements to her state machine.
> 
> TLA+ serves as Quartzs target specification language and its
verification backend. TLA+
and its model checker, TLC, are relatively mature, well-documented, and have been successfully applied
in developing and testing significant systems [40]. More modern
model checkers have since emerged, but they tend to be inherently
tied to the semantics of particular implementation languages such
as C [26] or operate at the low level of bytecode [24]. The flexibility of TLA+
s specification language simplifies Quartzs task of
generating a formal contract specification. This becomes especially
important when describing the execution semantics of Solidity,
which have important differences from the semantics of traditional
programming languages. Moreover, there are ongoing efforts to
modernize verification in TLA+
, such as symbolic model checking
with SMT solvers [32], that Quartz may be able to use in the future.
>
> Specification Generation
>
> Quartzs specification generator targets PlusCal, an intermediate
language built on top of the original TLA+
specification language.
>
> Quartz is able to translate state machine descriptions to Solidity
implementations, enabling seamless deployment once a contract
has been sufficiently validated by its developer. Quartz targets
Solidity rather than EVM bytecode for several reasons. Solidity is
more human readable than EVM bytecode, which means a contract
author may easily inspect and audit a generated implementation if
necessary. Moreover, there is an ongoing effort within the Ethereum
community to replace the original EVM with a new virtual machine
based on WebAssembly [20]. By targeting Solidity, Quartz remains
agnostic to this potential change.


[[https://dl.acm.org/doi/10.1145/3366370][Core Concepts, Challenges, and Future Directions in Blockchain: A Centralized Tutorial]]

> Contract Security Concerns
>
> Soliditys syntax and basic execution semantics are, by design, very similar to those of traditional
imperative programming languages, but writing a correct and secure smart contract can be challenging. This is because Ethereums contract execution model and mining process introduce subtleties to Soliditys behavior, many of which have no analogues in other programming languages
and platforms. Contract developers rely on their prior experiences and intuitions regarding the
execution of imperative code, and Soliditys efforts to present familiar syntax can obscure the underlying blockchains true execution semantics. Writing a correct and secure smart contract is
particularly important, because smart contracts are immutable. When a new contract is instantiated, its code is stored on the blockchains ledger and cannot be changed. In Section 8, we will
summarize some of the ongoing efforts to help developers avoid introducing bugs in their smart
contracts and to defend their contracts from potential attacks.

> TOWARD ROBUST SMART CONTRACTS
>
> Because smart contracts are intended to handle management of data and enforcement of rules in
high-stakes situations, and because they are both difficult to implement correctly and impossible
to modify once deployed, there is significant interest in applying techniques from formal methods
and programming languages research to the domain of smart contracts. The general goal of these
efforts is to allow developers to reason about and establish guarantees for the behavior of contracts
before they are deployed. This interest further intensified after the theft of funds from TheDAO, a
famous contract on the main Ethereum blockchain. Here, we summarize approaches belonging
to three categories: formal analysis of existing contract code, translation of contract code into
alternative languages that facilitate formal analysis, and alternative languages to express contract
logic. We close with a brief discussion of a slightly different approach to contract defense involving
bug bounties.


[[http://obsidian-lang.com/][Obsidian: A safer blockchain programming language]]

> Obsidian is a new programming language for writing smart contracts, which are programs for blockchain platforms.
>
> Written in Scala and Java

[[https://github.com/ethereum/solidity][Ethereum Foundation. The solidity contract-oriented programming language]]

[[https://github.com/ethereum/serpent][Ethereum Foundation. The serpent contract-oriented programming language]]

[[https://github.com/vyperlang/vyper][Pythonic Smart Contract Language for the EVM]]

[[https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7546538][Hawk: The Blockchain Model of Cryptography and Privacy-Preserving Smart Contracts]]

[[https://github.com/aeternity/aesophia][Stand alone compiler for the Sophia smart contract language]]
- Written in Erlang

[[https://github.com/ethereum/serpent][Serpent]]

> Serpent is an assembly language that compiles to EVM code that is extended with various high-level features. It can be useful for writing code that requires low-level opcode manipulation as well as access to high-level primitives like the ABI.
>
> Being a low-level language, Serpent is NOT RECOMMENDED for building applications unless you really really know what you're doing. The creator recommends Solidity as a default choice, LLL if you want close-to-the-metal optimizations, or Viper if you like its features though it is still experimental.

Building Better Systems Podcast:
[[https://www.youtube.com/watch?v=wT-AmR7wtI8][Episode #6 Dan Guido - What the hell are the blockchain people doing & why isn't it a dumpster fire?]]

** Interesting Rust Projects                                  :rust:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: rust-projects
:EXPORT_DATE: 2020-12-12
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Some interesting Rust projects, which might be helpful for the rib-os project.
:EXPORT_OPTIONS: toc:2
:END:


[[https://github.com/mozilla/rust-android-gradle][rust-android-gradle]]. Cross compile Rust Cargo projects for Android targets.

Rust windows: [[https://github.com/rust-windowing/android-ndk-rs][android-ndk-rs]]. Rust bindings to the Android NDK.

[[https://github.com/MortimerGoro/gvr-sys][gvr-sys]]. Rust bindings for Google VR SDK.

[[https://github.com/LEXUGE/dcompass][dcompass]]. High-performance DNS server with rule matching/DoT/DoH functionality built-in.

[[https://www.areweguiyet.com/][Are we UI yet]]

> As a low level language, Rust is perfectly suitable for making user interfaces the old fashioned way, with native APIs. However, competing in today's world typically means supporting many platforms, and that makes using native APIs an unattractive option for many.

Blog:
[[https://caballerocoll.com/blog/bevy-chess-tutorial/][Chess game in Rust using Bevy]]

** Error Handling                               :rust:errorhandling:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: error-handling
:EXPORT_DATE: 2020-11-21
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Error handling learning and practice.
:EXPORT_OPTIONS: toc:2
:END:

*** std::io::Error

- [[https://github.com/rust-bitcoin/rust-bitcoin/pull/494#issuecomment-716196725][rust-bitcoin discussion]]
- He also linked to his commemt on reddit:
  [[https://www.reddit.com/r/rust/comments/jbdk5x/blog_post_study_of_stdioerror/g8vzhjy/?utm_source=reddit&utm_medium=web2x&context=3][std::io::Error]]
  for which he commented to matklad's blog post 
  [[https://matklad.github.io/2020/10/15/study-of-std-io-error.html][study of std::io::Error]]

*** anyhow::Result

** Macros                                                 :macro:cs:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: macros
:EXPORT_DATE: 2020-12-20
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Dive in Macros
:EXPORT_OPTIONS: toc:2
:END:

*** Papers

- [[https://www.cs.utah.edu/plt/publications/macromod.pdf][Composable and Compilable Macros]] by Matthew Flatt, University of Utah
- [[https://www2.ccs.neu.edu/racket/pubs/icfp10-cf.pdf][Fortifying Macros]] by Ryan Culpepper & Matthias Felleisen, Northeastern University

*** Posts

- [[https://kevin.stravers.net/2017/11/practical-macros-in-racket-and-how-to-work-with-them.html][Practical macros in Racket and how to work with them]] by Kevin R. Stravers in 2017
- [[http://www.greghendershott.com/fear-of-macros/][Fear of Macros]] by Greg Hendershott in 2020
- [[http://www.greghendershott.com/2014/10/why-macros.html][Why macros?]] by Greg Hendershott in 2014
> Later I remembered Matthias Felleisen boiling down macros into three main categories:
>
> 1. *Binding forms*. You can make your own syntax for binding values to identifiers, including function definition forms. You may hear people say, in a Lisp you dont have to wait for the language designers to add a feature (like ~lambda~ for Java?). Using macros you can add it yourself. Binding forms is one example.
>
> 2. *Changing order of evaluation*. Something like ~or~ or ~if~ cant really be a function, because you want it to short-circuit  if the first test evaluates to true, dont evaluate the other test at all.
>
> 3. *Abstractions like domain specific langagues (DSLs)*. You want to provide a special language, which is simpler and/or more task-specific than the full/raw Lisp youre using. This DSL might be for users of your software, and/or it might be something that you use to help implement parts of your own program.
>
> Every macro is doing one of those three things. Only macros can really do the first two, at all1. Macros let you do the last one more elegantly.

*** Rust

- [[https://doc.rust-lang.org/book/ch19-06-macros.html][Rust Macros]]

*** Racket

- [[https://docs.racket-lang.org/guide/macros.html][Racket Macros guide]]
- [[https://docs.racket-lang.org/reference/Macros.html][Racket Macros reference]]

*** Emacs and orgmode

- orgmode [[https://orgmode.org/manual/Macro-Replacement.html][Maro Replacement]]
- [[https://orgmode.org/manual/Structure-of-Code-Blocks.html#Structure-of-Code-Blocks][Structure of Code Blocks]]
- [[https://lepisma.xyz/wiki/emacs/org-mode/macros.html][lepisma.xyz's notes]]
- [[https://github.com/fniessen/org-macros/][fniessen/org-macros]]

*** Lisp

- [[https://lisp-lang.org/learn/macros][Lisp lang Macros]]
- Macro chapters from *Practical Common Lisp*:
  - [[http://www.gigamonkeys.com/book/macros-standard-control-constructs.html][Macros: Standard Control Constructs]]
  - [[http://www.gigamonkeys.com/book/macros-defining-your-own.html][Macros: Defining Your Own]]
- [[https://www.gnu.org/software/emacs/manual/html_node/eintr/Lisp-macro.html#Lisp-macro][GNU Lisp macro]]
- [[https://www.gnu.org/software/emacs/manual/html_node/elisp/Macros.html#Macros][GNU Emacs Lisp Macros]]
- [[https://www.gnu.org/software/emacs/manual/html_node/elisp/Compiling-Macros.html#Compiling-Macros][Macros and Byte Compilation]]
> When a macro call appears in a Lisp program being compiled, the Lisp compiler calls the macro definition just as the interpreter would, and receives an expansion. But instead of evaluating this expansion, it compiles the expansion as if it had appeared directly in the program. As a result, the compiled code produces the value and side effects intended for the macro, but executes at full compiled speed. This would not work if the macro body computed the value and side effects itselfthey would be computed at compile time, which is not useful.
>
> In order for compilation of macro calls to work, the macros must already be defined in Lisp when the calls to them are compiled. The compiler has a special feature to help you do this: if a file being compiled contains a defmacro form, the macro is defined temporarily for the rest of the compilation of that file.

** Lisp-lang                                                  :lisp:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: lisp
:EXPORT_DATE: 2020-12-19
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Lisp programming
:EXPORT_OPTIONS: toc:2
:END:

*** Official 

Website: https://lisp-lang.org/

- [[http://sbcl.org/manual/index.html][SBCL 2.1.0 User Manual]]
- [[https://www.cliki.net/Exercices][Common Lisp Programming Exercises]]
- Style Guide: 
  - https://lisp-lang.org/style-guide/
  - http://labs.ariel-networks.com/cl-style-guide.html
- Writing Libraries: https://lisp-lang.org/learn/writing-libraries
- Test with Travis-CI: https://github.com/luismbo/cl-travis
- SLIME is the Superior Lisp Interaction Mode for Emacs: 
  https://common-lisp.net/project/slime/doc/html/

Emacs Lisp: [[https://www.gnu.org/software/emacs/manual/html_node/eintr/index.html][An Introduction to Programming in Emacs Lisp]]

*** Books

- [[https://www.cliki.net/Online%20tutorial][Recommended for beginners]]
- [[https://www.cliki.net/Lisp%20books][A list of favorite Lisp books.]]
- [[https://lispcookbook.github.io/cl-cookbook/][The Common Lisp Cookbook]]
- Book list: [[https://lisp-lang.org/books/][Lisp lang books]]
- *Structure and interpretation of computer programs*
- Onlisp

*** Posts

- [[https://fare.livejournal.com/188429.html][Why I haven't jumped ship from Common Lisp to Racket (just yet)]]
- [[https://www.xach.com/lisp/][Zach Beane's Lisp Resources]]

*** Videos

- [[https://www.youtube.com/watch?v=SPgjgybGb5o][Common Lisp - How to Start a New Project]]

*** Macros in Lisp

- [[https://lisp-lang.org/learn/macros][Lisp lang Macros]]
- Macro chapters from *Practical Common Lisp*:
  - [[http://www.gigamonkeys.com/book/macros-standard-control-constructs.html][Macros: Standard Control Constructs]]
  - [[http://www.gigamonkeys.com/book/macros-defining-your-own.html][Macros: Defining Your Own]]

*** History

- [[http://www.lispworks.com/documentation/HyperSpec/Body/01_ab.htm][1.1.2 History]]

*** Lectures

- [[https://www.youtube.com/watch?v=-J_xL4IGhJA&list=PLE18841CABEA24090][MIT 6.001 Structure and Interpretation, 1986]]
- [[https://www.youtube.com/watch?v=IcZSFewqr9k&list=PLkEwH_Z2WOlppy8oUfrGwFVlOuKyo3RO_&index=1][SICP]] mirror with Chinese script

** Haskell                                                 :haskell:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: haskell
:EXPORT_DATE: 2020-12-20
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Haskell programming
:EXPORT_OPTIONS: toc:2
:END:

[[http://learnyouahaskell.com/chapters][Learn You a Haskell for Great Good!]]

[[https://tryhaskell.org/][Try Haskell in your browser!]]

[[https://haskell-via-sokoban.nomeata.de/][Haskell via Sokoban]]

*** Pieces

[[http://learnyouahaskell.com/types-and-typeclasses#believe-the-type][Types and Typeclasses]]. Believe the type.
> Previously we mentioned that Haskell has a static type system. The type of every expression is known at compile time, which leads to safer code. If you write a program where you try to divide a boolean type with some number, it won't even compile. That's good because it's better to catch such errors at compile time instead of having your program crash. Everything in Haskell has a type, so the compiler can reason quite a lot about your program before compiling it.

[[http://learnyouahaskell.com/recursion#thinking-recursively][Thinking recursively]]
> So when trying to think of a recursive way to solve a problem, try to think of when a recursive solution doesn't apply and see if you can use that as an edge case, think about identities and think about whether you'll break apart the parameters of the function (for instance, lists are usually broken into a head and a tail via pattern matching) and on which part you'll use the recursive call.

[[https://notes.abhinavsarkar.net/2020/aoc-learnings][Learnings From Solving Advent Of Code 2020 In Haskell]]

*** Tools

[[https://docs.haskellstack.org/][Why Stack]]
> Stack is a build tool for Haskell designed to answer the needs of Haskell users new and experienced alike. It has a strong focus on reproducible build plans, multi-package projects, and a consistent, easy-to-learn interface, while providing the customizability and power experienced developers need. As a build tool, Stack does not stand alone. It is built on the great work provided by:

> The *Glasgow Haskell Compiler* (GHC), the premier Haskell compiler. Stack will manage your GHC installations and automatically select the appropriate compiler version for your project.
> The *Cabal build system*, a specification for defining Haskell packages, together with a library for performing builds.
> The *Hackage package repository*, providing more than ten thousand open source libraries and applications to help you get your work done.
> The *Stackage package collection*, a curated set of packages from Hackage which are regularly tested for compatibility. Stack defaults to using Stackage package sets to avoid dependency problems.

** Lua-lang                                                    :lua:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: lua
:EXPORT_DATE: 2020-12-19
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Lua programming
:EXPORT_OPTIONS: toc:2
:END:

Paper: [[https://www.lua.org/doc/jucs05.pdf][The Implementation of Lua 5.0]]

** Gamedev                                            :gamedev:game:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: gamedev
:EXPORT_DATE: 2020-12-19
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Game programming
:EXPORT_OPTIONS: toc:2
:END:

Gaming,learning and programming.

*** Languages

[[https://macoy.me/blog/programming/CakelispIntro][Cakelisp: a programming language for games]]

[[https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp][Game Oriented Assembly Lisp]]

Rustlisp for game dev: https://gamelisp.rs/

*** Posts and videos

[[https://michaelnielsen.org/blog/shirkys-law-and-why-most-social-software-fails/][Shirkys Law and why (most) social software fails]]

> The third reason developers fail to obey Shirkys Law is that its difficult to do. The most successful social software starts out doing one task supremely well. That task is simple, useful, and original. Its easy to come up with a task which is useful and original  just combine existing ideas in a new way, perhaps with some minor twists. But finding something thats also simple is hard. It has to be a single task that cant be reduced or explained in terms of existing tasks. Inventing or discovering such a task requires either a lot of hard work and social insight, or a great deal of luck. Its no wonder most social software fails.

[[http://worrydream.com/#!/LearnableProgramming][Learnable Programming]]

> - Not only skills but also a way of thinking
> - Get something on the screen as soon as possible
> - Create by reacting

[[https://nullprogram.com/blog/2017/04/27/][Two Games with Monte Carlo Tree Search]]

Video: [[https://www.youtube.com/watch?v=YyIQKBzIuBY][Alan Kay - Programming and Scaling]]

Video: [[https://www.youtube.com/watch?v=IGMiCo2Ntsc][Bret Victor - The Future of Programming]]

> goals and constrains
>
> "What you want to do", not instructions about "How to do"
>
> Pattern matching

[[https://www.youtube.com/watch?v=yzMVEbs8Zz0][Charles Isbell and Michael Littman: Machine Learning and Education | Lex Fridman Podcast #148]]

> joy

Gamification concept.

[[https://www.youtube.com/watch?v=ZZvRw71Slew][The Future of Creativity and Innovation is Gamification: Gabe Zichermann at TEDxVilnius]]

> Gabe Zichermann 
>
> Conquer a challenge -> feel great and feel successful -> do it more.
> The more success we feel, we more we are willing to keep doing it

[[https://www.youtube.com/watch?v=v5Qjuegtiyc][Gamification to improve our world: Yu-kai Chou at TEDxLausanne]]

> Ownership: gamers feel they own something, making them want to improve it
>
> Social: The most effective way to chage a person's behavior is showing them 
> what their neighbours do

Unity: [[https://www.youtube.com/watch?v=WLDgtRNK2VE][Devlog 2: Game architecture with ScriptableObjects | Open Projects]]

[[https://www.gamasutra.com/view/news/288343/7_educational_games_that_every_developer_should_study.php][7 educational games that every developer should study]]

[[https://opensource.com/article/20/12/lua-guess-number-game][Learn Lua by writing a "guess the number" game]]

[[https://all-things-andy-gavin.com/2011/03/12/making-crash-bandicoot-gool-part-9/][Making Crash Bandicoot  GOOL  part 9]]

[[https://mfiano.net/posts/Gamedev-Sleep-Repeat.html][Gamedev, Sleep, Repeat]]
> Game engines are large systems consisting of many moving parts. Good software engineering requires simplicity -- it is what allows a system to remain secure, stable, and coherent throughout its evolution. Simplicity itself requires a lot of work at the start of a project to reduce the idea to its essense, and lots of discipline over the lifetime of the project to be able to distinguish worthwhile changes from the pernicious ones. That is simply everything my game engine is not, because for such a complex piece of software such as a game engine, it is not easy to know HOW all the pieces fit together, just some vague idea. Complexity arises through the iterative process that is implementing and actually debugging problems with these features. Making a small change to get a engine feature to play nice with others could, and often does, adversely affects simplicity and elegance much later down the road during development.

[[https://mfiano.net/posts/Follow-up-to-Gamedev-Sleep-Repeat.html][Follow up to Gamedev, Sleep, Repeat]]
>  I am less interested in making games, and more interested in the design of game engines. A game engine is interesting to me because it requires discipline in many fields of study, and each implementation is different. The thing is, a game engine is a piece of software that manages the data flow for a particular game, or a particular category of games. It is nothing more than a set of choices someone made for you in order to write games in a particular way. Any given game engine could be productive or counter-productive in creating your game. Even using a general purpose game engine like Unity and Unreal is a trade-off, and for a significant game, you'll find you still have to work around or reimplement core engine features at the 11th hour to get your game shipped.

[[https://lostgarden.home.blog/2006/10/24/what-are-game-mechanics/][What are game mechanics?]] October 24, 2006 by Daniel Cook
> Humans are wired to solve black boxes. It is a fundamental aspect of our neurological learning wetware. We get real chemical rewards when we grok a problem or gain information that we suspect will help in grokking a black box. Evolution has selected for this behavior over thousands of generations since it is the biological reward system that encourages tool use and technological adoption. Without this built in addiction to problem solving, we would lack agriculture, medicine, architecture and other fundamental survival techniques that make the human species such a remarkably successful animal.

Boos that are [[https://lostgarden.home.blog/worth-reading/][worth reading]]

*** Programminguzzles

[[https://idyll.pub/post/blueberry-pancakes-28b1a2e1a8986c44ac091f08/][A toy algorithms problem]]

Tool: [[https://idyll.pub/post/announcing-idyll-pub-0a3eff0661df3446a915700d/][Publish interactive blog posts and explorable explanations with Idyll's free hosting service.]]

[[https://www.cliki.net/Exercices][Common Lisp Programming Exercises]]

[[https://www.ic.unicamp.br/~meidanis/courses/mc336/2006s2/funcional/L-99_Ninety-Nine_Lisp_Problems.html][L-99: Ninety-Nine Lisp Problems]]

[[http://www.informatimago.com/develop/lisp/l99/index.html][Solutions to Ninety-Nine Lisp Problems]]

[[https://auth0.com/blog/advent-of-code-tips-tricks/][Tips and Tricks for Solving Advent of Code's Puzzles]]

> You should always keep in mind that Advent of Code puzzles were meant to be solved. The many considerations that go into making an Advent of Code puzzle include:
> 
> - For a given input (remember, every participant has their own unique input), there is one and only one correct answer.
> - Avoiding expectations of domain-specific knowledge, including computer science. The puzzles arent made with the assumption that youve taken a data structures course or even any computer science course. You are expected to know how to do a little coding.
> - Trying not to make the reader make any assumptions. In fact, the text of the puzzle often repeats and highlights important details. Eric has observed that for every sentence, theres a user that skipped only that sentence.
> - Every day has two puzzles, with the end of the first puzzle acting as a kind of checkpoint. The second puzzle is always a twist on the first, and its meant to simulate the real-world experience of changing requirements.
> - Generally, the later in the month, the more challenging the puzzle. They throw in the occasional off-difficulty puzzle to control pacing and to keep participants from burning out.
> - Some earlier puzzles may be simpler versions of more difficult puzzles that appear later. This is Advent of Codes way of preparing you.
> - The puzzles vary in type from day to day to keep things interesting, and weekend puzzles are more involved than weekday puzzles.
> - Using a compiled language to solve the puzzles wont give you any noticeable speed advantage over using an interpreted language. If your code is still working on a solution after about a minute, youre probably taking the wrong approach. To quote the About page, every problem has a solution that completes in at most 15 seconds on ten-year-old hardware.

[[https://blog.vero.site/post/advent-leaderboard][Advent of Code: How to Leaderboard]]

> Another aspect is the unique two-part format of each puzzle. Even though they use the same input, you dont get to see the second part until after youve solved the first one, a feature that Eric Wastl (AoCs creator) has taken full advantage of in designing puzzles. The second part is often a surprising twist on the first part, which keeps you on your toes and challenges you to keep your code moderately general or refactorable in a way that I think almost no other programming challenges do. This sometimes even happens between days in a calendar, when a puzzle turns out to be about some model of computation you implemented two or five or ten days ago  hope you kept your code and remember how it works!

[[http://web.mit.edu/puzzle/www/][MIT Puzzle Club]]

[[https://web.mit.edu/puzzle/www/2014/round/knights/][The Red and White Knights]]

[[https://github.com/Bogdanp/awesome-advent-of-code][Awesome AoC]]

Looks old:
[[https://ipsc.ksp.sk/rules][Internet Problem Solving Contest]]

** PGP                                      :pgp:keybase:protonmail:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: pgp
:EXPORT_DATE: 2020-11-24
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: PGP, Keybase, Protonmail
:EXPORT_OPTIONS: toc:2
:END:


My PGP public key is hosting on my own website:
https://impl.dev/keys/aimeez.asc

Keybase and Protonmail use their own ways to generate new keys.
Users can download a PGP private key from Protonmail
and import it to Keybase.
Keybase will generate a new public key from the private key,
which means the user will have two public keys with the same
private key.

My requirement is to copy/paste the public key to Keybase, 
but not another new public key.
So this isn't what I need.
I keep a Keybase ID though: https://keybase.io/aimeedeer

References: 
- [[https://book.keybase.io/docs/cli#basics][Keybase Book: Command Line]]
- Protonmail: [[https://protonmail.com/blog/what-is-pgp-encryption/][What is PGP encryption and how does it work?]]
- [[https://www.pitt.edu/~poole/PGP.htm][PGP 6.5.8 Pretty Good Privacy]].
  Downloading, Installing, Setting Up, and Using this Encryption Software
  A Tutorial for Beginners to PGP

** Data Structures in Popular Blockchains :blockchain:rust:bitcoin:ethereum:polkadot:substrate:near:nervos@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: data-structures-in-popular-blockchains
:EXPORT_DATE: 2020-11-02
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Data structures in popular rust blockchains.
:EXPORT_OPTIONS: toc:2
:END:


Not as simple as I thought,
data structure are designed quite differently in different projects.

Let's take a look at some examples.

*** [[https://github.com/rust-bitcoin/rust-bitcoin][Bitcoin]]

[[https://en.bitcoin.it/wiki/Protocol_documentation#Block_Headers][Bitcoin Headers]]

[[https://en.bitcoin.it/wiki/Block_hashing_algorithm][Block hashing algorithm]]

>A block header contains these fields:
4  Bytes Version	       		Block version number
32 Bytes hashPrevBlock		256-bit hash of the previous block header
32 Bytes hashMerkleRoot		256-bit hash based on all of the transactions in the block
4 Bytes	 Time			Current block timestamp as seconds since 1970-01-01T00:00 UTC
4 Bytes	 Bits			Current target in compact format
4 Bytes	 Nonce			32-bit number (starts at 0)

[[https://docs.rs/bitcoin/0.25.0/bitcoin/][Rust Bitcoin Library]]

I started with the well-known example of Bitcoin.
Its protocol is simple and clearly explained in the whitepaper.

src: rust-bitcoin/src/blockdata/block.rs

I like developers put an introduction in front of a page!

#+begin_src rust
//! Bitcoin Block
//!
//! A block is a bundle of transactions with a proof-of-work attached,
//! which commits to an earlier block to form the blockchain. This
//! module describes structures and functions needed to describe
//! these blocks and the blockchain.
//!
#+end_src

A Bitcoin block data structure is simple,
and it looks like this:

#+begin_src rust
/// A Bitcoin block, which is a collection of transactions with an attached
/// proof of work.
#[derive(PartialEq, Eq, Clone, Debug)]
pub struct Block {
    /// The block header
    pub header: BlockHeader,
    /// List of transactions contained in the block
    pub txdata: Vec<Transaction>
}
#+end_src


And the blockheader:

#+begin_src rust
/// A block header, which contains all the block's information except
/// the actual transactions
#[derive(Copy, PartialEq, Eq, Clone, Debug)]
pub struct BlockHeader {
    /// The protocol version. Should always be 1.
    pub version: i32,
    /// Reference to the previous block in the chain
    pub prev_blockhash: BlockHash,
    /// The root hash of the merkle tree of transactions in the block
    pub merkle_root: TxMerkleNode,
    /// The timestamp of the block, as claimed by the miner
    pub time: u32,
    /// The target value below which the blockhash must lie, encoded as a
    /// a float (with well-defined rounding, of course)
    pub bits: u32,
    /// The nonce, selected to obtain a low enough blockhash
    pub nonce: u32,
}
#+end_src

In order to save disk space, Bitcoin uses Merkle tree to compress
transaction history.
[[https://en.wikipedia.org/wiki/Merkle_tree][Merkle tree]] is a binary hash tree.
The `merkle_root` in the `BlockHeader` struct refers to
the root of a Merkle tree,
which indicates the proof of transaction history.

[[https://bitcoin.org/bitcoin.pdf][Bitcoin Whitepaper]] is simple paper that explains
its architecture.

Then let's take a look at its value field, `txdata: Vec<Transaction>`.

#+begin_src rust
//! Bitcoin Transaction
//!
//! A transaction describes a transfer of money. It consumes previously-unspent
//! transaction outputs and produces new ones, satisfying the condition to spend
//! the old outputs (typically a digital signature with a specific key must be
//! provided) and defining the condition to spend the new ones. The use of digital
//! signatures ensures that coins cannot be spent by unauthorized parties.
//!
//! This module provides the structures and functions needed to support transactions.
//!
#+end_src

[[https://docs.rs/bitcoin/0.25.0/bitcoin/blockdata/transaction/struct.Transaction.html][Struct bitcoin::blockdata::transaction::Transaction]]

In Bitcoin, transactions issues started with
searching for recievers' addresses.
Then find the input UTXOs with approved signature.
So the input and output data structures are a bit different.

#+begin_src rust
/// A transaction output, which defines new coins to be created from old ones.
#[derive(Clone, PartialEq, Eq, Debug, Hash)]
pub struct TxOut {
    /// The value of the output, in satoshis
    pub value: u64,
    /// The script which must satisfy for the output to be spent
    pub script_pubkey: Script
}
#+end_src

#+begin_src rust
/// A transaction input, which defines old coins to be consumed
#[derive(Clone, PartialEq, Eq, Debug, Hash)]
pub struct TxIn {
    /// The reference to the previous output that is being used an an input
    pub previous_output: OutPoint,
    /// The script which pushes values on the stack which will cause
    /// the referenced output's script to accept
    pub script_sig: Script,
    /// The sequence number, which suggests to miners which of two
    /// conflicting transactions should be preferred, or 0xFFFFFFFF
    /// to ignore this feature. This is generally never used since
    /// the miner behaviour cannot be enforced.
    pub sequence: u32,
    /// Witness data: an array of byte-arrays.
    /// Note that this field is *not* (de)serialized with the rest of the TxIn in
    /// Encodable/Decodable, as it is (de)serialized at the end of the full
    /// Transaction. It *is* (de)serialized with the rest of the TxIn in other
    /// (de)serialization routines.
    pub witness: Vec<Vec<u8>>
}
#+end_src

*** [[https://github.com/openethereum/openethereum][Ethereum]]

OpenEthereum is Ethereum 1.0 Rust client.

Different from Bitcoin's data structure,
Ethereum introduces one more field.

src: openethereum/ethcore/types/src/block.rs

#+begin_src rust
/// A block, encoded as it is on the block chain.
#[derive(Default, Debug, Clone, PartialEq)]
pub struct Block {
	/// The header of this block.
	pub header: Header,
	/// The transactions in this block.
	pub transactions: Vec<UnverifiedTransaction>,
	/// The uncles of this block.
	pub uncles: Vec<Header>,
}
#+end_src

Its header data structure is much more complicated compared to Bitcoin.

src: openethereum/ethcore/types/src/header.rs

#+begin_src rust
/// A block header.
///
/// Reflects the specific RLP fields of a block in the chain with additional room for the seal
/// which is non-specific.
///
/// Doesn't do all that much on its own.
#[derive(Debug, Clone, Eq, MallocSizeOf)]
pub struct Header {
	/// Parent hash.
	parent_hash: H256,
	/// Block timestamp.
	timestamp: u64,
	/// Block number.
	number: BlockNumber,
	/// Block author.
	author: Address,

	/// Transactions root.
	transactions_root: H256,
	/// Block uncles hash.
	uncles_hash: H256,
	/// Block extra data.
	extra_data: Bytes,

	/// State root.
	state_root: H256,
	/// Block receipts root.
	receipts_root: H256,
	/// Block bloom.
	log_bloom: Bloom,
	/// Gas used for contracts execution.
	gas_used: U256,
	/// Block gas limit.
	gas_limit: U256,

	/// Block difficulty.
	difficulty: U256,
	/// Vector of post-RLP-encoded fields.
	seal: Vec<Bytes>,

	/// Memoized hash of that header and the seal.
	hash: Option<H256>,
}
#+end_src

I can't fully understand the header data structure
design just from the code.
I guess I need to reread [[https://ethereum.github.io/yellowpaper/paper.pdf][Ethereum Yellow Paper]].

src: openethereum/ethcore/types/src/transaction/transaction.rs

#+begin_src rust
/// A set of information describing an externally-originating message call
/// or contract creation operation.
#[derive(Default, Debug, Clone, PartialEq, Eq, MallocSizeOf)]
pub struct Transaction {
	/// Nonce.
	pub nonce: U256,
	/// Gas price.
	pub gas_price: U256,
	/// Gas paid up front for transaction execution.
	pub gas: U256,
	/// Action, can be either call or contract create.
	pub action: Action,
	/// Transfered value.
	pub value: U256,
	/// Transaction data.
	pub data: Bytes,
}
#+end_src

Yellow paper:
>The Transaction. A transaction (formally, T) is a
single cryptographically-signed instruction constructed by
an actor externally to the scope of Ethereum.
on1
>
>There are two types of transactions: those
which result in message calls and those which result in
the creation of new accounts with associated code (known
informally as contract creation').

#+begin_src rust
/// Transaction action type.
#[derive(Debug, Clone, PartialEq, Eq, MallocSizeOf)]
pub enum Action {
	/// Create creates new contract.
	Create,
	/// Calls contract at given address.
	/// In the case of a transfer, this is the receiver's address.'
	Call(Address),
}
#+end_src

The "contract" in the code comments are referring to a "smart contract" 
on the Ethereum blockchain platform, which can be considered 
as backend service in traditional internet programming, 
and a dapp, which with the full name of "decentralized application", 
can be regarded as the frontend.

*** [[https://github.com/paritytech/polkadot][Polkadot]]

Polkadot is built on Substrate, a blockchain framework.
The Substrate doc has explainations of its [[https://substrate.dev/docs/en/knowledgebase/learn-substrate/extrinsics#block-structure][Block Structure]]
> A block in Substrate is composed of a header and 
  an array of extrinsics. The header contains a
  block height, parent hash, extrinsics root, state root, and digest. 

src: core-primitives/src/lib.rs

src: parachain/test-parachains/adder/src/lib.rs

#+begin_src rust
#[derive(Default, Clone, Hash, Eq, PartialEq, Encode, Decode)]
pub struct HeadData {
	/// Block number
	pub number: u64,
	/// parent block keccak256
	pub parent_hash: [u8; 32],
	/// hash of post-execution state.
	pub post_state: [u8; 32],
}
#+end_src 

#+begin_src rust
/// Block data for this parachain.
#[derive(Default, Clone, Encode, Decode)]
pub struct BlockData {
	/// State to begin from.
	pub state: u64,
	/// Amount to add (overflowing)
	pub add: u64,
}
#+end_src

#+begin_src rust
/// Execute a block body on top of given parent head, producing new parent head
/// if valid.
pub fn execute(
	parent_hash: [u8; 32],
	parent_head: HeadData,
	block_data: &BlockData,
) -> Result<HeadData, StateMismatch> {
	debug_assert_eq!(parent_hash, parent_head.hash());

	if hash_state(block_data.state) != parent_head.post_state {
		return Err(StateMismatch);
	}

	let new_state = block_data.state.overflowing_add(block_data.add).0;

	Ok(HeadData {
		number: parent_head.number + 1,
		parent_hash,
		post_state: hash_state(new_state),
	})
}
#+end_src

src: substrate/primitives/blockchain/src/header_metadata.rs

#+begin_src rust
/// Handles header metadata: hash, number, parent hash, etc.
pub trait HeaderMetadata<Block: BlockT> {
	/// Error used in case the header metadata is not found.
	type Error;

	fn header_metadata(
		&self,
		hash: Block::Hash,
	) -> Result<CachedHeaderMetadata<Block>, Self::Error>;
	fn insert_header_metadata(
		&self,
		hash: Block::Hash,
		header_metadata: CachedHeaderMetadata<Block>,
	);
	fn remove_header_metadata(&self, hash: Block::Hash);
}
#+end_src

src: substrate/primitives/blockchain/src/backend.rs

*** [[https://github.com/near/nearcore.git][NEAR]]

NEAR has two types of block structure that looks more or less the same.
I choose to use the "V2" version as the example code.

src: nearcore/core/primitives/src/block.rs

#+begin_src rust
#[derive(BorshSerialize, BorshDeserialize, Serialize, Debug, Clone, Eq, PartialEq)]
pub struct BlockV2 {
    pub header: BlockHeader,
    pub chunks: Vec<ShardChunkHeader>,
    pub challenges: Challenges,

    // Data to confirm the correctness of randomness beacon output
    pub vrf_value: near_crypto::vrf::Value,
    pub vrf_proof: near_crypto::vrf::Proof,
}
#+end_src

src: nearcore/core/primitives/src/block_header.rs

#+begin_src rust
/// Versioned BlockHeader data structure.
/// For each next version, document what are the changes between versions.
#[derive(BorshSerialize, BorshDeserialize, Serialize, Debug, Clone, Eq, PartialEq)]
pub enum BlockHeader {
    BlockHeaderV1(Box<BlockHeaderV1>),
    BlockHeaderV2(Box<BlockHeaderV2>),
}
#+end_src

Still, we choose to use V2 code.

#+begin_src rust
/// V1 -> V2: Remove `chunks_included` from `inner_reset`
#[derive(BorshSerialize, BorshDeserialize, Serialize, Debug, Clone, Eq, PartialEq)]
#[borsh_init(init)]
pub struct BlockHeaderV2 {
    pub prev_hash: CryptoHash,

    /// Inner part of the block header that gets hashed, split into two parts, one that is sent
    ///    to light clients, and the rest
    pub inner_lite: BlockHeaderInnerLite,
    pub inner_rest: BlockHeaderInnerRestV2,

    /// Signature of the block producer.
    pub signature: Signature,

    /// Cached value of hash for this block.
    #[borsh_skip]
    pub hash: CryptoHash,
}
#+end_src

src: nearcore/core/primitives/src/sharding.rs

#+begin_src rust
#[derive(BorshSerialize, BorshDeserialize, Serialize, Clone, PartialEq, Eq, Debug)]
#[borsh_init(init)]
pub struct ShardChunkHeaderV2 {
    pub inner: ShardChunkHeaderInner,

    pub height_included: BlockHeight,

    /// Signature of the chunk producer.
    pub signature: Signature,

    #[borsh_skip]
    pub hash: ChunkHash,
}
#+end_src

#+begin_src rust
#[derive(BorshSerialize, BorshDeserialize, Serialize, Clone, PartialEq, Eq, Debug)]
pub struct ShardChunkHeaderInner {
    /// Previous block hash.
    pub prev_block_hash: CryptoHash,
    pub prev_state_root: StateRoot,
    /// Root of the outcomes from execution transactions and results.
    pub outcome_root: CryptoHash,
    pub encoded_merkle_root: CryptoHash,
    pub encoded_length: u64,
    pub height_created: BlockHeight,
    /// Shard index.
    pub shard_id: ShardId,
    /// Gas used in this chunk.
    pub gas_used: Gas,
    /// Gas limit voted by validators.
    pub gas_limit: Gas,
    /// Total balance burnt in previous chunk
    pub balance_burnt: Balance,
    /// Outgoing receipts merkle root.
    pub outgoing_receipts_root: CryptoHash,
    /// Tx merkle root.
    pub tx_root: CryptoHash,
    /// Validator proposals.
    pub validator_proposals: Vec<ValidatorStake>,
}
#+end_src

src: nearcore/core/primitives/src/challenge.rs

#+begin_src rust
#[derive(BorshSerialize, BorshDeserialize, Serialize, PartialEq, Eq, Clone, Debug)]
#[borsh_init(init)]
pub struct Challenge {
    pub body: ChallengeBody,
    pub account_id: AccountId,
    pub signature: Signature,

    #[borsh_skip]
    pub hash: CryptoHash,
}

pub type Challenges = Vec<Challenge>;
#+end_src

Seems NEAR heavily typed their data.
I couldn't find NEAR's architecture design 
from its paper or documentation.

*** [[https://github.com/nervosnetwork/ckb][Nervos CKB]]

src: ckb/util/types/src/core/cell.rs

#+begin_src rust
#[derive(Clone, Eq, PartialEq, Default)]
pub struct CellMeta {
    pub cell_output: CellOutput,
    pub out_point: OutPoint,
    pub transaction_info: Option<TransactionInfo>,
    pub data_bytes: u64,
    /// In memory cell data and its hash
    /// A live cell either exists in memory or DB
    /// must check DB if this field is None
    pub mem_cell_data: Option<(Bytes, Byte32)>,
}
#+end_src

src: ckb/util/types/src/generated/blockchain.rs

#+begin_src rust
#[derive(Debug, Default)]
pub struct BlockBuilder {
    pub(crate) header: Header,
    pub(crate) uncles: UncleBlockVec,
    pub(crate) transactions: TransactionVec,
    pub(crate) proposals: ProposalShortIdVec,
}
#+end_src

#+begin_src rust
#[derive(Debug, Default)]
pub struct UncleBlockBuilder {
    pub(crate) header: Header,
    pub(crate) proposals: ProposalShortIdVec,
}
#+end_src 

There is almost no comment on these codes,
and I don't understand that `ProposalShortIdVec` means.
How they define `UncleBlockVec`, which raises 
new questions about "an uncle block". 
I hope there is a meaningful explanation here 
to eliminate the confusion of learning its code.

I finally found an [[https://github.com/nervosnetwork/rfcs/blob/master/rfcs/0019-data-structures/0019-data-structures.md][explaination of data structure]]
from its GitHub doc.
It would be much convenient if I could 
read this information in code comments.

In Bitcoin, the uncle block is stored in the header data;
In CKB, it is stored in the block directly as a field.
I don't have any further thoughts here at the moment.

After reading this page, I still don't know
what `ProposalShortIdVec` is.
I guess that might because I lack some pre-knowledge to start with.


src: ckb/util/types/src/core/cell.rs

#+begin_src rust
#[derive(Default)]
pub struct CellMetaBuilder {
    cell_output: CellOutput,
    out_point: OutPoint,
    transaction_info: Option<TransactionInfo>,
    data_bytes: u64,
    mem_cell_data: Option<(Bytes, Byte32)>,
}
#+end_src

src: ckb/util/types/src/core/transaction_meta.rs

#+begin_src rust
#[derive(Default, Debug, PartialEq, Eq, Clone)]
pub struct TransactionMeta {
    pub(crate) block_number: u64,
    pub(crate) epoch_number: u64,
    pub(crate) block_hash: Byte32,
    pub(crate) cellbase: bool,
    /// each bits indicate if transaction has dead cells
    pub(crate) dead_cell: BitVec,
}
#+end_src

src: ckb/util/types/src/core/blockchain.rs


*** More to do

- Solana
** Deal With Git Submodule in Hugo Themes       :git:submodule:hugo:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: git-submodule-hugo-theme
:EXPORT_DATE: 2020-10-31
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: The problems I've met when I use Hugo themes, and how I solved it.
:EXPORT_OPTIONS: toc:2
:END:

I use hugo themes for this website, and I met problems.

*** Begin with Hugo and others' themes

I go inside the `themes` folder, and clone all three repos
followed the readme.

#+begin_src shell
$ cd themes/
$ git clone https://github.com/kaushalmodi/hugo-bare-min-theme.git
$ git clone https://github.com/kaushalmodi/hugo-search-fuse-js
$ git clone https://github.com/kaushalmodi/hugo-debugprint
#+end_src

Check status.
My file `cheatsheet.org` changes can be ignored.

#+begin_src shell
$ cd ..
$ git status

On branch master
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   cheatsheet.org

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	content/posts/cheatsheet.md
	themes/

no changes added to commit (use "git add" and/or "git commit -a")
#+end_src

I add it to git.

#+begin_src shell
$ git add .

warning: adding embedded git repository: themes/hugo-bare-min-theme
hint: You've added another git repository inside your current repository.
hint: Clones of the outer repository will not contain the contents of
hint: the embedded repository and will not know how to obtain it.
hint: If you meant to add a submodule, use:
hint: 
hint: 	git submodule add <url> themes/hugo-bare-min-theme
hint: 
hint: If you added this path by mistake, you can remove it from the
hint: index with:
hint: 
hint: 	git rm --cached themes/hugo-bare-min-theme
hint: 
hint: See "git help submodule" for more information.
warning: adding embedded git repository: themes/hugo-debugprint
warning: adding embedded git repository: themes/hugo-search-fuse-js
#+end_src

I follow the hint.

#+begin_src shell
$ git rm --cached themes/hugo-bare-min-theme

error: the following file has staged content different from both the
file and the HEAD:
    themes/hugo-bare-min-theme
(use -f to force removal)

$ git rm -f --cached themes/hugo-bare-min-theme

rm 'themes/hugo-bare-min-theme'
#+end_src

And I check the status again.

#+begin_src shell
$ ls themes/

hugo-bare-min-theme	hugo-debugprint		hugo-search-fuse-js

$ git status

On branch master
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	modified:   cheatsheet.org
	new file:   content/posts/cheatsheet.md
	new file:   themes/hugo-debugprint
	new file:   themes/hugo-search-fuse-js

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	themes/hugo-bare-min-theme/
#+end_src

Then I add files.

#+begin_src shell
$ git add .

warning: adding embedded git repository: themes/hugo-bare-min-theme
hint: You've added another git repository inside your current repository.
hint: Clones of the outer repository will not contain the contents of
hint: the embedded repository and will not know how to obtain it.
hint: If you meant to add a submodule, use:
hint: 
hint: 	git submodule add <url> themes/hugo-bare-min-theme
hint: 
hint: If you added this path by mistake, you can remove it from the
hint: index with:
hint: 
hint: 	git rm --cached themes/hugo-bare-min-theme
hint: 
hint: See "git help submodule" for more information.
#+end_src

I am confused.
But I keep trying.

#+begin_src shell
$ git add themes/hugo-bare-min-theme/
$ git status

On branch master
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	modified:   cheatsheet.org
	new file:   content/posts/cheatsheet.md
	new file:   themes/hugo-bare-min-theme
	new file:   themes/hugo-debugprint
	new file:   themes/hugo-search-fuse-js
#+end_src

Then I commit these changes one by one.

#+begin_src shell
$ git add content/posts/cheatsheet.md
$ git add themes/hugo-bare-min-theme/
$ git add themes/hugo-debugprint/
$ git add themes/hugo-search-fuse-js/
$ git commit -m"submodule"

[master ece9977] submodule
 5 files changed, 135 insertions(+), 1 deletion(-)
 create mode 100644 content/posts/cheatsheet.md
 create mode 160000 themes/hugo-bare-min-theme
 create mode 160000 themes/hugo-debugprint
 create mode 160000 themes/hugo-search-fuse-js

$ git push origin master
#+end_src

*** Deploy: Netlify build failed

I push the source code to GitHub and use Netlify for auto-building.
Howevery, Netlify build failed with 
the error message says something wrong with submodules.

#+begin_src shell
Error checking out submodules: fatal: No url found for submodule path 'themes/hugo-bare-min-theme' in .gitmodules
Failing build: Failed to prepare repo
Failed during stage 'preparing repo': Error checking out submodules: fatal: No url found for submodule path 'themes/hugo-bare-min-theme' in .gitmodules
: exit status 128
#+end_src

I think I met this problem before when I built [[https://rustinblockchain][rib.rs]] website in Hugo.
But I can remember how I solved it at last.
(That's why I take notes now ;)

*** Remove submodules

I go inside of each theme repo, and try to remove the `.git` file.

#+begin_src shell
$ cd hugo-bare-min-theme/
$ git rm .git

fatal: pathspec '.git' did not match any files

$ git rm -rf .git

fatal: pathspec '.git' did not match any files

$ rm -rf .git

$ cd ..
$ cd hugo-debugprint/
$ rm -rf .git/
$ cd ..
$ cd hugo-search-fuse-js/
$ rm -rf .git/
#+end_src

Again, check status.

#+begin_src shell
$ cd ..
$ git submodule status

fatal: no submodule mapping found in .gitmodules for path 'themes/hugo-bare-min-theme'

$ git status
On branch master
nothing to commit, working tree clean
#+end_src

It's interesting, and I am super confusing now.
I don't know what to do, and try something unreasonable.
I go to github.com/my/repo, and delete the `.gitmodules`.
Then I `git pull` changes to my local repo.

Now check the status.

#+begin_src shell
$ git submodule status

fatal: no submodule mapping found in .gitmodules for path 'themes/hugo-bare-min-theme'

$ cat .git/modules/

cat: .git/modules/: Is a directory

$ ls .git/modules/

themes
#+end_src

I try more ways to clean these uncleared-relational submodules.

#+begin_src shell
$ git rm --cached
usage: git rm [<options>] [--] <file>...

    -n, --dry-run         dry run
    -q, --quiet           do not list removed files
    --cached              only remove from the index
    -f, --force           override the up-to-date check
    -r                    allow recursive removal
    --ignore-unmatch      exit with a zero status even if nothing matched

$ ls .git/config 

.git/config

$ cat .git/config 

[core]
	repositoryformatversion = 0
	filemode = true
	bare = false
	logallrefupdates = true
	ignorecase = true
	precomposeunicode = true
[remote "origin"]
	url = git@github.com:Aimeedeer/org-notes.git
	fetch = +refs/heads/*:refs/remotes/origin/*
[submodule "themes/hugo-bare-min-theme"]
	url = https://github.com/kaushalmodi/hugo-bare-min-theme
	active = true

$ rm -rf .git/modules/themes/
$ git status

On branch master
nothing to commit, working tree clean

$ git submodule status

fatal: no submodule mapping found in .gitmodules for path 'themes/hugo-bare-min-theme'

$ git reset
$ git status

On branch master
nothing to commit, working tree clean

$ git submodule status

fatal: no submodule mapping found in .gitmodules for path 'themes/hugo-bare-min-theme'

$ git rm themes/*

error: the following files have local modifications:
    themes/hugo-bare-min-theme
    themes/hugo-debugprint
    themes/hugo-search-fuse-js
(use --cached to keep the file, or -f to force removal)

$ git status

On branch master
Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   config.toml

no changes added to commit (use "git add" and/or "git commit -a")

$ git commit -am"config"

[master 2c206b9] config
 1 file changed, 4 insertions(+)

$ git rm -f themes/*

rm 'themes/hugo-bare-min-theme'
rm 'themes/hugo-debugprint'
rm 'themes/hugo-search-fuse-js'

$ git status

On branch master
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	deleted:    themes/hugo-bare-min-theme
	deleted:    themes/hugo-debugprint
	deleted:    themes/hugo-search-fuse-js


$ git commit -m"rm"

[master 4404bde] rm
 3 files changed, 3 deletions(-)
 delete mode 160000 themes/hugo-bare-min-theme
 delete mode 160000 themes/hugo-debugprint
 delete mode 160000 themes/hugo-search-fuse-js
#+end_src

Finally the submodule is clean!

#+begin_src shell
$ git submodule status
#+end_src

I go back to the `themes` folder to start over.

#+begin_src shell
$ cd themes/
$ git clone https://github.com/kaushalmodi/hugo-bare-min-theme
$ cd hugo-bare-min-theme/
$ rm -rf .git
$ cd ..
$ cd ..
$ git status

On branch master
Untracked files:
  (use "git add <file>..." to include in what will be committed)
	themes/

nothing added to commit but untracked files present (use "git add" to track)

$ git add .

-bare-min-theme/exampleSite/content/post/migrate-from-jekyll.md

$ git status

On branch master
Changes to be committed:
  (use "git restore --staged <file>..." to unstage)
	new file:   themes/hugo-bare-min-theme/.gitignore
	new file:   themes/hugo-bare-min-theme/.gitmodules
	new file:   themes/hugo-bare-min-theme/LICENSE.md
	new file:   themes/hugo-bare-min-theme/README.md
	new file:   themes/hugo-bare-min-theme/archetypes/.gitkeep
	new file:   themes/hugo-bare-min-theme/config.toml
	new file:   themes/hugo-bare-min-theme/exampleSite/.dir-locals.el
	new file:   themes/hugo-bare-min-theme/exampleSite/LICENSE
	new file:   themes/hugo-bare-min-theme/exampleSite/README.md
	new file:   themes/hugo-bare-min-theme/exampleSite/config.toml
	new file:   themes/hugo-bare-min-theme/exampleSite/content/about.md
	new file:   themes/hugo-bare-min-theme/exampleSite/content/post/creating-a-new-theme.md
	new file:   themes/hugo-bare-min-theme/exampleSite/content/post/goisforlovers.md
	new file:   themes/hugo-bare-min-theme/exampleSite/content/post/hugoisforlovers.md
	new file:   themes/hugo-bare-min-theme/exampleSite/content/post/migrate-from-jekyll.md
	new file:   themes/hugo-bare-min-theme/exampleSite/content/search.md
	new file:   themes/hugo-bare-min-theme/exampleSite/exampleSite.org
	new file:   themes/hugo-bare-min-theme/exampleSite/layouts/.gitkeep
	new file:   themes/hugo-bare-min-theme/exampleSite/static/.gitignore
	new file:   themes/hugo-bare-min-theme/exampleSite/themes/.ignore
	new file:   themes/hugo-bare-min-theme/exampleSite/themes/hugo-bare-min-theme
	new file:   themes/hugo-bare-min-theme/images/screenshot.png
	new file:   themes/hugo-bare-min-theme/images/tn.png
	new file:   themes/hugo-bare-min-theme/layouts/404.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/baseof.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/li.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/list.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/single.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/summary.html
	new file:   themes/hugo-bare-min-theme/layouts/_default/terms.html
	new file:   themes/hugo-bare-min-theme/layouts/index.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/archive/version_ge.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/header_image.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/mathjax.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/opengraph.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/summary_minus_toc.html
	new file:   themes/hugo-bare-min-theme/layouts/partials/twitter_cards.html
	new file:   themes/hugo-bare-min-theme/layouts/shortcodes/figure2.html
	new file:   themes/hugo-bare-min-theme/netlify.toml
	new file:   themes/hugo-bare-min-theme/static/css/github_chroma.css
	new file:   themes/hugo-bare-min-theme/static/js/mathjax-config.js
	new file:   themes/hugo-bare-min-theme/theme.toml
#+end_src

I commit the changes and check the status,
and it looks clean. Great!

#+begin_src shell
$ git commit -am"theme"
$ git submodule status
#+end_src


Then I repeat the workable solution to the other two theme repos,
and push the final changes.

Netlify Build Complete!

*** Others

It is strange that I don't see other people met these problems
when I searched on Google.

I also hope I can avoid this type of problems next time,
or find better solutions.
** Lighthouse Run                              :blockchain:ethereum:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: lighthouse-run
:EXPORT_DATE: 2020-08-12
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Lighthouse first try.
:EXPORT_OPTIONS: toc:2
:END:

*** 2020-08-12 Testing

#+begin_src shell
validator_client_1  | Your wallet's 12-word BIP-39 mnemonic is:
validator_client_1  | 
validator_client_1  | 	enlist whip budget awkward gold glad toast demise grass radar chicken link
validator_client_1  | 
validator_client_1  | This mnemonic can be used to fully restore your wallet, should 
validator_client_1  | you lose the JSON file or your password. 
validator_client_1  | 
validator_client_1  | It is very important that you DO NOT SHARE this mnemonic as it will 
validator_client_1  | reveal the private keys of all validators and keys generated with  
validator_client_1  | this wallet. That would be catastrophic.
validator_client_1  | 
validator_client_1  | It is also important to store a backup of this mnemonic so you can 
validator_client_1  | recover your private keys in the case of data loss. Writing it on 
validator_client_1  | a piece of paper and storing it in a safe place would be prudent.
validator_client_1  | 
validator_client_1  | Your wallet's UUID is:
validator_client_1  | 
validator_client_1  | 	44b3b046-628a-4e4b-9e3c-db614554c973
validator_client_1  | 
validator_client_1  | You do not need to backup your UUID or keep it secret.
validator_client_1  | Running account manager for medalla testnet


beacon_node_1       | Aug 12 17:15:03.191 INFO Libp2p Service                          peer_id: PeerId("16Uiu2HAmMCq2UrX3QR1MUTYPhmn5WMa7jf58zUw5uv5Yj6DYve97"), service: libp2p
beacon_node_1       | Aug 12 17:15:03.191 INFO ENR Initialised                         tcp: Some(9000), udp: None, ip: None, id: 0x54d7..f90b, seq: 1, enr: enr:-KO4QEiEj3uKV2pqOiuKDYPo0LKtXHl0ZXpx7iZJXFwBD_-1Gc2tnqTgYA2oVNYAuOzjktYL_-hmh14zOjD3uqCRGs8Bh2F0dG5ldHOIAAAAAAAAAACEZXRoMpDnp11aAAAAAf__________gmlkgnY0iXNlY3AyNTZrMaEDfwWJzY-NbCoPfSXUuXm6XcmKqRSPK4UmaraCOoeEngKDdGNwgiMo, service: libp2p
beacon_node_1       | Aug 12 17:15:03.192 INFO Listening established                   address: /ip4/0.0.0.0/tcp/9000/p2p/16Uiu2HAmMCq2UrX3QR1MUTYPhmn5WMa7jf58zUw5uv5Yj6DYve97, service: libp2p


validator_client_1  | 1/1	0x8bd5d025f7b5b46d622ffe26b80da6886f1567da0e3a3a38ca2b6dc9bae23da3bc0300d5d32b9c608a4dbcfa21acca73
validator_client_1  | Aug 12 17:15:04.471 WARN Ethereum 2.0 is pre-release. This software is experimental.
validator_client_1  | Aug 12 17:15:04.471 INFO Lighthouse started                      version: Lighthouse/v0.2.2-8a1a4051+
validator_client_1  | Aug 12 17:15:04.471 INFO Configured for testnet                  name: medalla
validator_client_1  | Aug 12 17:15:04.474 INFO Starting validator client               datadir: "/root/.lighthouse/validators", beacon_node: http://beacon_node:5052
validator_client_1  | Aug 12 17:15:04.517 INFO Completed validator discovery           new_validators: 1
validator_client_1  | Aug 12 17:15:05.298 INFO Enabled validator                       voting_pubkey: 0x8bd5d025f7b5b46d622ffe26b80da6886f1567da0e3a3a38ca2b6dc9bae23da3bc0300d5d32b9c608a4dbcfa21acca73
validator_client_1  | Aug 12 17:15:05.298 INFO Initialized validators                  enabled: 1, disabled: 0
validator_client_1  | Aug 12 17:15:05.310 INFO Connected to beacon node                version: Lighthouse/v0.2.2-8a1a4051+/x86_64-linux
validator_client_1  | Aug 12 17:15:05.311 INFO Genesis has already occurred            seconds_ago: 706497
validator_client_1  | Aug 12 17:15:05.333 INFO Loaded validator keypair store          voting_validators: 1
validator_client_1  | Aug 12 17:15:05.335 INFO Block production service started        service: block
validator_client_1  | Aug 12 17:15:05.335 INFO Attestation production service started  next_update_millis: 2664, service: attestation
#+end_src
** Hugo Code Highlight                                    :hugo:css:@hacking:
:PROPERTIES:
:EXPORT_FILE_NAME: hugo-code-highlight
:EXPORT_DATE: 2020-11-14
:EXPORT_HUGO_SECTION: hacking
:EXPORT_DESCRIPTION: Hugo uses default built-in code highlight. Change it from config.toml and (maybe) add your own syntax.css.
:EXPORT_OPTIONS: toc:2
:END:


*** Disable the default

Add this code to the top level in your config.toml.
Do not put it below [Params].

#+begin_src 
pygmentsUseClasses = true
#+end_src

*** Generate your syntax.css

Hugo's doc:
[[https://gohugo.io/content-management/syntax-highlighting/][Generate Syntax Highlighter CSS]]

#+begin_src shell
hugo gen chromastyles --style=monokai > syntax.css
#+end_src

Replace "monokai" with other names [[https://xyproto.github.io/splash/docs/][here]].

Add the CSS file to the right place, for example,
> static/css/syntax.css

and add the path to your header.html or head.html,
where stylesheets are imported.
** Game Theory                  :blockchain:incentives:gametheory:@community:
:PROPERTIES:
:EXPORT_FILE_NAME: game-theory
:EXPORT_DATE: 2020-11-24
:EXPORT_HUGO_SECTION: community
:EXPORT_DESCRIPTION: Game theory, blockchain protocols, etc.
:EXPORT_OPTIONS: toc:2
:END:


*** Learning

[[https://www.youtube.com/watch?v=WyRyWQwm0x0][An Axiomatic Approach to Block Rewards (Tim Roughgarden @ Stanford Blockchain Conference 2020)]]
> *Strategy:*
> - articulate desiderata of allocation rules
> - prove that the proportional rule the unique
    one satisfying all of them
>
> *Role models:* von Neumann-Morgenstern Utility Theory,
  Arrow/s Impossibility Theorem, the Shapley value.
>
> *Note:* impossibility/uniqueness results clarify
  the compromises required.

[[https://arxiv.org/pdf/1909.10645.pdf][An Axiomatic Approach to Block Rewards]]

** Blockchain Voting                           :blockchain:voting:@community:
:PROPERTIES:
:EXPORT_FILE_NAME: blockchain-voting
:EXPORT_DATE: 2020-11-16
:EXPORT_HUGO_SECTION: community
:EXPORT_DESCRIPTION: Reading notes about blockchain voting.
:EXPORT_OPTIONS: toc:2
:END:

*** Posts

[[https://www.schneier.com/blog/archives/2019/02/blockchain_and_.html][Blockchain and Trust]], 2019
> When you analyze both blockchain and trust, you quickly realize that 
there is much more hype than value. Blockchain solutions are 
often much worse than what they replace.
>
> First, a caveat. By blockchain, I mean something very specific: 
the data structures and protocols that make up a public blockchain. 
These have three essential elements. The first is a distributed 
(as in multiple copies) but centralized (as in theres only one) ledger, 
which is a way of recording what happened and in what order. 
This ledger is public, meaning that anyone can read it, and immutable, 
meaning that no one can change what happened in the past.
>
> The second element is the consensus algorithm, which is a way 
to ensure all the copies of the ledger are the same. This is 
generally called mining; a critical part of the system is that 
anyone can participate. It is also distributed, meaning that 
you dont have to trust any particular node in the consensus network. 
It can also be extremely expensive, both in data storage and 
in the energy required to maintain it. Bitcoin has the most expensive 
consensus algorithm the world has ever seen, by far.
>
> Finally, the third element is the currency. This is some sort of 
digital token that has value and is publicly traded. Currency is 
a necessary element of a blockchain to align the incentives of 
everyone involved. Transactions involving these tokens are stored on the ledger.
>
> Most blockchain enthusiasts have a unnaturally narrow definition of trust. 
Theyre fond of catchphrases like [[https://www.nytimes.com/2017/12/18/opinion/bitcoin-boom-technology-trust.html][in code we trust]], [[https://www.amazon.com/Math-We-Trust-Bitcoin-Cryptocurrency-ebook/dp/B07C7TPXMD?tag=w050b-20][in math we trust]], 
and [[https://cryptoclothing.org/product/crypto-shirt/][in crypto we trust]]. This is trust as verification. 
But verification isnt the same as trust.

> Morals and reputation scale only to a certain population size. 
Primitive systems were good enough for small communities, 
but larger communities required delegation, and more formalism.
>
> The third is institutions. Institutions have rules and laws that 
induce people to behave according to the group norm, 
imposing sanctions on those who do not. In a sense, 
laws formalize reputation. Finally, the fourth is security systems. 
These are the wide varieties of security technologies we employ: 
door locks and tall fences, alarm systems and guards, 
forensics and audit systems, and so on.
>
> These four elements work together to enable trust. 

> In many ways, trusting technology is harder than trusting people. 
Would you rather trust a human legal system or the details of 
some computer code you dont have the expertise to audit?


*** Papers

[[https://people.csail.mit.edu/rivest/pubs/PSNR20.pdf][Going from Bad to Worse: From Internet Voting to Blockchain Voting]], November 6, 2020 (DRAFT)

** DAO                                            :blockchain:dao:@community:
:PROPERTIES:
:EXPORT_FILE_NAME: dao
:EXPORT_DATE: 2020-11-16
:EXPORT_HUGO_SECTION: community
:EXPORT_DESCRIPTION: Reading notes about the community DAO.
:EXPORT_OPTIONS: toc:2
:END:

[[https://blog.ethereum.org/2014/12/26/secret-sharing-daos-crypto-2-0/][Secret Sharing DAOs: The Other Crypto 2.0]], 2014

[[https://github.com/DavidJohnstonCEO/DecentralizedApplications][The General Theory of Decentralized Applications, Dapps]]
> The concept of a Dapp is so powerful and elegant, because it does not 
include these traditional corporate techniques. The ownership of 
the Dapps tokens is all that is required for the holder to use the system. 
Its that simple. The value of the tokens is determined by 
how much people value the application. All the incentives, 
all the monetization, all the ways to raise support are 
built into this beautifully simple structure. 
Dapps are not required to recreate the functions that used to be necessary 
in centralized corporations in order to balance the power of shareholders 
and offer returns for investors and employees.

> Initial tokens are distributed
>
> If the Dapp is using the fund-raising mechanism, a wallet software becomes 
available to the stakeholders of the Dapp, so that they can exchange 
the tokens of the DA. In the case of Mastercoin, an Exodus fund-raising address 
and a wallet script were publicly released.
>
> If the Dapp is using the development mechanism, a bounty system is 
put in place that allows the suggestion of tasks to be performed, 
the tracking of the people who are working on those tasks and 
the criteria by which bounties can be awarded.


[[https://bitcoinmagazine.com/articles/bootstrapping-a-decentralized-autonomous-corporation-part-i-1379644274][Bootstrapping A Decentralized Autonomous Corporation: Part I]] | 2013
> As Lets Talk Bitcoins Daniel Larmier pointed out in his own exploration on this concept, 
in a sense Bitcoin itself can be thought of as a very early prototype of exactly such a thing. 
Bitcoin has 21 million shares, and these shares are owned by what can be considered 
Bitcoins shareholders. It has employees, and it has a protocol for paying them: 25 BTC 
to one random member of the workforce roughly every ten minutes. It even has 
its own marketing department, to a large extent made up of the shareholders themselves. 
However, it is also very limited. It knows almost nothing about the world except for 
the current time, it has no way of changing any aspect of its function aside from 
the difficulty, and it does not actually do anything per se; it simply exists, 
and leaves it up to the world to recognize it. The question is: can we do better?

> The first challenge is obvious: how would such a corporation actually make 
any decisions? Its easy to write code that, at least given predictable environments, 
takes a given input and calculates a desired action to take. But who is going to 
run the code? If the code simply exists as a computer program on some particular machine, 
what is stopping the owner of that machine from shutting the whole thing down, 
or even modifying its code to make it send all of its money to himself? To this problem, 
there is only one effective answer: distributed computing.

> Here, rather, we need the kind of distributed computing that we see in Bitcoin: 
a set of rules that decentrally self-validates its own computation. 
In Bitcoin, this is accomplished by a simple majority vote: if you are not helping to 
compute the blockchain with the majority network power, your blocks will get discarded 
and you will get no block reward. The theory is that no single attacker will 
have enough computer power to subvert this mechanism, so the only viable strategy 
is essentially to go with the flow and act honestly to help support the network 
and receive ones block reward. So can we simply apply this mechanism to 
decentralized computation? That is, can we simply ask every computer in the network to 
evaluate a program, and then reward only those whose answer matches the majority vote? 

> Bitcoin is a special case because Bitcoin is simple: it is just a currency, 
carrying no property or private data of its own. A virtual corporation, 
on the other hand, would likely need to store the private key to its Bitcoin wallet  
a piece of data which should be available in its entirety to no one, not to everyone 
in the way that Bitcoin transactions are. But, of course, the private key must 
still be usable. Thus, what we need is some system of signing transactions, 
and even generating Bitcoin addresses, that can be computed in a decentralized way. 
Fortunately, Bitcoin allows us to do exactly that.

[[https://blog.ethereum.org/2014/05/06/daos-dacs-das-and-more-an-incomplete-terminology-guide/][
DAOs, DACs, DAs and More: An Incomplete Terminology Guide]] | 2014
> as Bitshares Daniel Larimer points out, everyone thinks a DAC is just a way of 
IPOing your centralized company. The intent of this article will be to delve into 
some of these concepts, and see if we can come up with at least the beginnings of 
a coherent understanding of what all of these things actually are.

> Note that there is one gray area here: contracts which are finite on one side, 
but infinite on the other side. For example, if I want to hedge the value of 
my digital assets, I might want to create a contract where anyone can 
freely enter and leave. Hence, the other side of the contract, the parties 
that are speculating on the asset at 2x leverage, has an unbounded number of parties, 
but my side of the contract does not. Here, I propose the following divide: 
if the side with a bounded number of parties is the side that intends to receive 
a specific service (ie. is a consumer), then it is a smart contract; however, 
if the side with a bounded number of parties is just in it for profit 
(ie. is a producer), then it is not.

> That is, there is a concept of shares in a DAC which are purchaseable 
and tradeable in some fashion, and those shares potentially entitle 
their holders to continual receipts based on the DACs success. 
A DAO is non-profit; though you can make money in a DAO, the way to do 
that is by participating in its ecosystem and not by providing investment 
into the DAO itself. Obviously, this distinction is a murky one; 
all DAOs contain internal capital that can be owned, and the value of 
that internal capital can easily go up as the DAO becomes more powerful/popular, 
so a large portion of DAOs are inevitably going to be DAC-like to some extent.
>
> Thus, the distinction is more of a fluid one and hinges on emphasis: 
to what extent are dividends the main point, and to what extent is it about 
earning tokens by participation? Also, to what extent does the concept of 
a share exist as opposed to simple virtual property? For example, 
a membership on a nonprofit board is not really a share, because membership 
frequently gets granted and confiscated at will, something which would be 
unacceptable for something classified as investable property, and a bitcoin is not 
a share because a bitcoin does not entitle you to any claim on profits or 
decision-making ability inside the system, whereas a share in a corporation 
definitely is a share. In the end, perhaps the distinction might ultimately be 
the surprisingly obscure point of whether or not the profit mechanism 
and the consensus mechanism are the same thing.

> Additionally, there is also the question of how all of these things should be built. 
An AI, for example, should likely exist as a network of private servers, 
each one running often proprietary local code, whereas a DO should be fully 
open source and blockchain-based. Between those two extremes, there is 
a large number of different paradigms to pursue. How much of the intelligence 
should be in the core code? Should genetic algorithms be used for updating code, 
or should it be futarchy or some voting or vetting mechanism based on individuals? 
Should membership be corporate-style, with sellable and transferable shares, 
or nonprofit-style, where members can vote other members in and out? 
Should blockchains be proof of work, proof of stake, or reputation-based? 
Should DAOs try to maintain balances in other currencies, 
or should they only reward behavior by issuing their own internal token? 
These are all hard problems and we have only just begun scratching the surface of them.

[[https://hackernoon.com/turn-an-internet-community-into-a-dao-in-3-steps-8k1b3w5y][Turn an Internet Community into a DAO in 3 Steps]]
> Simply put, DAO is a perfect structure to organize collective activities in the community, 
especially when most collaborations in the community are conducted distributedly, 
multi-disciplinarily, in random occurrence, and without a trust basis. 
DAO leverages Smart Contract on the blockchain to automatically implement contract terms 
to solve the trust issues. Also, contribution-based incentives can be allocated to activate the community.
>
> However, DAO's structure is not perfect and has some limitations for large scale applications.
>
> First, DAO relies too much on the smart contract, while the machine language is not suitable 
for conveying complex business logic. It's almost impossible for a general internet community 
to become an expert to compile all its collaboration needs into the contract. 
The stake is too high! It is also costly and low in efficiency if every operation step 
needs to run smart contracts on the blockchain to reach the global consensus. 
>
> Second, most of DAO's governance protocols mainly focus on the voting algorithm, 
while for the internet communities, voting would only be a small part of 
all the collective actions. Actually, the community is more caring about how to 
make the collaborations happen among all the community members.
>
> Third, as there is a lack of an effective management system to regulate 
the collaborations, the DAO has become only a shell structure without any real value 
creation activities in it. So, it's not hard to understand that the DAO's 
governance token holders have low intent to vote as they do not care about 
what is going on in the community, and they are only pursuing arbitrage opportunities.  

> The Wiki-based ComCo Management Framework contains one's collaboration history, 
which can be traced back as the credential check.

**

** Governance                                         :governance:@community:
:PROPERTIES:
:EXPORT_FILE_NAME: governance
:EXPORT_DATE: 2020-11-12
:EXPORT_HUGO_SECTION: community
:EXPORT_OPTIONS: toc:2
:END:

#+begin_description
Notes about governance in open source communities,
including developer communities and blockchain projects' communities.
#+end_description

[[https://www.djangoproject.com/weblog/2020/mar/12/governance/][New governance model for the Django project]]
- James Bennett on March 12, 2020

[[https://github.com/django/deps/blob/master/accepted/0010-new-governance.rst][DEP 0010: New governance for the Django project]]
- Created:	2018-09-22
- Last-Modified:	2020-03-12

[[https://github.com/rust-lang/wg-governance/blob/master/CHARTER.md][Rust-lang: Governance WG Charter]]
- last updated: [May 25th 2019] 

[[https://ziglang.org/news/announcing-zig-software-foundation.html][Announcing the Zig Software Foundation]]
- Zig language

[[https://modelviewculture.com/pieces/codes-of-conduct-when-being-excellent-is-not-enough][Codes of Conduct: When Being Excellent is Not Enough]]
- December 10th, 2014

** Philosophy and Minds                    :philosophy:mind:thought:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: philosophy-and-minds
:EXPORT_DATE: 2020-11-16
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Learning from great minds.
:EXPORT_OPTIONS: toc:2
:END:


[[https://www.youtube.com/watch?v=SOr1YYRljV8][Yaron Brook: Ayn Rand and the Philosophy of Objectivism | Lex Fridman Podcast #138]]

Yaron Brook introduced a lot of stories about Ayn Rand 
in this podcast.
I only read Ayn Rand's book [[https://en.wikipedia.org/wiki/Atlas_Shrugged][Atlas Shrugged]] several years ago,
and I loved it.

A shot one [[https://www.youtube.com/watch?v=oC2nWeEhvcw][Ayn Rand doesn't have all the answers, but she has all the questions | Michael Malice]].

I plan to reread [[https://www.goodreads.com/book/show/6454477-the-red-book][The Red Book]] from C.G. Jung
and Friedrich Nietzsche's books.
** Papers                                                    :paper:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: papers
:EXPORT_DATE: 2020-12-05
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Papers I've read. 
:EXPORT_OPTIONS: toc:2
:END:


[[https://arxiv.org/abs/2012.01032][VM Matters: A Comparison of WASM VMs and EVMs in the Performance of Blockchain Smart Contracts]]


[[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3725023][Determinants of Early-Stage Startup Performance: Survey Results]]
> To explore determinants of new venture performance, the CEOs of 470 early-stage startups were surveyed regarding a broad range of factors related to their ventures customer value proposition, product management, marketing, technology and operations, financial management, funding choices, team management, and founder attributes. Multivariate regression analysis shows that startups that employed lean startup management practicesin particular, an optimal rate of pivotinghad stronger seed equity valuation growth, as did new ventures that struck the right balance in recruiting for skill versus attitude and that professionalized human resource policies earlier. High levels of confidence in financial metricsincluding estimates of unit economics, the ratio of customer lifetime value to customer acquisition cost, and total addressable market sizewere also associated with strong growth in seed equity value.
>
> Valuation outcomes were not related to several founder/CEO attributes, including age, educational background, personality traits, and motivations for becoming an entrepreneur. Likewise, choosing angels versus venture capital firms as lead seed round investors did not predict subsequent growth in equity valuation, nor did decisions about partnerships to provide technology, operational capacity, or marketing support.

[[https://geon.usc.edu/~biederman/publications/Biederman_Shiffrar_1987.pdf][Sexing Day-Old Chicks: A Case Study and Expert Systems Analysis of a Difficult Perceptual-Learning Task]]

[[https://eprint.iacr.org/2018/414.pdf][Aggregation of Gamma-Signatures and Applications to Bitcoin]]

Not a great paper. I don't think it has strong proof of its point,
and I am not sure if it's workable as their reasoning.

> Aggregate signature (AS) allows non-interactively condensing multiple individual signatures into a compact one.
Besides the faster verification, it is useful to reduce storage and bandwidth, and is especially attractive for blockchain and cryptocurrency. 

> Currently, due to the 1M-byte limitation of block size, about 7 transactions
are conducted per second in the Bitcoin system. This leads to, in particular,
longer confirmation latency, relatively higher transaction fees, and easier target
of spam attacks.

> Bitcoin uses the EC-DSA signature scheme [37] over
the secp256k1 curve [22]. According to Bitcoin Stack Exchange, in a standard
pay to public key hash (P2PKH) transaction or a pay to script hash (P2SH)
transaction, the signatures occupy about 40% of transcript size.
In addition, an EC-DSA signature involves non-linear combination of ephemeral secret-key
and static secret-key, which is the source for relative inefficiency and for the
cumbersome in extensions to multi-signatures [8, 47], scriptless scripts [66], etc.
As a consequence, recently there is also renewed interests in deploying Schnorrs
signature with Bitcoin in the future.

> Practical aggregate signature schemes were proposed [17, 7] in the plain
public-key model. They are derived based on the BLS short signature [18] in
groups with bilinear maps. There have been some discussions on deploying the
pairing-based AS schemes [17, 7] in the Bitcoin system [46], which are briefly
summarized below.
>  System complexity. Deploying pairing-based aggregate signature schemes requires the replacement of not only the EC-DSA algorithm but also the underlying elliptic curve. It makes a deployment in practice (such as Bitcoin)
much more invasive than simply shifting algorithms.
>  Bilinear group vs. general group. Intractability problems in groups with bilinear maps are weaker than the discrete logarithm problem in general EC
groups.
>  Verification speed. As an individual signature scheme, the verification of the
pairing-based BLS signature is significantly slower than that of EC-DSA.
Note that the miners still need to verify the correctness of individual BLS
signatures before aggregating them into a block. Some survey indicates that
on a concrete hardware it can verify 70,000 secp256k1 signatures per second,
while it could only verify about 8,000 BLS signatures per second [46].
>
> It is thus highly desirable to develop aggregate signatures, with the following
features simultaneously:
>  It can be built from general elliptic curves (without bilinear maps), in the
plain public-key model with fully asynchronous communications.
>  The underlying signature scheme has provable security, and moreover, is
more efficient and flexible than EC-DSA.

[[https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3715647][Freedom to (Smart) Contract: The Myth of Code and Blockchain Governance Law]]

> The only thing a smart contract truly adds to traditional contracts is automated
execution that is enforced by the blockchains consensus mechanism; this may provide some efficiency
to the legal system by streamlining basic performance but it cannot be the only form of governance over
smart contracts. 

[[https://eprint.iacr.org/2020/1601][Adaptive layer-two dispute periods in blockchains]]

> In the Ethereum Virtual Machine [41] (EVM), the computational, storage, and transmission efforts required to process
a transaction are characterized by its gas consumption, where
gas is a unit designed to capture the total cost of execution of
a transaction. Consequently, an EVM transaction must specify
both (i) a limit of how much gas the transaction may consume,
and (ii) a price paid by the transaction sender per unit of
gas the transaction consumes. Accordingly, the capacities of
Ethereum blocks are decided by the network in terms of
gas units. While some studies investigate the precision of
gas as a measure of true transaction execution cost [42, 43],
and others investigate how transaction gas prices can be set
effectively [44], this paper, to the best of our knowledge, is
the first to propose blockchain gas consumption as a measure
of dispute opportunity.
>
> Plasma is an off-chain architecture [10] managed by a
central operator. In Plasma MVP [2], the central operator
periodically publishes a commitment to the state of the
UTXO ledger on the parent-chain. Users must validate the
full ledger with every commitment, and dispute any fake
transactions or dishonestly minted funds. Plasma Cash [3]
reduces the user verification overhead of Plasma MVP. Each
deposit creates a new coin whose ownership can be transferred. 
A user withdrawing m individual coins has to initiate
m disputable withdrawals using the smart-contract. Plasma
Debit [4] amends Plasma Cash by adding a numeric value
a to each coin to denote what portion of the corresponding
deposit belongs to the owning user, while the rest is owed to
the operator, bringing it closer to a payment-channel design.
Plasma Prime [5] reduces the sizes of disputes. NOCUST is
an account-based Plasma design [7] where an operator that
withholds the data behind its commitments must be forced to
reveal it within a fixed-time period. In NOCUST-ZKP [8, 11]
commitments are proven in zero-knowledge to be correct, but
disputes to reveal data may only be performed within a fixed
amount of time. Lastly, [12] analyses the lower bound on the
number of disputes that must be made in such schemes.

** Books                                                      :book:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: books
:EXPORT_DATE: 2020-11-13
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Books I've read. 
:EXPORT_OPTIONS: toc:2
:END:

Aimee's [goodreads](https://www.goodreads.com/user/show/90889710-aimee-zhu)


*** 2020

- Guns, Germs, and Steel: The Fates of Human Societies
- [[https://www.amazon.com/Art-War-AmazonClassics-Sun-Tzu-ebook/dp/B073QR86XF/ref=sr_1_4][The Art of War]]
- [[https://www.amazon.com/15-Minute-Read-Power-Subconscious-ebook/dp/B08541YNTW/ref=rtpb_2/138-2049715-3003242][The Power of Your Subconscious Mind]]
- [[https://landing.coingecko.com/how-to-defi/][How to DeFi]]
- [[https://www.goodreads.com/book/show/38819529-the-hobbit][The Hobbit]]
- [[https://www.goodreads.com/book/show/50491494-options-trading-crash-course][Options Trading Crash Course]]
- [[https://www.amazon.com/Franklins-Autobiography-Eclectic-English-Classics-ebook/dp/B0052GE5GC/][Franklin's Autobiography]]
- [[https://www.goodreads.com/notes/38145718-thomas-edison/90889710-aimee-zhu][Thomas Edison: A Captivating Guide to the Life of a Genius Inventor]]
- [[https://www.amazon.com/Elements-Style-Fourth-William-Strunk-ebook/dp/B07NPN5HTP/ref=sr_1_4][The elements of style]]
- [[https://www.amazon.com/Out-My-Mind-Sharon-Draper-ebook/dp/B003ATPRNI/ref=sr_1_3][Out of my mind]]
- [[https://www.amazon.com/Manage-Your-Day-Day-Creative-ebook/dp/B00B77UE4W/ref=sr_1_2][Manage Your Day-to-Day: Build Your Routine, Find Your Focus, and Sharpen Your Creative Mind]]
- [[https://www.amazon.com/Animal-Farm-Fairy-Modern-Classic-ebook/dp/B003K16PUU/ref=sr_1_1][Animal Farm]]
- [[https://www.amazon.com/Decisions-Death-Street-Kindle-Single-ebook/dp/B00TO1J78M/ref=sr_1_1][Decisions: Life and Death on Wall Street]]
- [[https://www.amazon.com/Little-Still-Market-Books-Profits-ebook/dp/B003VWCQB0/ref=sr_1_1][The Little Book that Still Beats the Market]]
- [[https://www.amazon.com/If-You-Tell-Unbreakable-Sisterhood-ebook/dp/B07Q5TL9SQ/ref=sr_1_3][If You Tell: A True Story of Murder, Family Secrets, and the Unbreakable Bond of Sisterhood]]
- [[https://www.amazon.com/Think-Grow-Rich-Napoleon-Hill-ebook/dp/B08776ZZY4/ref=sr_1_3][Think and Grow Rich]]
- [[https://www.goodreads.com/notes/36992849-work-less-make-more/90889710-aimee-zhu?ref=bsop][Work Less, Make More]]
- 
  - ref: origin [[https://www.amazon.com/Autobiography-Andrew-Carnegie-Gospel-Classics-ebook/dp/B002G54Y3Q/ref=sr_1_4][The Autobiography of Andrew Carnegie and The Gospel of Wealth]]
- [[https://www.amazon.cn/dp/B087JNZ6ZL/ref=sr_1_1][ CEO ]]
  - ref: origin [[https://www.amazon.com/gp/product/0399592091/ref=ox_sc_act_title_1][The Ride of a Lifetime: Lessons Learned from 15 Years as CEO of the Walt Disney Company]]
- [[https://www.goodreads.com/book/show/51957605][]]
  - ref: origin [[https://www.amazon.com/REMINISCENCES-STOCK-OPERATOR-Edwin-Lefevre-ebook/dp/B07ND35YTJ/ref=tmm_kin_swatch_0][Reminiscences of a Stock Operator]]
- [[https://www.amazon.cn/dp/B00U3NDI1C/ref=sr_1_1][]]
  - ref: origin [[https://www.amazon.com/Inside-House-Money-Traders-Profiting-ebook/dp/B00GYXP8CW/ref=sr_1_1][Inside the House of Money: Top Hedge Fund Traders on Profiting in the Global Markets]]
- [[https://www.goodreads.com/book/show/35561327][]]
- [[https://www.amazon.cn/dp/B01HRYE86S/ref=sr_1_1][:]]
  - ref: origin [[https://www.amazon.com/Hot-Zone-Terrifying-Story-Origins-ebook/dp/B007DCU4IQ/ref=sr_1_1][The Hot Zone: The Terrifying True Story of the Origins of the Ebola Virus]]

** Posts I Really Really Like                                 :post:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: posts-i-really-really-like
:EXPORT_DATE: 2021-01-29
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Posts I really really like   
:EXPORT_OPTIONS: toc:2
:END:

[[http://calteches.library.caltech.edu/51/2/CargoCult.htm][Cargo Cult Science]] by Richard P. Feynman

> Some remarks on science, pseudoscience, and learning how to not fool yourself. Caltechs 1974 commencement address.

[[https://blog.rust-lang.org/2017/03/02/lang-ergonomics.html][Rust's language ergonomics initiative]] by Aaron Turon

> Empathy


** Note Management                                           :notes:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: note-management
:EXPORT_DATE: 2020-10-29
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Notes about note management.
:EXPORT_OPTIONS: toc:2
:END:

Notes from 
[[https://zettelkasten.de/posts/three-layers-structure-zettelkasten/][Tale of Complexity  Structural Layers in Note Taking]]

- Bottom Layer: Content  
  Tiny, tiny bits of content.
- Middle Layer: Structure Notes.
  Tables of contents.
- Top Layer: 
  Main Structure Notes and Double Hashes

** How to Read and Write                                   :writing:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: how-to-read-and-write
:EXPORT_DATE: 2020-10-29
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Notes about reading and writing.
:EXPORT_OPTIONS: toc:2
:END:

*** Read books
[[https://zettelkasten.de/posts/barbell-method-reading/][
The Barbell Method of Reading]]

The Barbell Method takes this into account by integrating 
your reading habit into your knowledge work with two steps:

**Read the book**. Read swiftly but dont skip any parts 
unless they make you vomit or put you to sleep. 
Mark all the passages that stand out and contain useful, 
interesting or inspiring information.

**Read the book a second time**. But now you read 
the marked parts only. This time you make notes, 
connect them to past notes (Zettelkasten Method!) 
and think about what youve read. 
Make mindmaps, drawings, bullet points  
everything that helps you to think more clearly.

The quality of the book will now determine 
how much time you invest in it. 
Sometimes, a book is not that important and 
only provides a few shallow pieces of information. 
The second step could only take 
a very short period of time. But a good book is dense. 

True reading is not a passive process in which 
you just create an influx of information. 
It consists of deep processing, thinking and writing on 
what you have read and interconnecting it with you already know.

Only the three parts combined, reading, thinking, and writing, 
produce a true change in your brain and make you a better thinker. 
To write about what you read is important even if 
you dont aim to write books on something. 
Still, you have to write if you want to think properly. 
Still, you have to write to process information properly.

Dont try to impress anyone with things you dont have invested energy into.

At last, you are what you practice regularly. 
You are your habits. If your habits dont include 
to really gnaw on ideas and concepts, 
you wont sharpen your mental teeth. 
So if you want to be able to think deeply 
and properly, practice it.

The Zettelkasten Method is designed to serve several different purposes:

- Optimize the amount of information you process. You should read a lot.
- Produce an archive which consists of true knowledge, not just a collection of half-understood bits of random points.
- Learn to think deeply and thoroughly by making it a habit to practice it.

*** Read papers

[[https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf][How to Read Paper]]

THE THREE-PASS APPROACH

The key idea is that you should read the paper in up to
three passes, instead of starting at the beginning 
and plowing your way to the end. Each pass accomplishes specific
goals and builds upon the previous pass: 
The first pass gives you a general idea about the paper. 
The second pass lets you grasp the papers content, but not its details. 
The third pass helps you understand the paper in depth.


The first pass is a quick scan to get a birds-eye view of
the paper. You can also decide whether you need to do any
more passes. This pass should take about five to ten minutes
and consists of the following steps:
1. Carefully read the title, abstract, and introduction
2. Read the section and sub-section headings, but ignore everything else
3. Read the conclusions
4. Glance over the references, mentally ticking off the ones youve already read

At the end of the first pass, you should be able to answer the five Cs:
1. Category: What type of paper is this? A measurement paper? An analysis of an existing system? A description of a research prototype?
2. Context: Which other papers is it related to? Which theoretical bases were used to analyze the problem?
3. Correctness: Do the assumptions appear to be valid?
4. Contributions: What are the papers main contributions?
5. Clarity: Is the paper well written?

Incidentally, when you write a paper, you can expect most
reviewers (and readers) to make only one pass over it. Take
care to choose coherent section and sub-section titles and
to write concise and comprehensive abstracts. If a reviewer
cannot understand the gist after one pass, the paper will
likely be rejected; if a reader cannot understand 
the highlights of the paper after five minutes, the paper will likely
never be read.

In the second pass, read the paper with greater care, but
ignore details such as proofs. It helps to jot down the key
points, or to make comments in the margins, as you read.

To fully understand a paper, particularly if you are 
reviewer, requires a third pass. The key to the third pass
is to attempt to virtually re-implement the paper: that is,
making the same assumptions as the authors, re-create the
work. By comparing this re-creation with the actual paper,
you can easily identify not only a papers innovations, but
also its hidden failings and assumptions.


This pass requires great attention to detail. You should
identify and challenge every assumption in every statement.
Moreover, you should think about how you yourself would
present a particular idea. This comparison of the actual
with the virtual lends a sharp insight into the proof and
presentation techniques in the paper and you can very likely
add this to your repertoire of tools. During this pass, you
should also jot down ideas for future work.

This pass can take about four or five hours for beginners,
and about an hour for an experienced reader. At the end
of this pass, you should be able to reconstruct the entire
structure of the paper from memory, as well as be able to
identify its strong and weak points. In particular, you should
be able to pinpoint implicit assumptions, missing citations
to relevant work, and potential issues with experimental or
analytical techniques.

Ive used this approach for the last 15 years 
to read conference proceedings, write reviews, 
do background research,
and to quickly review papers before a discussion. 
This disciplined approach prevents me from drowning in the details
before getting a birds-eye-view. It allows me to estimate the
amount of time required to review a set of papers. 
Moreover, I can adjust the depth of paper evaluation depending
on my needs and how much time I have.

If you are reading a paper to do a review, you should also
read Timothy Roscoes paper on [[http://people.inf.ethz.ch/troscoe/pubs/review-writing.pdf][Writing reviews for systems conferences]]. 
If youre planning to write a technical
paper, you should refer both to 
[[http://www.cs.columbia.edu/hgs/etc/writingstyle.html][Henning Schulzrinnes comprehensive website]] 
and [[http://www.che.iitm.ac.in/misc/dd/writepaper.pdf][George Whitesidess excellent overview of the process]]. 
Finally, Simon Peyton Jones has a website 
that covers [[http://research.microsoft.com/simonpj/Papers/givinga-talk/giving-a-talk.htm][the entire spectrum of research skills]].

*** How to write

Timothy Roscoes paper on [[http://people.inf.ethz.ch/troscoe/pubs/review-writing.pdf][Writing reviews for systems conferences]].
This is the paper worth reading many times,
and follow his practice.

**First of all, summarize the paper. **
Give a neutral description of what you think the paper
is about, where the authors are coming from, 
why they view the problem as important,
and what theyve done. 
This is a great way to start writing a review, 
particularly when youre not sure how to get started.

**Second, state what you think the contributions are.** 
Its rare to find a paper that completely fails to 
make any contributions, but its much more common to find one that
makes no useful contributions, 
or contributions that turn out to be flawed. 
In any case, state what the authors think the contributions are, 
or, if you think theres a contribution
you think theyve missed, what it is. 
A surprisingly common mistake among paper
authors is to fail to state the contribution - 
if thats the case, gently point this out (see
Tone below), but try to fill it in.

**Next, give your specific comments** on the paper 
by working through the scribbles you made 
on first (or second) reading. 
Often you may find your opinion has changed in the meantime, 
which is fine (you may even have learned something!). 
Some reviewers like to separate their comments 
into technical discussion, and then small points like typos
and other mistakes, often referred to as nits.

<some good suggestions in between>

Finally, provide some kind of conclusion at the end. 
If you like, summarize the good
points and bad points separately, 
but the important thing is to give 
a brief recommendation for the paper and your reasons for it.

**Consequently, tone is important.**

Rather than saying this paper doesnt cite Multics, which did everything you do and
more, its better to say something like This paper reminded me of Multics, which
seems quite similar. I would find the paper more persuasive if it stated what the authors
do over and above Multics.

Also bear in mind that, in all cases, there is a still a remote possibility that youve
misunderstood the paper. Hence, a flat assertion like The algorithm given in the paper
breaks in the presence of Byzantine faults is risky, and may be unfair to the authors.
Its better to write The description in the paper left me worried that algorithm breaks
in the presence of Byzantine faults., preferably followed by a sketch of why you think
this is the case.

**Conclusion**

Writing a good review is important: it helps the authors do better work, it helps you
to learn more about the subject being reviewed, and it makes you look good in front
of your peers. Surprisingly, it can also be fun  even writing a review for a really bad
paper can be rewarding if it forces you to explain concepts afresh in a new context.

*** Articles about writing

[[https://github.com/mnielsen/notes-on-writing/blob/master/notes_on_writing.md][Notes on writing well]]
by Michael Nielsen

> On note-taking: Something I wish I'd understood earlier is how important it is to get good at note-taking. It is not trivial to do well. Rather, it is something that one can get better and better at. The payoff of improving is that it makes writing far easier. The better your notes, the easier the writing will be. There are several elements to it: (1) Primary note-taking; (2) Queueing; (3) Refactoring and organization. You need to get good at all.
>
> In "Structure and Interpretation of Computer Programs":
>
> - "Building Abstractions with Procedures"
> - "Building Abstractions with Data"
> - "Modularity, Objects, and State"
> - "Metalinguistic Abstraction"
> - "Computing with Register Machines"
>
> Chapter titles 1, 2 and 5 are verb phrases, while 3 and 4 are noun phrases. I prefer the more active titles, perhaps for the obvious reason that they create more of a sense of going someplace!
>
> Beware classic style if you've not yet mastered a subject: Sometimes, you wish to write about a subject, even though you haven't yet mastered that subject. It is difficult to write on such a subject in classic style, because the assumptions of classic style very nearly imply mastery. It is easier to instead slip occasionally into a personal style, explaining your exploration of the subject, and the limits of your knowledge. In such cases it may work to use a hybrid style, in which you alternate the personal with the classic. Feynman occasionally uses this style, either to explain his own thinking, or to explain the hypothetical thinking of others.

[[http://www.paulgraham.com/useful.html][How to write usefully]]

[[https://www.gwern.net/About#writing-checklist][Gwern's writing checklist]]
[[https://www.nngroup.com/articles/how-people-read-online/][
How people read online]]

** Depression                                    :depression:mental:@reading:
:PROPERTIES:
:EXPORT_FILE_NAME: depression
:EXPORT_DATE: 2020-12-10
:EXPORT_HUGO_SECTION: reading
:EXPORT_DESCRIPTION: Notes about depression.
:EXPORT_OPTIONS: toc:2
:END:

[[https://www.youtube.com/watch?v=8Su5VtKeXU8][How To Cope With Depression]]

[[https://www.ted.com/talks/johann_hari_this_could_be_why_you_re_depressed_or_anxious/transcript][TED: This could be why you're depressed or anxious]]

> In a moving talk, journalist Johann Hari shares fresh insights 
on the causes of depression and anxiety from experts 
around the world -- as well as some exciting emerging solutions. 
"If you're depressed or anxious, you're not weak and 
you're not crazy, you're not, in the main, a machine with broken parts
 -- you're a human being with unmet needs," Hari says.

> We feel this way for reasons, and they can be hard to see 
in the throes of depression -- I understand that really well 
from personal experience. But with the right help, we can 
understand these problems and we can fix these problems together. 
But to do that, the very first step is we have to stop insulting 
these signals by saying they're a sign of weakness, or madness 
or purely biological, except for a tiny number of people. We need to 
start listening to these signals, because they're telling us 
something we really need to hear. It's only when we truly listen to 
these signals, and we honor these signals and respect these signals, 
that we're going to begin to see the liberating, nourishing, 
deeper solutions. The cows that are waiting all around us. 

[[https://www.youtube.com/watch?v=Xm_2zmX6Akc][Jordan Peterson: How To Deal With Depression]]

[[https://www.youtube.com/watch?v=17fbxRQgMlU][Sir Ken Robinson: Finding Your Element]]


** Rust China                                         :rust:china:@community:
:PROPERTIES:
:EXPORT_FILE_NAME: rust-china
:EXPORT_DATE: 2020-11-20
:EXPORT_HUGO_SECTION: community
:EXPORT_DESCRIPTION: All about Rust China.
:EXPORT_OPTIONS: toc:2
:END:

*** Companies using Rust

- Alibaba & Ant Finance
  - Multiple teams & products
  - [[https://occlum.io/][Occlum]] and the [[https://github.com/occlum/occlum][source]] # ~tee~
- [[https://www.huawei.com/en/][Huawei]]
  - Multiple teams & products
- [[https://www.cryptape.com/][Cryptape]] # ~blockchain~
  - [[https://github.com/nervosnetwork/ckb][CKB]]
- [[https://www.rivtower.com/][RivTower ]] # ~blockchain~
  - [[https://github.com/citahub/cita][CITA]]
- [[https://pingcap.com/][PingCAP]] # ~database~
  - [[https://github.com/tikv/tikv][TiKV]]
- [[https://www.bilibili.com/][Bilibili]] # ~video~ ~social~
- [[https://www.bytedance.com/en/][Bytedance]] # ~video~ ~social~
- [[https://www.zhihu.com/][Zhihu]] # ~forum~
  - [[https://github.com/zhihu/rucene][Rucene]]

*** Conferences

[[https://2020conf.rustcc.cn/][Rust China Conf 2020]] | Shanghai or Shenzhen
- Source code?
- Organizing by [[https://rustcc.cn/][RustCC]] 

[[https://rustcon.asia][RustCon Asia 2019]] | Beijing
- Source code is on [[https://github.com/rustcon-asia/beijing-2019][GitHub]]
- Co-organized by [[https://www.cryptape.com/][Cryptape]] and [[https://pingcap.com/][PingCAP]]
- Announcement: [[https://rustcon.asia/blog/hello-asia/][Hello /  Asia]]
- Recap: [[https://medium.com/@Aimeedeer/a-close-touch-with-rust-community-4a8507b756d9][A Close Encounter with Rust Community]]
- [[https://www.dropbox.com/sh/t6s39rupk492ntq/AACSMbbeE-uYLqqlyJmXXGUPa?dl=0][Photos]]
- [[https://www.youtube.com/watch?v=YSEx8wtlPWc&list=PL85XCvVPmGQjPvweRqkBgnh_HKE5MBB8x][Videos]]

*** GitHub Orgs

- https://github.com/rust-lang-cn
- https://github.com/RustChina
- https://github.com/rust-zh


*** Forums and Channels

**** Forum and media

- Forum RustCC: https://rustcc.cn/
- WeChat news channel: Rust
- Telegram news channel: https://t.me/rust_daily_news

**** Telegram

- https://t.me/rust_zh
- https://t.me/rust_deep_water
- https://t.me/rust_tw  

**** WeChat groups

Invite only because of WeChat's limitation.

**** QQ groups

- Rust1303838735 
- Rust2813448660
- Rust570065685
- Topics: 
  - Rust Redox437268658
  - Rust Data Science 681142501
  - Rust webassembly/wasm347929175
  - Rust 687763184 
   https://rust.cc
  - Rust-617238820
  - Rust 825820683
  -  Rust812748521
  - 446590168
  - Offline meetups: 
    - 305842562
    - 966129249
    - 673715651
    - 738772514
    - 131080784
    - 962149536

